---
title: "Environmental Compliance-Incidental Take Authorization (EC-ITA) Reporting"
author: "Kevin L. Stierhoff"
date: '`r format(Sys.time(), format = "%F %T", tz = "UTC", usetz = TRUE)`'
css: css/ast.css
output:
  bookdown::html_document2:
    toc: no
    toc_float: yes
---

```{r setup, include=FALSE}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,swfscMisc,lubridate,cowplot,here,marmap,fs,sf, odbc,
               mapview,mapdata,photobiology,ggmap,knitr,bookdown,tcltk,
               rnaturalearth,ggspatial,kableExtra,geosphere,janitor)

# Install and load required packages from Github -------------------------------
# surveyR
pacman::p_load_gh("kstierhoff/surveyR")
# atm==
pacman::p_load_gh("kstierhoff/atm")
# rnaturalearth data
pacman::p_load_gh("ropenscilabs/rnaturalearthdata")
pacman::p_load_gh("ropenscilabs/rnaturalearthhires")

# Define method of table generation (whether kable or xtable) for best formatting
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')
if (is.null(doc.type)) {doc.type <- "html"}

# Determine global knitr table format
if (doc.type == "latex") {
  knitr.format <- "latex"
} else {
  knitr.format <- "html" 
}

# knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, warning = FALSE,
                      fig.align = "center", knitr.kable.NA = "-")

# Create output directories
dir_create(here(), c("Data", "Figs", "Output"))
```

```{r project-settings, include=FALSE}
# Get project name from directory
prj.name <- last(unlist(str_split(here(), "/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste0("settings_", prj.name, ".R"))]
source(here("Doc/settings", prj.settings))
```

```{r user-input}
# Set processing controls -------------------------------------------------
save.figs     <- T # Create new figures
get.db        <- T # Download data from databases (fast; generally TRUE)
get.nav       <- T # Download Lasker nav data from ERDDAP
nav.source    <- "ERDDAP" # Navigation data source: ERDDAP or SCS
get.nav.sh    <- F # Download Shimada nav data from ERDDAP
get.nav.sd    <- F # Download Saildrone nav data from ERDDAP
get.nav.ns    <- F # Process data from nearshore vessels
get.bathy     <- F # Download ETOPO1 bathymetry data in the survey footprint
extract.bathy <- F # Extract bathymetry for each nav point
resize.map    <- F # Resize map during survey; if T, uses anticipated bounds of survey area
```

```{r process-nav}
# Source code to get nav data from ERDDAP or SCS
if (nav.source == "ERDDAP") {
  source(here("Code/get_nav_erddap.R"))
} else if (nav.source == "SCS") {
  source(here("Code/get_nav_scs.R"))
}

# Source code to get nav data for Shimada from ERDDAP
if (get.nav.sh) {
  source(here("Code/get_nav_erddap_SH.R"))
  
  nav.sh <- mutate(nav, vessel.name = "SH")
  
  # Combine RL and SH nav data
  nav <- nav %>% 
    mutate(vessel.name = "RL") %>% 
    bind_rows(nav.sh)
}

# Read transect waypoints
wpts <- read_csv(here("Data/Nav", wpt.filename))

# Convert planned transects to sf; CRS = crs.geog
wpts.sf <- wpts %>% 
  filter(Type %in% wpt.types) %>% 
  st_as_sf(coords = c("Longitude","Latitude"), crs = crs.geog) %>% 
  mutate(
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type)
  )

transects.sf <- wpts.sf %>% 
  group_by(Type, Transect, Region) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING") %>% 
  ungroup() %>% 
  mutate(
    distance = round(as.numeric(st_length(.))/1852,1),
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type, '<br/>',
                     'Distance:', distance, 'nmi<br/>')
  )

# Summarise nav
mean.sog <- mean(nav$SOG)

# Set padding around data  
if (resize.map) {
  # Use nav data to resize map to survey progress
  map.bounds <- nav.paths.sf %>% 
    st_transform(crs = crs.proj) %>%
    st_bbox()  
} else {
  # Use nav data to resize map to survey progress
  map.bounds <- transects.sf %>%
    st_transform(crs = crs.proj) %>%
    st_bbox()  
}
```

```{r process-nav-nearshore}
if (get.nav.ns) {
  # Load existing nav data
  if (get.nav) {
    # Remove existing nav data
    if (exists("nav.ns")) rm(nav.ns)
    
    for (i in nav.vessels.ns) {
      if (dir_exists(file.path(here("Data/Backscatter", i)))) {
        # List all CSV files
        nav.files <- dir_ls(file.path(here("Data/Backscatter", i)),
                            regexp = nasc.pattern.cps[i],
                            ignore.case = TRUE)
        
        # Remove existing nav.vessel.ns
        if (exists("nav.vessel.ns")) rm(nav.vessel.ns)
        
        # Create or load vessel nasc data
        if (length(nav.files) > 0) {
          # Configure progress bar
          pb <- tkProgressBar("R Progress Bar", "CSV File Processing", 0, 100, 0)
          
          # Process all .CSV files
          for (ii in seq_along(nav.files)) {
            # Extract vessel nasc
            nav.vessel.ns.temp <- extract_csv(nav.files[ii]) %>% 
              mutate(vessel.name = i,
                     sounder = sounder.type[i],
                     transect = str_replace(transect, nasc.pattern.cps[i],""),
                     dist = c(0,diff(dist_m))/1000)
            
            # Combine results
            if (exists("nav.vessel.ns")) {
              nav.vessel.ns <- bind_rows(nav.vessel.ns, nav.vessel.ns.temp)
            } else {
              nav.vessel.ns <- nav.vessel.ns.temp
            }
            
            # Update the progress bar
            pb.prog <- round(ii/length(nav.files)*100)
            info <- sprintf("%d%% done", pb.prog)
            setTkProgressBar(pb, pb.prog, sprintf("CSV processing - %s (%s)", i, info), info)
          }
          
          # Close progress bar
          close(pb)
          
          # Save/load nav.vessel.ns (for debugging)
          saveRDS(nav.vessel.ns, 
                  file = here("Data/Nav",  
                              paste0("nav_vessel_", i, ".rds")))
          
          # Remove bad intervals
          nav.vessel.ns <- nav.vessel.ns %>% 
            filter(lat != 999, long != 999)
          
          # Save original transect name before modifying
          # Convert date and time to POSIXct
          nav.vessel.ns <- nav.vessel.ns %>% 
            mutate(datetime      = ymd_hms(paste(date, time), tz = "UTC"))
          
          # Combine results from different vessels
          if (exists("nav.ns")) {
            nav.ns <- bind_rows(nav.ns, nav.vessel.ns)
          } else {
            nav.ns <- nav.vessel.ns
          }
        }
      }  
    }
    
    # Convert nearshore nav to spatial
    nav.ns.sf <- st_as_sf(nav.ns, coords = c("long","lat"), crs = crs.geog)
    
    nav.ns.paths.sf <- nav.ns.sf %>% 
      group_by(vessel.name) %>% 
      summarise(do_union = FALSE) %>% 
      st_cast("LINESTRING") %>% 
      mutate(tracklength = st_length(.))
    
    #Save processed nav data
    save(nav.ns, nav.ns.sf, nav.ns.paths.sf, file = here("Data/Nav/nav_data_nearshore.Rdata"))
  } else {
    # Load nav data
    load(here("Data/Nav/nav_data_nearshore.Rdata"))
    
  }
}
```

```{r get-saildrone-nav}
source(here("Code/get_nav_saildrone.R"))
```

```{r get-bathy}
# Get bathymetry data across range of nav data (plus/minus one degree lat/long)
if (get.bathy) {
  # Get boundaries for bathymetry grid
  # From NOAA vessel
  bathy.bounds <- nav.sf %>% 
    select(geometry) 
  
  # Add Saildrone, if present
  if (exists("nav.sd.sf")) {
    bathy.bounds <- bind_rows(bathy.bounds, select(nav.sd.sf, geometry))
  }
  
  # Add nearshore, if present
  if (exists("nav.ns.sf")) {
    bathy.bounds <- bind_rows(bathy.bounds, select(nav.ns.sf, geometry))
  }
  
  # Create bounding box
  bathy.bounds <- st_bbox(bathy.bounds) 
  
  # mapview(nav.paths.sf) + mapview(nav.sd.paths.sf) + mapview(nav.ns.paths.sf) + mapview(bathy.bounds)
  
  # Download bathy grid
  noaa.bathy <- getNOAA.bathy(
    lon1 = bathy.bounds$xmin - 1, 
    lon2 = bathy.bounds$xmax + 1,
    lat1 = bathy.bounds$ymax + 1, 
    lat2 = bathy.bounds$ymin - 1, 
    resolution = 1)
  
  # Save bathy results
  save(noaa.bathy, file = paste(here("Data/GIS"), "/bathy_data_",
                                survey.name,".Rdata", sep = ""))  
} else {
  load(paste(here("Data/GIS"), "/bathy_data_",
             survey.name,".Rdata", sep = ""))
}
```

```{r summarize-results}
# Summarize NASC by date and lat/long
nav.sun <- nav %>% 
  mutate(date = date(time)) %>% 
  group_by(date) %>% 
  summarise(lat = mean(lat),
            long = mean(long)) %>% 
  as.data.frame()

# Get sunrise/sunset for each survey day
nav.daynight <- data.frame()

for (i in 1:nrow(nav.sun)) {
  tmp <- day_night(date = nav.sun$date[i], 
                   geocode = data.frame(lat = nav.sun$lat[i], lon = nav.sun$long[i]),
                   twilight = survey.twilight)
  nav.daynight <- bind_rows(nav.daynight, tmp)
}

# Format the results
nav.daynight <- nav.daynight %>% 
  mutate(sunrise = ymd_hms(paste(day, hms::as_hms(sunrise*3600))) - minutes(survey.twilight.offset),
         sunset  = sunrise + daylength*3600 + minutes(survey.twilight.offset),
         sunrise = as.character(sunrise), # convert to character to work with gather()
         sunset  = as.character(sunset)) %>% 
  select(day, sunrise, sunset) %>% 
  gather(period, time, -day) %>% 
  mutate(time    = ymd_hms(time, tz = "UTC"), # convert back to POSIX
         sun_key = as.character(time)) %>% 
  arrange(time) %>% 
  mutate(id = seq(1, nrow(.)))

# Process FSV data from ERDDAP
nav <- nav %>%
  mutate(time = ymd_hms(time),
         date = date(time),
         dist = SOG*0.51444*60/1000) %>%  # Distance in km, from SOG (in knots)
  filter(between(long, min.long, max.long), between(lat, min.lat, max.lat))

if (extract.bathy) {
  # Get nav depth and compute photoperiod
  nav.depth <- get.depth(noaa.bathy, nav$long, nav$lat, locator = F, distance = T) %>%
    rename(long = lon) %>%
    bind_cols(select(nav, time, dist)) %>%
    mutate(dist.depth = c(0, diff(dist.km))) %>%
    filter(dist.depth < 100)  %>% # Remove distant points
    mutate(depth_bin = cut(depth, c(min(depth), -200, 0), include.lowest = T, labels = F),
           id = cut(as.numeric(time), as.numeric(nav.daynight$time),
                    include.lowest = T, labels = F),
           depth_bin = case_when(
             depth_bin == 1 ~ "Deep (>200 m)",
             depth_bin == 2 ~ "Shallow (<200 m)")) %>%
    filter(!is.na(depth_bin)) %>%
    left_join(select(nav.daynight, id, period)) %>%
    mutate(day_night = case_when(
      period == "sunrise" ~ "Day",
      period == "sunset"  ~ "Night")) %>%
    mutate(pings = case_when(
      abs(depth) < 250              ~ 60*(750/abs(250)),
      between(abs(depth), 250, 750) ~ 60*(750/abs(depth)),
      abs(depth) > 750              ~ 60*(750/abs(750)))) %>% # Compute time interval
    project_df(to = crs.proj) %>% 
    arrange(desc(day_night), time) 
  
  # Save results
  save(nav.depth, file = here("Output/nav_bathy_Lasker.Rdata"))
  
} else {
  # Load extracted bathymetry
  load(here("Output/nav_bathy_Lasker.Rdata"))
}

# Summarise distance by day/night and depth
# Number of pings per km were estimated as ...
nav.summ <- nav.depth %>% 
  filter(!is.nan(dist)) %>% 
  group_by(depth_bin, day_night) %>% 
  summarise(
    dist_km  = round(sum(dist)),
    pings_ek = round(sum(pings))) %>% 
  mutate(
    dist_nmi = round(dist_km * 0.539957)) %>% 
  select(depth_bin:dist_km, dist_nmi, everything())

# Write results to file
write_csv(nav.summ, paste0(here("Output"), "/", survey.name, "_LineKilometers_", survey.vessel, ".csv"))
```

```{r summarize-results-ns}
if (exists("nav.ns")) {
  # Summarize nav by date and lat/long
  nav.sun.ns <- nav.ns %>% 
    mutate(date = date(datetime)) %>% 
    group_by(date) %>% 
    summarise(lat = mean(lat),
              long = mean(long)) %>% 
    as.data.frame() %>% 
    filter(!is.na(date))
  
  # Get sunrise/sunset for each survey day
  nav.daynight.ns <- data.frame()
  
  for (i in 1:nrow(nav.sun.ns)) {
    tmp <- day_night(date = nav.sun.ns$date[i], 
                     geocode = data.frame(lat = nav.sun.ns$lat[i], lon = nav.sun.ns$long[i]),
                     twilight = survey.twilight)
    
    nav.daynight.ns <- bind_rows(nav.daynight.ns, tmp)
  }
  
  # Format the results
  nav.daynight.ns <- nav.daynight.ns %>% 
    mutate(sunrise = ymd_hms(paste(day, hms::as_hms(sunrise*3600))) - minutes(survey.twilight.offset),
           sunset  = sunrise + daylength*3600 + minutes(survey.twilight.offset),
           sunrise = as.character(sunrise), # convert to character to work with gather()
           sunset  = as.character(sunset)) %>% 
    select(day, sunrise, sunset) %>% 
    gather(period, time, -day) %>% 
    mutate(time    = ymd_hms(time, tz = "UTC"), # convert back to POSIX
           sun_key = as.character(time)) %>% 
    arrange(time) %>% 
    mutate(id = seq(1, nrow(.)))
  
  
  # Process FSV data from ERDDAP
  nav.ns <- nav.ns %>%
    mutate(time = ymd_hms(datetime),
           date = date(datetime)) %>%  # Distance in km, from speed in
    filter(between(long, min.long, max.long), between(lat, min.lat, max.lat))
  
  if (extract.bathy) {
    # Get nav depth and compute photoperiod
    nav.depth.ns <- get.depth(noaa.bathy, nav.ns$long, nav.ns$lat, locator = F, distance = T) %>%
      rename(long = lon) %>%
      bind_cols(select(nav.ns, time, dist, vessel.name)) %>%
      mutate(dist.depth = c(0, diff(dist.km))) %>%
      filter(dist.depth < 100)  %>% # Remove distant points
      mutate(depth_bin = cut(depth, c(min(depth), -200, 0), include.lowest = T, labels = F),
             id = cut(as.numeric(time), as.numeric(nav.daynight.ns$time),
                      include.lowest = T, labels = F),
             depth_bin = case_when(
               depth_bin == 1 ~ "Deep (>200 m)",
               depth_bin == 2 ~ "Shallow (<200 m)")) %>%
      filter(!is.na(depth_bin)) %>%
      left_join(select(nav.daynight.ns, id, period)) %>%
      mutate(day_night = case_when(
        period == "sunrise" ~ "Day",
        period == "sunset"  ~ "Night")) %>%
      mutate(pings = case_when(
        abs(depth) < 250              ~ 60*(750/abs(250)),
        between(abs(depth), 250, 750) ~ 60*(750/abs(depth)),
        abs(depth) > 750              ~ 60*(750/abs(750)))) %>% # Compute time interval
      project_df(to = crs.proj) %>% 
      arrange(desc(day_night), time)
    
    # Save results
    save(nav.depth.ns, file = here("Output/nav_bathy_nearshore.Rdata"))
    
  } else {
    # Load extracted bathymetry
    load(here("Output/nav_bathy_nearshore.Rdata"))
  }
  
  # Summarise distance by day/night and depth
  # Number of pings per km were estimated as ...
  nav.summ.ns <- nav.depth.ns %>% 
    filter(!is.nan(dist), !is.na(day_night)) %>% 
    group_by(vessel.name, depth_bin, day_night) %>% 
    summarise(
      dist_km  = round(sum(dist)),
      pings_ek = round(sum(pings))) %>% 
    ungroup() %>% 
    mutate(
      dist_nmi = round(dist_km * 0.539957)) %>% 
    select(vessel.name, depth_bin:dist_km, dist_nmi, everything())
  
  # Write results to file
  write_csv(nav.summ.ns, paste0(here("Output"), "/", survey.name, "_LineKilometers_Nearshore", ".csv")) 
}
```

```{r summarize-results-sd}
if (exists("nav.sd")) {
  # Summarize NASC by date and lat/long
  nav.sun.sd <- nav.sd %>% 
    mutate(date = date(time)) %>% 
    group_by(date) %>% 
    summarise(lat = mean(lat),
              long = mean(long)) %>% 
    as.data.frame() %>% 
    filter(!is.na(date))
  
  # Get sunrise/sunset for each survey day
  nav.daynight.sd <- data.frame()
  
  for (i in 1:nrow(nav.sun.sd)) {
    tmp <- day_night(date = nav.sun.sd$date[i], 
                     geocode = data.frame(lat = nav.sun.sd$lat[i], lon = nav.sun.sd$long[i]),
                     twilight = survey.twilight)
    
    nav.daynight.sd <- bind_rows(nav.daynight.sd, tmp)
  }
  
  # Format the results
  nav.daynight.sd <- nav.daynight.sd %>% 
    mutate(sunrise = ymd_hms(paste(day, hms::as_hms(sunrise*3600))) - minutes(survey.twilight.offset),
           sunset  = sunrise + daylength*3600 + minutes(survey.twilight.offset),
           sunrise = as.character(sunrise), # convert to character to work with gather()
           sunset  = as.character(sunset)) %>% 
    select(day, sunrise, sunset) %>% 
    gather(period, time, -day) %>% 
    mutate(time    = ymd_hms(time, tz = "UTC"), # convert back to POSIX
           sun_key = as.character(time)) %>% 
    arrange(time) %>% 
    mutate(id = seq(1, nrow(.)))
  
  
  # Process FSV data from ERDDAP
  nav.sd <- nav.sd %>%
    mutate(time = ymd_hms(time),
           date = date(time),
           dist = SOG*0.51444*60/1000) %>%  # Distance in km, from speed in
    filter(between(long, min.long, max.long), between(lat, min.lat, max.lat))
  
  if (extract.bathy) {
    # Get nav depth and compute photoperiod
    nav.depth.sd <- get.depth(noaa.bathy, nav.sd$long, nav.sd$lat, locator = F, distance = T) %>%
      rename(long = lon) %>%
      bind_cols(select(nav.sd, time, dist)) %>%
      mutate(dist.depth = c(0, diff(dist.km))) %>%
      filter(dist.depth < 100)  %>% # Remove distant points
      mutate(depth_bin = cut(depth, c(min(depth), -200, 0), include.lowest = T, labels = F),
             id = cut(as.numeric(time), as.numeric(nav.daynight.sd$time),
                      include.lowest = T, labels = F),
             depth_bin = case_when(
               depth_bin == 1 ~ "Deep (>200 m)",
               depth_bin == 2 ~ "Shallow (<200 m)")) %>%
      filter(!is.na(depth_bin)) %>%
      left_join(select(nav.daynight.sd, id, period)) %>%
      mutate(day_night = case_when(
        period == "sunrise" ~ "Day",
        period == "sunset"  ~ "Night")) %>%
      mutate(pings = case_when(
        abs(depth) < 250              ~ 60*(750/abs(250)),
        between(abs(depth), 250, 750) ~ 60*(750/abs(depth)),
        abs(depth) > 750              ~ 60*(750/abs(750)))) %>% # Compute time interval
      project_df(to = crs.proj) %>% 
      arrange(desc(day_night), time)
    
    # Save results
    save(nav.depth.sd, file = here("Output/nav_bathy_Saildrone.Rdata"))
    
  } else {
    # Load extracted bathymetry
    load(here("Output/nav_bathy_Saildrone.Rdata"))
  }
  
  # Summarise distance by day/night and depth
  # Number of pings per km were estimated as ...
  nav.summ.sd <- nav.depth.sd %>% 
    filter(!is.nan(dist), !is.na(day_night)) %>% 
    group_by(depth_bin, day_night) %>% 
    summarise(
      dist_km  = round(sum(dist)),
      pings_ek = round(sum(pings))) %>% 
    ungroup() %>% 
    mutate(
      dist_nmi = round(dist_km * 0.539957)) %>% 
    select(depth_bin:dist_km, dist_nmi, everything())
  
  # Write results to file
  write_csv(nav.summ.sd, paste0(here("Output"), "/", survey.name, "_LineKilometers_Saildrone", ".csv")) 
}
```

# `r survey.name.long`(`r survey.name`)
## Summarize effort by depth and day/night

Total transit distance (km and nmi) and number of pings emitted from the multifrequency echosounders are summarized by period (day or night, based on daily sunrise and sunset time at the vessel's location) and seabed depth (greater or less than 200 m). Number of pings are estimated every 1 minute based on the seabed depth (m), where the number of pings per second is equal to 750/depth. Deeper than 750 m, the ping rate is assume to be 1 ping per second (pps). A maximum ping rate of be 3 pps is assume for depths shallower than 250 m.  

### NOAA Ships
#### Total acoustic km

```{r effort-summary}
# Print nav summary
nav.summ %>% 
  adorn_totals() %>% 
  rename(Depth            = depth_bin,
         Period           = day_night,
         "Distance (km)"  = dist_km,
         "Distance (nmi)" = dist_nmi,
         Pings            = pings_ek) %>%  
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("c"), digits = c(0),
        format.args = list(big.mark = ",")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                full_width = F) 
```

#### Transect effort only

In addition to the total kilometers, the ship often requests a summary of transect distance sampled by the ship during each leg.

```{r transect-summary}
if (file.exists(here("Data/Backscatter/nasc_all.Rdata"))) {
  # Load backscatter data
  load(here("Data/Backscatter/nasc_all.Rdata"))
  
  if (extract.bathy) {
    # Extract depth for each interval
    nasc.depth <- get.depth(noaa.bathy, nasc$long, nasc$lat, 
                            locator = F, distance = T) %>%
      rename(long = lon) 
    
    # Save results
    save(nasc.depth, file = here("Output/nasc_bathy_Lasker.Rdata"))
    
  } else {
    # Load extracted bathymetry
    load(here("Output/nasc_bathy_Lasker.Rdata"))
  }
  
  # Add depth data to nasc
  nasc$depth <- nasc.depth$depth
  
  # Re-cut legs
  nasc <- nasc %>% 
    mutate(leg = cut(as.numeric(date(datetime)), leg.breaks, labels = FALSE))
  
  # Summarize transect distance by leg
  nasc.summ <- nasc %>% 
    mutate(key = paste(transect.orig, Interval)) %>% 
    group_by(leg) %>% 
    summarise(
      Transects = n_distinct(transect),
      dist_km = n_distinct(key)/10,
      dist_nmi = dist_km * 0.539957)
  
  nav.das <- nav %>% 
    group_by(leg) %>% 
    summarise(das = n_distinct(date))
  
  nasc.summ %>% 
    adorn_totals() %>%
    rename("Leg" = leg,
           "Distance (km)"  = dist_km,
           "Distance (nmi)" = dist_nmi) %>%  
    kable(format = knitr.format, booktabs = TRUE, escape = F,
          align = c("c"),
          digits = c(0,0,0,0),
          format.args = list(big.mark = ",")) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"),
                  full_width = F) %>%
    row_spec(0, align = c("c"))
} else {
  print("No backscatter data present")
}
```

### Nearshore

```{r effort-summary-nearshore}
if (exists("nav.summ.ns")) {
  nav.summ.ns %>% 
    adorn_totals() %>% 
    rename(Vessel           = vessel.name,
           Depth            = depth_bin,
           Period           = day_night,
           "Distance (km)"  = dist_km,
           "Distance (nmi)" = dist_nmi,
           Pings            = pings_ek) %>%  
    kable(format = knitr.format, booktabs = TRUE, escape = F,
          align = c("c"),
          format.args = list(big.mark = ",")) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"),
                  full_width = F) %>%
    row_spec(0, align = c("c")) 
} else {
  print("No nearshore data.")
}
```

### Saildrone

```{r effort-summary-saildrone}
if (exists("nav.summ.sd")) {
  nav.summ.sd %>% 
    adorn_totals() %>% 
    rename(Depth            = depth_bin,
           Period           = day_night,
           "Distance (km)"  = dist_km,
           "Distance (nmi)" = dist_nmi,
           Pings            = pings_ek) %>%  
    kable(format = knitr.format, booktabs = TRUE, escape = F,
          align = c("c"),
          format.args = list(big.mark = ",")) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"),
                  full_width = F) %>%
    row_spec(0, align = c("c")) 
} else {
  print("No Saildrone data.")
}
```

```{r create-basemap, include=F}
# Configure base map options -----------------
# Import landmarks
locations <- filter(read.csv(here("Data/Map/locations.csv")), name %in% label.list) %>%
  project_df(to = crs.proj)

# Get state data
states <- ne_states(country = 'United States of America', returnclass = 'sf')
ca     <- filter(states, name == "California")

# Get countries
countries <- ne_countries(scale = "large", returnclass = "sf") %>%
  filter(subregion %in% c("Northern America","Central America"))

# Read bathy contours shapefile 
bathy <- st_read(here("Data/GIS/bathy_contours.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = Contour)

# Determine map aspect ratio and set height and width
map.aspect <- (map.bounds$xmax - map.bounds$xmin)/(map.bounds$ymax - map.bounds$ymin)
map.height <- 10
map.width  <- map.height*map.aspect

# Create base map
base.map <- get_basemap(nav.paths.sf, states, countries, locations, bathy, map.bounds, crs = crs.proj) +
  # Add scalebar
  annotation_scale(style = "ticks", location = "br", height = unit(0.15, "cm"))

if (save.figs) {
  save(base.map, file = here("Data/Map/basemap.Rdata"))  
}
```

## Map vessel nav by depth and day/night  
### _Reuben Lasker_

```{r map-daynight-bathy}
if (save.figs) {
  # Map Lasker results by depth bin
  bathy.plot <- base.map + 
    geom_point(data = nav.depth, aes(X, Y, colour = depth_bin), size = 0.5) +
    scale_colour_manual(name = "Depth", values = c("#40C270","#1C1C8A")) +
    theme(legend.position.inside = c(0,0),
          legend.justification = c(0,0),
          legend.background    = element_blank(),
          legend.key           = element_blank()) +
    ggtitle("Vessel nav by depth") 
  
  # Map results by day/night
  daynight.plot <- base.map + 
    geom_point(data = nav.depth, aes(X, Y, colour = day_night), size = 0.5) +
    scale_colour_manual(name = "Time of day", values = c("#F09F43","#211D1D")) +
    theme(legend.position.inside = c(0,0),
          legend.justification = c(0,0),
          legend.background    = element_blank(),
          legend.key           = element_blank()) +
    ggtitle("Vessel nav by day/night")
  
  # Combine plots
  bathy.photo.plot <- plot_grid(bathy.plot, 
                                daynight.plot, 
                                nrow = 1, align = "v")
  
  # Save combo plot
  ggsave(bathy.photo.plot, 
         filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_day_", survey.vessel, ".png"),
         height = map.height, width = map.width*2)
  
}

# Include figure
include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_day_", survey.vessel, ".png"))
```  

### Nearshore

```{r map-daynight-bathy-nearshore}
if (save.figs) {
  # Map Saildrone results by depth bin
  if (exists("nav.depth.ns")) {
    # Map Lasker results by depth bin
    bathy.plot.ns <- base.map + 
      geom_point(data = nav.depth.ns, aes(X, Y, colour = depth_bin), size = 0.5) +
      scale_colour_manual(name = "Depth", values = c("#40C270","#1C1C8A")) +
      theme(legend.position.inside = c(0,0),
            legend.justification = c(0,0),
            legend.background    = element_blank(),
            legend.key           = element_blank()) +
      ggtitle("Vessel nav by depth") 
    
    # Map results by day/night
    daynight.plot.ns <- base.map + 
      geom_point(data = nav.depth.ns, aes(X, Y, colour = day_night), size = 0.5) +
      scale_colour_manual(name = "Time of day", values = c("#F09F43","#211D1D")) +
      theme(legend.position.inside = c(0,0),
            legend.justification = c(0,0),
            legend.background    = element_blank(),
            legend.key           = element_blank()) +
      ggtitle("Vessel nav by day/night")
    
    # Combine plots
    bathy.photo.plot.ns <- plot_grid(bathy.plot.ns, 
                                     daynight.plot.ns, 
                                     nrow = 1, align = "v")
    
    # Save combo plot
    ggsave(bathy.photo.plot.ns, 
           filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_day_nearshore.png"),
           height = map.height, width = map.width*2)
  }
}

if (file.exists(paste0(here("Figs"), "/", survey.name, "_nav_depth_day_nearshore.png"))) {
  include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_day_nearshore.png"))
} else {
  print("No nearshore data.")
}

```

### Saildrone

```{r map-daynight-bathy-saildrone}
if (save.figs) {
  # Map Saildrone results by depth bin
  if (exists("nav.depth.sd")) {
    # Map Lasker results by depth bin
    bathy.plot.sd <- base.map + 
      geom_point(data = nav.depth.sd, aes(X, Y, colour = depth_bin), size = 0.5) +
      scale_colour_manual(name = "Depth", values = c("#40C270","#1C1C8A")) +
      theme(legend.position.inside = c(0,0),
            legend.justification = c(0,0),
            legend.background    = element_blank(),
            legend.key           = element_blank()) +
      ggtitle("Vessel nav by depth") 
    
    # Map results by day/night
    daynight.plot.sd <- base.map + 
      geom_point(data = nav.depth.sd, aes(X, Y, colour = day_night), size = 0.5) +
      scale_colour_manual(name = "Time of day", values = c("#F09F43","#211D1D")) +
      theme(legend.position.inside = c(0,0),
            legend.justification = c(0,0),
            legend.background    = element_blank(),
            legend.key           = element_blank()) +
      ggtitle("Vessel nav by day/night")
    
    # Combine plots
    bathy.photo.plot.sd <- plot_grid(bathy.plot.sd, 
                                     daynight.plot.sd, 
                                     nrow = 1, align = "v")
    
    # Save combo plot
    ggsave(bathy.photo.plot.sd, 
           filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_day_Saildrone.png"),
           height = map.height, width = map.width*2)
  }
}

if (file.exists(paste0(here("Figs"), "/", survey.name, "_nav_depth_day_Saildrone.png"))) {
  include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_day_Saildrone.png"))
} else {
  print("No Saildrone data.")
}

```

## Map vessel nav by depth (daytime only)
### _Reuben Lasker_

```{r map-daytime-bathy}
if (save.figs) {
  # Map only daytime nav by depth
  day.plot <- base.map + 
    geom_point(data = filter(nav.depth, day_night == "Day"), 
               aes(X, Y, colour = depth_bin), size = 0.5) +
    scale_colour_manual(name = "Depth", values = c("#40C270", "#1C1C8A")) +
    theme(legend.position.inside = c(0,0),
          legend.justification = c(0,0),
          legend.background    = element_blank(),
          legend.key           = element_blank()) +
    ggtitle("Daytime vessel nav by depth")
  
  # Save daytime only plot
  ggsave(day.plot, 
         filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_", survey.vessel, ".png"),
         height = map.height, width = map.width)
}

include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_", survey.vessel, ".png"))
```

### Nearshore

```{r map-daytime-bathy-nearshore}
if (exists("nav.depth.ns")) {
  if (save.figs) {
    # Map only daytime nav by depth
    day.plot.ns <- base.map + 
      geom_point(data = filter(nav.depth.ns, day_night == "Day"), 
                 aes(X, Y, colour = depth_bin), size = 0.5) +
      scale_colour_manual(name = "Depth", values = c("#40C270", "#1C1C8A")) +
      theme(legend.position.inside = c(0,0),
            legend.justification = c(0,0),
            legend.background    = element_blank(),
            legend.key           = element_blank()) +
      ggtitle("Daytime vessel nav by depth")
    
    # Save daytime only plot
    ggsave(day.plot.ns, 
           filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_nearshore.png"),
           height = map.height, width = map.width)
  }
}  

if (file.exists(paste0(here("Figs"), "/", survey.name, "_nav_depth_nearshore.png"))) {
  include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_nearshore.png"))
} else {
  print("No nearshore data.")
}  
```

### Saildrone

```{r map-daytime-bathy-saildrone}
if (exists("nav.depth.sd")) {
  if (save.figs) {
    # Map only daytime nav by depth
    day.plot.sd <- base.map + 
      geom_point(data = filter(nav.depth.sd, day_night == "Day"), 
                 aes(X, Y, colour = depth_bin), size = 0.5) +
      scale_colour_manual(name = "Depth", values = c("#40C270", "#1C1C8A")) +
      theme(legend.position.inside = c(0,0),
            legend.justification = c(0,0),
            legend.background    = element_blank(),
            legend.key           = element_blank()) +
      ggtitle("Daytime vessel nav by depth")
    
    # Save daytime only plot
    ggsave(day.plot.sd, 
           filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_Saildrone.png"),
           height = map.height, width = map.width)
  }
}  

if (file.exists(paste0(here("Figs"), "/", survey.name, "_nav_depth_Saildrone.png"))) {
  include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_Saildrone.png"))
} else {
  print("No Saildrone data.")
}  
```

## Summarize trawl data

```{r import-trawl-data, include=FALSE}
if (get.db) {
  if (trawl.source == "SQL") {
    # Configure ODBC connection to TRAWL database
    trawl.con  <- dbConnect(odbc(), 
                            Driver = "SQL Server", 
                            Server = "161.55.235.187", 
                            Database = "Trawl", 
                            Trusted_Connection = "True")
  } else if (trawl.source == "Access") {
    trawl.con  <- dbConnect(odbc(), 
                            Driver = "Microsoft Access Driver (*.mdb, *.accdb)", 
                            DBQ = file.path(here("Data/Trawl"),trawl.db.access))
  }
  
  # Import trawl database tables
  catch.all	     <- tbl(trawl.con, "Catch") %>% collect()
  haul.all       <- tbl(trawl.con, "Haul") %>% collect()
  lengths.all    <- tbl(trawl.con, "Specimen") %>% collect()
  if (dbExistsTable(trawl.con, "LengthFrequency"))
    lengthFreq.all <- tbl(trawl.con,"LengthFrequency") %>% collect()
  spp.codes      <- tbl(trawl.con, "SpeciesCodes") %>% collect()
  
  # Close database channel
  dbDisconnect(trawl.con)
  
  # Replace round herring in the database
  spp.codes$scientificName[spp.codes$species == 161743] <- "Etrumeus teres"
  
  # Save imported database data to .Rdata file
  if (exists("lengthFreq.all")) {
    save(catch.all, haul.all, lengths.all, spp.codes, lengthFreq.all, 
         file = here("Data/Trawl/trawl_data.Rdata"))
  } else {
    save(catch.all, haul.all, lengths.all, spp.codes,  
         file = here("Data/Trawl/trawl_data.Rdata"))
  }
  
  # Save species codes
  save(spp.codes, file = here("Output/species_codes.Rdata"))
  write_csv(spp.codes, here("Output/species_codes.csv"))
} else {
  # Load previously imported database data
  load(here("Data/Trawl/trawl_data.Rdata"))
}
``` 

```{r collect-trawl-data}
if (get.db) {
  # Source script to collect data from trawl database
  source(here("Code/collect_trawl_database.R"))
  
} else {
  # Load trawl data
  load(here("Data/Trawl/trawl_data_raw.Rdata"))
  
}
```

```{r format-trawl-data}
# Source script to format data from trawl database
source(here("Code/format_trawl_database.R"))
```

```{r process-haul-data}
# Select bad trawls
haul.bad <- haul.all %>% 
  filter(trawlPerformance %in% trawl.performance) 

# Get only hauls from current survey
haul <- filter(haul.all, cruise %in% cruise.name) %>% 
  filter(!collection %in% haul.bad$collection) %>% 
  mutate(duration = difftime(haulBackTime, equilibriumTime, units = "mins"), # Calculate duration
         cluster  = cumsum(c(0, diff(equilibriumTime)) > 12) + 1) # Assign cluster

# Find midpoint of each haul as the mean lat/lon
haul.mid <- haul %>% 
  group_by(cluster, haul) %>% 
  summarise(
    lat  = mean(c(startLatDecimal, stopLatDecimal)),
    long = mean(c(startLongDecimal, stopLongDecimal))) 

# Find midpoint of each haul cluster as the average of haul midpoints
cluster.mid <- haul.mid %>% 
  group_by(cluster) %>% 
  summarise(
    lat  = mean(lat),
    long = mean(long))
```

```{r process-trawl-haul-data}
# Filter haul data for current survey
haul <- haul.all %>% 
  select(cruise, ship, haul, collection, startLatDecimal, startLongDecimal, 
         stopLatDecimal, stopLongDecimal, equilibriumTime, haulBackTime, 
         trawlPerformance, season, notes) %>% 
  filter(cruise %in% cruise.name & ship %in% cruise.ship) %>%
  # Manually remove hauls
  filter(!haul %in% haul.rm) %>% 
  # Calculate haul duration
  mutate(duration = difftime(haulBackTime, equilibriumTime, units = "mins")) %>% 
  # Remove bad trawls
  filter(!trawlPerformance %in% trawl.performance) %>%
  filter(!haul %in% trawl.haul.exclude) %>%
  # Assign cluster based on yearday
  mutate(cluster = cumsum(c(0, diff(equilibriumTime)) > 12) + 1,
         sample.type = "Trawl") 

# Filter catch data for current survey
catch <- catch.all %>% 
  left_join(select(spp.codes, species, scientificName, commonName)) %>% 
  left_join(select(haul, haul, equilibriumTime, startLatDecimal, startLongDecimal)) %>% 
  filter(cruise %in% cruise.name & ship %in% cruise.ship & 
           netSampleType == 'codend') %>% 
  inner_join(select(haul, haul, cluster)) %>% 
  mutate(key = paste(haul, scientificName),
         sample.type = "Trawl")

# Find midpoint of each haul as the mean lat/lon
haul.mid <- haul %>% 
  group_by(cluster, haul, sample.type) %>% 
  summarise(
    lat  = mean(c(startLatDecimal, stopLatDecimal)),
    long = mean(c(startLongDecimal, stopLongDecimal)))

# Convert to sf for plotting
haul.mid.sf <- haul.mid %>% 
  mutate(label = paste("Haul", haul)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

# Convert haul paths and midpoints to sf; CRS = crs.geog
# Create haul paths from starts and ends
haul.paths <- select(haul, haul, lat = startLatDecimal, long = startLongDecimal) %>% 
  bind_rows(select(haul, haul, lat = stopLatDecimal, long = stopLongDecimal)) %>% 
  arrange(haul) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  group_by(haul) %>% 
  summarise(do_union = FALSE) %>% 
  st_cast("LINESTRING") 

# Find midpoint of each haul cluster as the average of haul midpoints
cluster.mid <- haul.mid %>% 
  group_by(cluster, sample.type) %>% 
  summarise(
    lat  = mean(lat),
    long = mean(long)) %>% 
  ungroup() %>% 
  project_df(to = crs.proj)

# Convert to sf for plotting
cluster.mid.sf <- cluster.mid %>% 
  mutate(label = paste("Cluster", cluster)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 
```  

### GPS data for each haul 

```{r trawl-haul-stats}
# Output haul data to CSV
haul %>% 
  select(haul, datetime = equilibriumTime, startLatDecimal, startLongDecimal,
         stopLatDecimal, stopLongDecimal) %>% 
  write_csv(here("Output/haul_table_EC-ITA.csv"))

haul %>% 
  select(haul, datetime = equilibriumTime, startLatDecimal, startLongDecimal,
         stopLatDecimal, stopLongDecimal) %>%  
  kable(format = knitr.format, booktabs = TRUE, escape = F,
        align = c("c"), digits = c(4),
        format.args = list(big.mark = ",")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                full_width = F) %>% 
  scroll_box(height = "500px") 
```

### Detailed catch and weight for each haul 

```{r trawl-catch-stats}
# Output catch data to CSV
catch %>% 
  select(haul, datetime = equilibriumTime, startLatDecimal, startLongDecimal,
         scientificName, commonName, totalWeight, totalNum) %>% 
  arrange(haul, desc(totalWeight)) %>% 
  write_csv(here("Output/catch_table_EC-ITA.csv"))

catch %>% 
  select(haul, datetime = equilibriumTime, startLatDecimal, startLongDecimal,
         scientificName, commonName, totalWeight, totalNum) %>% 
  arrange(haul, desc(totalWeight)) %>%  
  kable(format = knitr.format, booktabs = TRUE, escape = F,
        align = c("c"), digits = c(4),
        format.args = list(big.mark = ",")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                full_width = F) %>% 
  scroll_box(height = "500px") 
```


