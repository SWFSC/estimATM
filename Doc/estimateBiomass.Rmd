---
title: "Estimate CPS biomass from Acoustic-Trawl Surveys"
author: "Kevin L. Stierhoff (Maintainer), Juan P. Zwolinski, and David A. Demer"
date: '`r format(Sys.time(), format = "%F %T", usetz = TRUE)`'
csl: csl/ices-journal-of-marine-science.csl
css: css/ast.css
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
  bookdown::pdf_document2:
    toc: yes
    includes:
      in_header: yaml/header.tex
  bookdown::word_document2:
    reference_docx: template/report_template_Rmarkdown.docx
    pandoc_args: [
     "--filter", "yaml/pandoc_newpage_filter.R"
     ]
bibliography: bib/ast_bib.bib
editor_options: 
  chunk_output_type: inline
---  

```{r load-libraries-functions, error=FALSE, message=FALSE, warning=FALSE, echo=FALSE}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,swfscMisc,reshape2,tcltk,lubridate,sp,rgeos,readxl,
               knitr,maps,geosphere,Hmisc,ggrepel,png,cowplot,forecast,xts,
               RSQLite,geoR,kableExtra,devtools,scatterpie,marmap,magick,
               beepr,rnaturalearth,shadowtext,here,leaflet,leafem,htmltools,
               leaflet.extras,maptools,mapview,photobiology,fs,plotly,
               concaveman,DT,xml2,glue,lwgeom,DBI,odbc,bookdown,sf,ggnewscale,
               rworldmap,rworldxtra,data.table,stplanr,ggspatial,htmlwidgets)

# Install and load required packages from Github -------------------------------
# surveyR
pacman::p_load_gh("kstierhoff/surveyR")
pacman::p_load_gh("kstierhoff/atm")
# rnaturalearth data
pacman::p_load_gh("ropenscilabs/rnaturalearthdata")
pacman::p_load_gh("ropenscilabs/rnaturalearthhires")
```

```{r knitr-options,echo=FALSE}
# Define method of table generation (whether kable or xtable) for best formatting
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')
doc.name <- knitr::current_input()
if (is.null(doc.type)) {doc.type <- "html"}
if (is.null(doc.name)) {doc.name <- "estimateBiomass.Rmd"}

# Set global knitr chunk options
if (.Platform$OS.type == "unix") {
  # Do not specify Cairo device for MacOS
  knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, cache = FALSE,
                        fig.align = 'center', dev = "png", dpi = 150)
} else {
  knitr::opts_chunk$set(echo = FALSE, warning = FALSE, message = FALSE, cache = FALSE,
                        fig.align = 'center', dev = "png", dpi = 150,
                        dev.args = list(type = "cairo"))
}

# determine global knitr table format
if (doc.type == "latex") {
  knitr.format <- "latex"
} else {
  knitr.format <- "html" 
}
```

```{r project-info, include=FALSE}
# Get session.info to include in document
session.info <- session_info()

# Get project name from directory
prj.name <- last(unlist(str_split(here(),"/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste0("settings_", prj.name, ".R"))]
source(here("Doc/settings", prj.settings))
```

```{r user-controls}
# Processing controls (T/F) ---------------------------------------------------
### Usually T
get.db            <- T # Download data from databases (fast; generally TRUE)
get.nav           <- T # Download primary vessel nav data from ERDDAP
nav.source        <- "ERDDAP" # Navigation data source: ERDDAP or SCS
get.nav.sd        <- T # Download Saildrone nav data from ERDDAP
get.nav.sh        <- T # Download NOAA Ship nav data
copy.files        <- F # Copy data files to local directory 
process.csv       <- T # Process Echoview files
save.figs         <- F # Draw new figures and maps
download.hab      <- F # Download habitat map
process.scs       <- T # Process SCS data 

do.bootstrap      <- T # Generate bootstrap estimates

### Sometimes F
do.imap           <- T # Create interactive Leaflet map
save.imap         <- F # Save Leaflet maps
overwrite.files   <- T # Overwrite files (TRUE if files have changed)
overwrite.csv     <- T # Overwrite CSV files (TRUE if files have changed)
process.csv.all   <- F # Process all acoustic backscatter files (F = new files only)
process.csv.krill <- T # Process krill backscatter data
process.cal       <- T # Process calibration results
process.ctd       <- F # Process CTD and UCTD casts
copy.bib          <- F # Copy bibliography files (requires connection to AST2)
match.intervals   <- F # Match intervals for comparing EK60 and EK80
get.bathy         <- F # Extract ETOPO1 bathymetry data in the survey footprint
resize.map        <- F # Resize map during survey; if T, uses anticipated bounds of survey area
```

```{r create-dirs}
dir_create(here(), c("Code","Data", "Doc", "Figs", "Images", "Output", "References", "Simulation"))
```

```{r at-methods-overview, child='Background/ATM_Methods.Rmd', eval=FALSE}

```

# Project information and configuration  
This report presents results from the **`r survey.name.long` (`r survey.name`)**.  

The results were generated using R and Rstudio:  

* `r session.info[["platform"]]$version` 
* Last run: `r session.info[["platform"]]$date`

## Controls and Settings

Processing controls and survey-specific settings are configured here: `here("Doc/settings")`. The settings file is automatically identified based on the name of the directory in which the .Rproj file is stored (in this case, `r here()`). For this analysis, **`r prj.settings`** is used. More information about the settings file is below.  

## Processing loop controls

Options in this section of the settings file control the execution of the various code chunks. All chunks should usually be run (i.e., controls  <- `T`) the first time to copy all necessary data files, import data from databases, generate maps and figures, estimate abundance and biomass, etc. Subsequent processing may be sped-up by setting some controls to `F` if source data or analysis code has not changed.

### Survey-specific settings  

To more easily configure processing for different surveys and distribute updated code, the settings file is also used to configure survey-specific settings for each survey.  There are many settings, all of which should be reviewed at the start of each survey analysis.

## File handling  

Files are copied locally for processing to avoid slow results when working across the network (especially from remote locations or at sea). Controls in the User Settings section (above) determine whether files are copied locally (usually `TRUE` during the first run) and whether files are overwritten. If files are known to have changed, set `overwrite.files <- TRUE` to overwrite files already present, else files already present will be skipped and only new files copied to the local directory. If files have not changed, set `copy.files <- FALSE` to speed processing (`overwrite.files` will be ignored and may be left set to `TRUE`).

```{r copy-files,include=FALSE}
# Copy bibliography and CSL files -------------------------------------------------------
if (copy.bib) {
  file_copy("//swc-storage1.nmfs.local/AST1/LITERATURE/Rmarkdown/csl/ices-journal-of-marine-science.csl",
            here("Doc/csl"), overwrite = TRUE)
  file_copy("//swc-storage1.nmfs.local/AST1/LITERATURE/Rmarkdown/bib/ast_bib.bib",
            here("Doc/bib"), overwrite = TRUE)    
}

if (copy.files) {
  # Create data directories
  dir_create(here("Data", c("Backscatter", "Calibration", "CTD", "CUFES", "Trawl", "UCTD")))
  dir_create(here("Data/Backscatter", nasc.vessels))
  
  # Copy trawl Access database
  haul.db <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/HAUL"),
                    regexp = trawl.db.access)
  
  file_copy(haul.db, here("Data/Trawl"), overwrite = overwrite.files)
  
  # Copy CUFES files
  cufes.file <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/CUFES"), 
                       regexp = cufes.db.sqlite)
  
  file_copy(cufes.file, here("Data/CUFES"), overwrite = overwrite.files)
  
  # Copy CSV files for CPS
  pb <- tkProgressBar("R Progress Bar", "CSV File Copying", 0, 100, 0)
  
  for (d in seq_along(nasc.vessels)) {
    # Get vessel name
    dd <- nasc.vessels[d]
    
    # List CSV files for CPS and krill
    csv.files.cps <- dir_ls(file.path(survey.dir[dd], 
                                      nasc.dir[dd]), 
                            regexp = nasc.pattern.cps[dd],
                            recurse = nasc.recurse[dd],
                            ignore.case = TRUE)
    
    csv.files.krill <- dir_ls(file.path(survey.dir[dd], 
                                        nasc.dir[dd]), 
                              regexp = nasc.pattern.krill[dd],
                              recurse = nasc.recurse[dd],
                              ignore.case = TRUE)
    
    # Copy CSV files
    if (overwrite.csv) {
      # Copy all files
      file_copy(csv.files.cps, here("Data/Backscatter", dd), 
                overwrite = overwrite.csv)
      
      file_copy(csv.files.krill, here("Data/Backscatter", dd), 
                overwrite = overwrite.csv)
    } else {
      # List existing files
      files.cps <- path_file(dir_ls(here("Data/Backscatter", dd),
                                    regexp = nasc.pattern.cps[dd],
                                    recurse = nasc.recurse[dd],
                                    ignore.case = TRUE))
      
      files.krill <- path_file(dir_ls(here("Data/Backscatter", dd),
                                      regexp = nasc.pattern.krill[dd],
                                      recurse = nasc.recurse[dd],
                                      ignore.case = TRUE))
      
      # Copy new files only
      file_copy(str_subset(csv.files.cps, files.cps, negate = TRUE), 
                here("Data/Backscatter", dd))
      
      file_copy(str_subset(csv.files.krill, files.krill, negate = TRUE), 
                here("Data/Backscatter", dd))
    }
    
    # Update the progress bar
    pb.prog <- round(d/length(nasc.vessels)*100)
    info <- sprintf("%d%% done", pb.prog)
    setTkProgressBar(pb, pb.prog, sprintf("CSV Copying - (%s)", info), info)
  }
  
  close(pb)
  
  # Copy UCTD data ------------------------------------
  # Location of header files on survey directory
  uctd.hdr <- dir_ls(uctd.dir, regexp = uctd.hdr.pattern) %>% 
    path_filter(regexp = "_processed", invert = TRUE)
  
  # Copy files to plotCTD directory
  file_copy(uctd.hdr, here("Data/UCTD"), 
            overwrite = overwrite.files)
  
  # Location of processed UCTD files on survey directory
  uctd.proc <- dir_ls(uctd.dir, regexp = uctd.cast.pattern) %>% 
    path_filter(regexp = "_processed")
  
  # Copy files to plotCTD directory
  file_copy(uctd.proc, here("Data/UCTD"), 
            overwrite = overwrite.files)
  
  # Copy CTD data -------------------------------------
  # List raw CTD ASCII files
  ctd.hdr <- dir_ls(ctd.dir, regexp = ctd.hdr.pattern) %>% 
    path_filter(regexp = "_processed", invert = TRUE)
  
  # Copy files to plotCTD directory
  file_copy(ctd.hdr, here("Data/CTD"), 
            overwrite = overwrite.files)
  
  # Location of processed CTD files on survey directory
  ctd.proc <- dir_ls(ctd.dir, regexp = ctd.cast.pattern) %>% 
    path_filter(regexp = "_processed")
  
  # Copy files to plotCTD directory
  file_copy(ctd.proc, here("Data/CTD"),
            overwrite = overwrite.files)
}
```  

## Get habitat map  

Potential sardine habitat maps for the survey period are downloaded and assembled from the SWFSC website [link](http://swfscdata.nmfs.noaa.gov/AST/sardineHabitat).  

```{r download-habitat-maps}
if (download.hab) {
  source(here("Code/plot_sardine_habitat.R"))
}

if(file.exists(here("Figs/fig_habitat_map.png"))) {
  include_graphics(here("Figs/fig_habitat_map.png"))
} else {
  cat("No sardine habitat map available.")
}
```

# Process vessel data  

Vessel (e.g., lat/long, speed-over-ground, heading, etc.) and underway oceanographic data are available for all NOAA FSVs from ERDDAP in "near real time" during surveys (generally with a ~1 d lag, assuming an internet connection is available) or quality-assured (generally after the completion of survey legs). These data are logged continuously and averaged over 1-minute intervals. These data are relatively error-free and adhere to a strict format and are, therefore, more reliably and easily processed than the SCS event log (.elg) files provided to the Chief Scientist following a survey. Date ranges and desired variables are configured in the **`settings*.R`** files, and are used to assemble the URL used to download the data from ERDDAP.

```{r process-nav, message=FALSE, warning=FALSE, include=FALSE}
# Source code to get nav data for the primary survey vessel from ERDDAP or SCS
if (nav.source == "ERDDAP") {
  source(here("Code/get_nav_erddap.R"))
} else if (nav.source == "SCS") {
  source(here("Code/get_nav_scs.R"))
}

# Source Carranza nav data for summer 2021
if (survey.name %in% c("2107RL")) {
  source(here("Code/get_nav_carranza.R"))
}

# Source code to get nav data for Shimada from ERDDAP
# TRUE for 
source(here("Code/get_nav_saildrone.R"))

if (get.nav.sh) {
  source(here("Code/get_nav_erddap_SH.R"))
}

# Read transect waypoints
wpts <- read_csv(here("Data/Nav", wpt.filename), lazy = FALSE) %>% 
  rename(lat = Latitude, long = Longitude) %>% 
  project_df(to = crs.proj)

wpts.sf <- wpts %>% 
  filter(Type %in% wpt.types) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  mutate(
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type)
  )

if(is.null(wpts.sf$Region)) wpts.sf$Region = "All"

# Create transect lines from waypoint files and add line bearing
transects.sf <- wpts.sf %>% 
  group_by(Type, Transect, Region) %>% 
  summarise(do_union = FALSE) %>% 
  st_cast("LINESTRING") %>% 
  ungroup() %>% 
  mutate(distance = round(as.numeric(st_length(.))/1852,1),
         brg      = 360 + stplanr::line_bearing(.),
         label    = paste("Transect", Transect),
         popup    = paste('<b>Transect:</b>', Transect, Type, '<br/>',
                          'Distance:', distance, 'nmi<br/>')) 

st_write(transects.sf, here("Output/planned_transects.shp"), 
         delete_layer = TRUE)

# Create gps.csv file from nav to replace missing data in Echoview
nav.gps <- nav %>% 
  mutate(GPS_date = format(time, format = "%F"),
         GPS_time = format(time, format = "%T")) %>% 
  select(GPS_date, GPS_time, latitude = lat, longitude = long)

write_csv(nav.gps, here("Output/nav.gps.csv"))

# Get most recent vessel position for plotting
nav.now <- tail(nav, 1) %>%
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  mutate(label = paste("Last position:", time, "UTC"),
         popup = paste0('<b>Vessel name: </b>', survey.vessel, '<br/>',
                        '<b>Last position: </b>', time, ' UTC<br/>'))
```

```{r configure-base-map, include=FALSE}
# Get map data -------------------------------
# Import landmarks
locations <- filter(read.csv(here("Data/Map/locations.csv")), name %in% label.list) %>% 
  project_df(to = crs.proj)

# Get land features --------------------------
# Get state data
states <- ne_states(country = 'United States of America', returnclass = 'sf')
ca     <- filter(states, name == "California")

# Get countries
countries <- ne_countries(scale = "large", returnclass = "sf") %>%
  filter(subregion %in% c("Northern America","Central America"))

# Read bathy contours shapefile 
bathy <- st_read(here("Data/GIS/bathy_contours.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = Contour)

# Read isoline
bathy_5m_line <- st_read(here("Data/GIS/bathy_us_wc_5m.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = CONTOUR)

# Read 5m bathymetry points shapefile
bathy_5m_points <- st_read(here("Data/GIS/isobath_5m_final.shp"))

# Read 5m bathymetry polygon
bathy_5m_poly <- bathy_5m_points %>% 
  summarise(do_union = FALSE) %>% 
  st_cast("POLYGON") %>% 
  st_make_valid()

# Read 20m bathymetry polygon
bathy_20m_poly <- st_read(here("Data/GIS/bathy_20m_polygon.shp"))

# Create a reduced coastline for nearshore point estimation
bathy_5m_df <- bathy_5m_points %>%
  mutate(
    long = as.data.frame(st_coordinates(.))$X,
    lat = as.data.frame(st_coordinates(.))$Y) %>% 
  st_set_geometry(NULL)

write_csv(bathy_5m_df, here("Data/GIS/bathy_5m_final.csv"))

# Set padding around data  
if (resize.map) {
  # Use nav data to resize map to survey progress
  map.bounds <- nav.sf %>% 
    st_transform(crs = crs.proj) %>%
    st_bbox() 
} else {
  if (survey.name %in% c("2107RL")) {
    # Use combined planned transects
    map.bounds <- transects.jcf %>% 
      select(Type) %>% 
      bind_rows(transects.sf) %>% 
      st_transform(crs = crs.proj) %>%
      st_bbox()
  } else {
    # Use planned transects
    map.bounds <- transects.sf %>%
      st_transform(crs = crs.proj) %>%
      st_bbox()
  }
}

# Determine map aspect ratio and set height and width
map.aspect <- (map.bounds$xmax - map.bounds$xmin)/(map.bounds$ymax - map.bounds$ymin)
map.width  <- map.height*map.aspect

# Create base map
base.map <- get_basemap(nav.paths.sf, states, countries, locations, bathy, map.bounds, crs = crs.proj)

# Create base map for inset maps
base.map.bw <- ggplot() +
  # Plot bathymetry contours
  geom_sf(data = bathy, colour = "gray90") +
  # Plot high-res land polygons
  geom_sf(data = countries, fill = "gray90", color = "gray50") +
  geom_sf(data = states, fill = "gray90", colour = "gray50") +
  # Format axes and titles
  xlab("Longitude") + ylab("Latitude") + 
  coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
           xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
           ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"]))) +
  theme_bw() + 
  theme(axis.text.x  = element_blank(),
        axis.text.y  = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank())

# Save the base map
ggsave(base.map,file = here("Figs/fig_basemap.png"), 
       height = map.height, width = map.width)

ggsave(base.map.bw,
       file = here("Figs/fig_basemap_bw.png"), 
       height = map.height, width = map.width)

save(base.map, base.map.bw, file = here("Data/Map/basemap.Rdata"))
```  

# Map survey plan  

(ref:map-survey-plan) Planned compulsory (solid black lines) and adaptive (dashed red lines) transect lines sampled by _`r survey.vessel`_; offshore extensions to compulsory acoustic transects sampled by USVs (dashed green lines); and nearshore transect lines sampled by USVs and industry vessels (solid magenta lines). Isobaths (light gray lines) are placed at 50, 200, 500, and 2,000 m (or approximately 25, 100, 250, and 1,000 fathoms).

```{r map-survey-plan,fig.cap='(ref:map-survey-plan)'}
# Map planned transects
if (!survey.name %in% c("2107RL","2207RL")) {
  # Create map for surveys not in Mexico
  survey.plan <- base.map +    
    geom_sf(data = transects.sf, aes(colour = Type, linetype = Type), 
            show.legend = "line") +
    scale_colour_manual("Type", 
                        values = wpt.colors) +
    scale_linetype_manual("Type", 
                          values = wpt.linetypes) +
    coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
} else {
  # Create map for surveys in Mexico
  survey.plan <- base.map +    
    geom_sf(data = transects.sf, aes(colour = Type, linetype = Type), 
            show.legend = "line") +
    geom_sf(data = transects.jcf, aes(colour = Type, linetype = Type), 
            show.legend = "line") +
    scale_colour_manual("Type", 
                        values = wpt.colors) +
    scale_linetype_manual("Type", 
                          values = wpt.linetypes) +
    coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
}

# save survey plan map
ggsave(here("Figs/fig_survey_plan.png"), survey.plan,
       height = map.height, width = map.width)

if (survey.name %in% c("1707RL")) {
  # Set limit of Lisa Marie transects
  map.bounds.lm <- transects.sf %>% 
    filter(between(line, 85, 104)) %>% 
    st_transform(crs.proj) %>%
    st_bbox()
  
  # Map planned transects
  survey.plan.lm <- survey.plan + 
    coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
             xlim = c(map.bounds.lm["xmin"], map.bounds.lm["xmax"]), 
             ylim = c(map.bounds.lm["ymin"], map.bounds.lm["ymax"])) 
  
  # save survey plan map
  ggsave(here("Figs/fig_survey_plan_LisaMarie.png"), survey.plan.lm, 
         height = 7, width = 3.2)
  
  # Make composite map
  survey.plan.composite <- ggdraw() +
    draw_plot(survey.plan, 0,0,1,1,) +
    draw_plot(survey.plan.lm, 0.5, 0.5, 0.45, 0.3)
  
  # Save composite map
  ggsave(survey.plan.composite, 
         filename = here("Figs/fig_survey_plan_composite.png"),
         height = map.height, width = map.width)
}

# Include map
include_graphics(here("Figs/fig_survey_plan.png"))
```

# Process backscatter data
## Read and summarize CSV files from Echoview  

For each .CSV file produced during Echoview processing, data within each `r bin.length`-m long interval are vertically integrated every `r bin.depth` m (down to 100 m, then at 150 and 250 m) for each vessel. If the CTD.app has been used to define the stop integration depth, it is added, else `r nasc.depth.cps`` is used. Transect names are extracted from .CSV file names, short transects are excluded, and transect numbers are assigned.

```{r process-backscatter}
if (process.csv) {
  if (!process.csv.all) {
    # Load already processed CSV files 
    if (file.exists(here("Output/processed_csv.Rdata"))) {
      load(here("Output/processed_csv.Rdata"))
    }
    
    # Load already processed backscatter data
    load(here("Data/Backscatter/nasc_all.Rdata"))
  }
  
  # Process CSV files for each vessel
  for (i in nasc.vessels) {
    # List all CSV files
    nasc.files <- dir_ls(file.path(here("Data/Backscatter", i)),
                         regexp = nasc.pattern.cps[i],
                         ignore.case = TRUE)
    
    if (!process.csv.all) {
      # List only new CSV files
      nasc.files <- nasc.files[!fs::path_file(nasc.files) %in% processed.csv]
      
      # Load already processed vessel NASC data
      if (file.exists(here("Data/Backscatter", i, paste0("nasc_vessel_", i, "_RAW.rds")))) {
        nasc.vessel <- readRDS(here("Data/Backscatter", i, paste0("nasc_vessel_", i, "_RAW.rds")))
      }
    } else {
      # Remove existing nasc.vessel
      if (exists("nasc.vessel")) rm(nasc.vessel)
    }
    
    # Create or load vessel nasc data
    if (length(nasc.files) > 0) {
      # Configure progress bar
      pb <- tkProgressBar("R Progress Bar", "CSV File Processing", 0, 100, 0)
      
      # Process all .CSV files
      for (ii in seq_along(nasc.files)) {
        # Extract vessel nasc
        nasc.vessel.temp <- extract_csv(nasc.files[ii]) %>% 
          mutate(vessel.name = i,
                 sounder = sounder.type[i],
                 transect = str_replace(transect, nasc.pattern.cps[i],""))
        
        # Combine results
        if (exists("nasc.vessel")) {
          nasc.vessel <- bind_rows(nasc.vessel, nasc.vessel.temp)
        } else {
          nasc.vessel <- nasc.vessel.temp
        }
        
        # Update the progress bar
        pb.prog <- round(ii/length(nasc.files)*100)
        info <- sprintf("%d%% done", pb.prog)
        setTkProgressBar(pb, pb.prog, sprintf("CSV processing - %s (%s)", i, info), info)
      }
      
      # Close progress bar
      close(pb)
      
      # Save/load nasc.vessel (for debugging)
      saveRDS(nasc.vessel, 
              file = here("Data/Backscatter", i, 
                          paste0("nasc_vessel_", i, "_RAW.rds")))
      
      processed.csv.vessel <- unique(fs::path_file(nasc.vessel$filename))
      
      # Get intervals with bad lat/long values
      bad.nasc <- filter(nasc.vessel, lat == 999, long == 999) %>% 
        arrange(filename, datetime)
      
      if (nrow(bad.nasc) > 0) {
        write_csv(bad.nasc, here("Data/Backscatter", i, 
                                 paste0("nasc_vessel_", i, "_Bad.csv")))  
      }
      
      # Remove bad intervals
      nasc.vessel <- nasc.vessel %>% 
        filter(lat != 999, long != 999)
      
      # Save original transect name before modifying
      # Convert date and time to POSIXct
      nasc.vessel <- nasc.vessel %>% 
        mutate(datetime      = ymd_hms(paste(date, time), tz = "UTC"),
               leg = cut(as.numeric(date(datetime)), leg.breaks, labels = FALSE),
               transect.orig = transect,
               id = seq_along(datetime))
      
      if (i == "SD") {
        # Set Saildrone number as vessel name
        nasc.vessel <- nasc.vessel %>% 
          mutate(vessel.orig = as.factor(str_extract(filename, "SD\\d{4}")),
                 id = seq_along(Interval)) %>% 
          filter(fct_match(vessel.orig, paste("SD", sd.numbers, sep = ""))) %>% 
          filter(between(long, min.long, max.long)) %>% 
          filter(between(lat,  min.lat,  max.lat))
      }
      
      # Remove numbers from transect names (e.g., 105-1, 105-2, etc.)
      if (strip.tx.nums[i]) {
        nasc.vessel$transect <- gsub(tx.num.pattern[i], "", nasc.vessel$transect)
      }
      
      # Remove letters from transect names (e.g., 105A, 105B, etc.)
      if (strip.tx.chars[i]) {
        nasc.vessel$transect <- gsub(tx.char.pattern[i], "", nasc.vessel$transect)  
      }
      
      # Remove transit data
      if (rm.transit[i]) {
        # Filter based on transit pattern
        nasc.transit <- nasc.vessel %>% 
          # Remove based on transit pattern
          filter(str_detect(transect.orig, nasc.pattern.transit[i])) %>%
          # Remove inter-transects e.g., 102.5
          filter(!str_detect(transect.orig, "\\d\\.5"))
        
        if (nrow(nasc.transit) > 0) {
          saveRDS(nasc.transit, 
                  file = here("Data/Backscatter", i, 
                              paste0("nasc_vessel_", i, "_transit.rds")))
          
          # Filter transit
          nasc.vessel <- nasc.vessel %>% 
            # Remove based on transit pattern
            filter(str_detect(transect.orig, nasc.pattern.transit[i], negate = TRUE)) %>%
            # Remove inter-transects e.g., 102.5
            filter(str_detect(transect.orig, "\\d\\.5", negate = TRUE)) 
        }
      }
      
      # Remove offshore transects data
      # If proper offshore sampling was conducted, biomass will be estimated
      # in later steps. If offshore biomass is to be included in the final
      # estimates, combine.regions == TRUE and "Offshore" should be included in
      # estimate.regions
      if (rm.offshore[i]) {
        # Filter based on offshore pattern
        nasc.offshore <- nasc.vessel %>% 
          filter(str_detect(transect.orig, nasc.pattern.offshore[i])) 
        
        # Save processed CSV data from each survey vessel
        if (nrow(nasc.offshore) > 0) {
          saveRDS(nasc.offshore, 
                  file = here("Data/Backscatter", i, 
                              paste0("nasc_vessel_", i, "_offshore.rds")))
          
          # Filter offshore transects
          nasc.vessel <- nasc.vessel %>% 
            filter(str_detect(transect.orig, nasc.pattern.offshore[i], negate = TRUE)) 
        }
      }
      
      # Remove inshore transects data (i.e., transects conducted between transects on the
      # inshore portion of the survey area)
      if (rm.inshore[i]) {
        # Filter based on inshore pattern
        nasc.inshore <- nasc.vessel %>% 
          filter(str_detect(transect.orig, nasc.pattern.inshore[i])) 
        
        # Save processed CSV data from each survey vessel
        if (nrow(nasc.inshore) > 0) {
          saveRDS(nasc.inshore, 
                  file = here("Data/Backscatter", i, 
                              paste0("nasc_vessel_", i, "_inshore.rds")))
          
          # Filter offshore transects
          nasc.vessel <- nasc.vessel %>% 
            filter(str_detect(transect.orig, nasc.pattern.inshore[i], negate = TRUE)) 
        }
      }
      
      # Remove nearshore transects data
      # If proper nearshore sampling was conducted, biomass will be estimated
      # in later steps. If nearshore biomass is to be included in the final
      # estimates, combine.regions == TRUE and "Nearshore" should be included in
      # estimate.regions
      if (rm.nearshore[i]) {
        nasc.nearshore <- nasc.vessel %>% 
          filter(str_detect(transect.orig, nasc.pattern.nearshore[i]) |
                   str_detect(tolower(filename), "nearshore")) 
        
        # Extract nearshore intervals that fall within the 20 m isobath
        if (extract.nearshore[i]) {
          nasc.nearshore.extract <- nasc.nearshore %>%
            st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
            st_intersection(bathy_20m_poly)
          
          nasc.nearshore <- nasc.nearshore %>% 
            filter(id %in% nasc.nearshore.extract$id)
          
          # ggplot() +
          #   geom_point(data = nasc.vessel, aes(long, lat, group = transect.orig),
          #             colour = "black") +
          #   geom_point(data = nasc.nearshore, aes(long, lat),
          #             colour = "red", shape = 21, fill = NA) +
          #   geom_sf(data = bathy_20m_poly, fill = NA) +
          #   coord_sf()
        }
        
        if (nrow(nasc.nearshore) > 0) {
          # Save processed CSV data from each survey vessel
          saveRDS(nasc.nearshore, 
                  file = here("Data/Backscatter", i, 
                              paste0("nasc_vessel_", i, "_nearshore.rds")))
          
          nasc.vessel <- nasc.vessel %>% 
            filter(str_detect(transect.orig, nasc.pattern.nearshore[i], negate = TRUE)) %>% 
            filter(str_detect(tolower(filename), "nearshore", negate = TRUE))
        }
      }
      
      # In 2022, Lisa Marie sampled compulsory transects to ~5m depth
      # Remove core transect intervals that fall within the 20 m isobath
      if (extract.nearshore[i]) {
        nasc.vessel.extract <- nasc.vessel %>%
          st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
          st_difference(bathy_20m_poly)
        
        nasc.vessel <- nasc.vessel %>% 
          filter(id %in% nasc.vessel.extract$id)
        
        # ggplot() +
        #   geom_point(data = nasc.vessel, aes(long, lat), colour = "red") +
        #   geom_point(data = nasc.nearshore, aes(long, lat), colour = "black", fill = NA, shape = 21) +
        #   geom_sf(data = bathy_20m_poly, fill = NA) +
        #   coord_sf()
      }
      
      # Identify acoustic transects to include in processing, based on length
      tx.include <- nasc.vessel %>% 
        group_by(transect) %>% 
        summarise(L = length(Interval)/10*0.539957) %>%
        arrange(L) %>% 
        filter(L > min.tx.length[i])
      
      tx.short <- nasc.vessel %>% 
        group_by(transect) %>% 
        summarise(L = length(Interval)/10*0.539957) %>%
        arrange(L) %>% 
        filter(L <= min.tx.length[i])
      
      # Remove backscatter data from short transects
      nasc.vessel <- nasc.vessel %>% 
        filter(transect %in% tx.include$transect)
      
      if (nrow(nasc.vessel) > 0) {
        # Create new interval for summarizing and plotting backscatter 
        # and add vessel abbreviation to transect name
        nasc.vessel <- nasc.vessel %>% 
          mutate(int = cut(Interval, seq(1, max(Interval) + nasc.summ.interval,
                                         nasc.summ.interval),
                           labels = FALSE, include.lowest = TRUE),
                 transect.name = paste(vessel.name, transect))
        
        # Filter NASC per vessel -------------------------------------------------
        # Manually remove individual transects
        if (!is.na(tx.rm[i])) {
          nasc.vessel <- filter(nasc.vessel, !transect.orig %in% unlist(tx.rm[i])) 
        }
        
        # Set stop integration depth
        if (source.cps.nasc[i]) {
          # Use externally supplied cps.nasc with variable integration depth (from CTD.app)
          # Read file and create unique key for joining with nasc.vessel
          if (survey.name %in% c("1507SH","1606RL")) {
            cps.nasc.temp <- read.csv(data.cps.nasc[i]) %>% 
              mutate(key = paste(transect, interval))
            # mutate(key = paste(interval, round(dist_m, 6))) 
            
            if (survey.name == c("1507SH")) {
              # Join nasc.vessel and cps.nasc on transect number and interval
              nasc.vessel <- nasc.vessel %>% 
                mutate(time.align  = align.time(datetime, 1),
                       transect.num = as.numeric(substr(transect.name, 4, 5)),
                       key = paste(transect.num, Interval)) %>% 
                filter(!str_detect(tolower(filename), "krill")) %>% 
                left_join(select(cps.nasc.temp, key, cps.nasc)) %>% 
                mutate(cps.nasc.diff = NASC.50 - cps.nasc) %>% 
                mutate(cps.nasc = case_when(
                  is.na(cps.nasc) ~ NASC.50,
                  TRUE ~ cps.nasc))  
            } else if (survey.name == c("1606RL")) {
              # Join nasc.vessel and cps.nasc on transect number and interval
              nasc.vessel <- nasc.vessel %>% 
                mutate(time.align  = align.time(datetime, 1),
                       transect.num = as.numeric(substr(transect.name, 4, 6)),
                       key = paste(transect.num, Interval)) %>% 
                filter(!str_detect(tolower(filename), "krill")) %>% 
                left_join(select(cps.nasc.temp, key, cps.nasc)) %>% 
                mutate(cps.nasc.diff = NASC.50 - cps.nasc) %>% 
                mutate(cps.nasc = case_when(
                  is.na(cps.nasc) ~ NASC.50,
                  TRUE ~ cps.nasc))
            }
          } else {
            cps.nasc.temp <- read.csv(data.cps.nasc[i]) %>% 
              mutate(key = paste(lat, long, dist_m),
                     datetime      = ymd_hms(paste(date, time), tz = "UTC"),
                     time.align  = align.time(datetime, 1)) %>% 
              # Remove data from krill files (1807RL)
              filter(!str_detect(tolower(filename), "krill")) 
            
            # Join nasc.vessel and cps.nasc on datetime
            nasc.vessel <- nasc.vessel %>% 
              mutate(time.align  = align.time(datetime, 1)) %>% 
              # select(-cps.nasc) %>% 
              filter(!str_detect(tolower(filename), "krill")) %>% 
              left_join(select(cps.nasc.temp, time.align, cps.nasc))  
          }
        } else {
          # Use cps.nasc extracted using extract_cps_nasc.R
          if ("cps.nasc" %in% colnames(nasc.vessel)) {
            nasc.vessel$cps.nasc.source <- "cps.nasc"
          } else {
            # If cps.NASC not extracted, use fixed depth (nasc.depth.cps) defined in settings
            # nasc.vessel$cps.nasc <- purrr::pluck(nasc.vessel, nasc.depth.cps)
            nasc.vessel <- nasc.vessel %>% 
              mutate(cps.nasc = purrr::pluck(., nasc.depth.cps),
                     cps.nasc.source = nasc.depth.cps)
          }
          
          # If files are not passed through extract_CPS_NASC.R, then cps.nasc = NA
          nasc.vessel <- nasc.vessel %>% 
            # Create variable containing the source of cps.nasc data, either 
            # cps.nasc (from extract_CPS_NASC.R) or the value of nasc.depth.cps
            mutate(cps.nasc.source = case_when(
              is.na(cps.nasc) ~ nasc.depth.cps,
              TRUE ~ cps.nasc.source)) %>% 
            # Replace missing cps.nasc values with backscatter down to nasc.depth.cps
            mutate(cps.nasc = case_when(
              is.na(cps.nasc) ~ purrr::pluck(., nasc.depth.cps),
              TRUE ~ cps.nasc))
        }
        
        # Remove surface noise, often from Saildrone backscatter
        if (rm.surface[i]) {
          nasc.vessel <- mutate(nasc.vessel, cps.nasc = cps.nasc - NASC.5)
        }
        
        # Save processed CSV data from each survey vessel
        saveRDS(nasc.vessel, file = here("Data/Backscatter", i, 
                                         paste0("nasc_vessel_", i, ".rds")))
        
        nasc.vessel.comp <- project_df(nasc.vessel, to = crs.proj)
        
        # Map a comparison of cps.nasc to nasc.depth.cps and
        # indicating the source of the backscatter data
        compare.cps.nasc.map <- base.map + 
          geom_point(data = nasc.vessel.comp, aes(X, Y, size = NASC.250)) +
          geom_point(data = nasc.vessel.comp, 
                     aes(X, Y, size = cps.nasc, colour = cps.nasc.source),
                     shape = 21, fill = NA) +
          coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
                   xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
                   ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
        
        # Save figure
        ggsave(compare.cps.nasc.map, 
               filename = here("Data/Backscatter", i, paste0("nasc_vessel_map_", i, ".png")), 
               height = map.height, width = map.width)
        
        # Scatter plot comparing cps.nasc to nasc.depth.cps and
        # indicating the source of the backscatter data
        compare.cps.nasc.scatter <- ggplot() + 
          geom_point(data = nasc.vessel.comp, 
                     aes(cps.nasc, NASC.250, colour = cps.nasc.source)) + 
          geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
          facet_wrap(~cps.nasc.source) +
          coord_equal() + 
          theme_bw()
        
        # Save figure
        ggsave(compare.cps.nasc.scatter, 
               filename = here("Data/Backscatter", i, paste0("nasc_vessel_scatter_", i, ".png")))
        
        # Combine results from different vessels
        if (exists("nasc")) {
          nasc <- bind_rows(nasc, nasc.vessel)
        } else {
          nasc <- nasc.vessel
        }
      }
      
      # Combine processed.csv.vessel
      if (exists("processed.csv")) {
        processed.csv <- unique(sort(c(processed.csv, processed.csv.vessel)))
      } else {
        processed.csv <- processed.csv.vessel
      }
    }
  }  
  
  # Save processed NASC file import
  save(nasc, file = here("Data/Backscatter/nasc_all.Rdata"))
  
  # Save processed CSV file names
  save(processed.csv, file =  here("Output/processed_csv.Rdata"))
  
} else {
  load(here("Data/Backscatter/nasc_all.Rdata"))
}

# Combine nasc data for all NASC vessels in the core area
# Applied in 2107RL when sampling was coordinated with Carranza,
# and in 2207RL when core sampling was conducted by Lisa Marie off OR/WA
if (!is.na(merge.vessels["Core"])) {
  if (merge.vessels["Core"]) {
    nasc <- nasc %>% 
      mutate(
        vessel.orig = case_when(
          is.na(vessel.orig) ~ vessel.name,
          TRUE ~ vessel.name),
        vessel.name = survey.vessel.primary)
  } else {
    # Create vessel.orig if it doesn't exist
    nasc <- nasc %>% 
      mutate(vessel.orig = vessel.name)
  }
}

# Determine transect order by min latitude/longitude
tx.order <- nasc %>%
  # filter(str_detect(vessel.name, i)) %>% 
  group_by(transect.name) %>% 
  summarise(max.lat  = max(lat),
            min.long = max(long)) %>% 
  mutate(rank.lat  = rank(max.lat), 
         rank.long = rev(rank(min.long)), 
         diff      = rank.lat - rank.long,
         rank.final = rank.lat,
         transect.num = rank.final,
         transect = transect.num) %>%
  arrange(rank.final)

# for (i in nasc.vessels) {
#   if (use.tx.number[i]) {
#     # Calculate transect order per vessel
#     tx.order.temp <- nasc %>%
#       filter(str_detect(vessel.name, i)) %>% 
#       group_by(transect.name) %>% 
#       summarise(max.lat  = max(lat),
#                 min.long = max(long)) %>% 
#       mutate(rank.lat  = rank(max.lat), 
#              rank.long = rev(rank(min.long)), 
#              diff      = rank.lat - rank.long,
#              transect.num = as.numeric(str_extract(transect.name,"[[:digit:]]+")),
#              rank.final = rank(transect.num)) %>% 
#       arrange(rank.final)
#   } else {
#     # Calculate transect order per vessel
#     tx.order.temp <- nasc %>%
#       filter(str_detect(vessel.name, i)) %>% 
#       group_by(transect.name) %>% 
#       summarise(max.lat  = max(lat),
#                 min.long = max(long)) %>% 
#       mutate(rank.lat  = rank(max.lat), 
#              rank.long = rev(rank(min.long)), 
#              diff      = rank.lat - rank.long,
#              rank.final = rank.lat,
#              transect.num = rank.final) %>%
#       arrange(rank.final)
#   }
#   
#   # Assign transect order based on rank latitude
#   if (nrow(tx.order) == 0) {
#     # If the first vessel, create transects from 0 to number of transects
#     tx.order.temp$transect <- tx.order.temp$rank.final
#   } else {
#     # If not the first vessel, add rank latitude to largest existing transect number
#     tx.order.temp$transect <- tx.order.temp$rank.final + max(tx.order$transect)
#   }
#   
#   # Combine results from all vessels
#   tx.order <- bind_rows(tx.order, tx.order.temp) %>% 
#     arrange(transect)
# }

# Add transect numbers to NASC
nasc <- left_join(select(nasc, -transect), 
                  select(tx.order, transect.name, transect)) %>% 
  project_df(to = crs.proj)

# Create survey strata polygons
source(here("Code/drawStrataSurvey.R"))

# Remove saildrone overlap for 1807RL
if (prj.name %in% c("1807RL")) {
  # Subset Lasker backscatter
  nasc.rl <- filter(nasc, vessel.name == "RL")
  
  # Subset Saildrone backscatter and remove overlap with Lasker
  nasc.sd.sub <- filter(nasc, vessel.name == "SD1024") %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    st_difference(filter(survey.polygons, vessel.name == "RL"))
  
  nasc.sd <- nasc %>% 
    filter(vessel.name == "SD1024") %>% 
    filter(fct_match(as.factor(datetime), as.factor(nasc.sd.sub$datetime)))
  
  nasc <- bind_rows(nasc.rl, nasc.sd)
}

# Summarize nasc data
nasc.summ <- nasc %>% 
  group_by(vessel.name, transect, transect.name) %>% 
  summarise(
    start     = min(datetime),
    end       = max(datetime),
    duration  = difftime(end, start, units = "hours"),
    n_int     = length(Interval),
    distance  = length(Interval)*nasc.interval/1852,
    lat       = lat[which.min(long)],
    long      = long[which.min(long)],
    mean_nasc = mean(cps.nasc)) %>% 
  arrange(vessel.name, start)

# Save NASC summary
save(nasc.summ, file = here("Output/nasc_summ_tx.Rdata"))
```

## Compare CPS backscatter (cps.nasc) to NASC.70

For each vessel, plot the backscatter from the CTD.app (`cps.nasc`, or equivalent) to backscatter from the default fixed integration depth (`NASC.250`).

```{r compare-cps-nasc}
# Add missing vessel.orig column if not present 
if (!"vessel.orig" %in% names(nasc)) {
  nasc$vessel.orig <- nasc$vessel.name
}

# Compare cps.nasc to NASC.70
ggplot(nasc, aes(NASC.250, cps.nasc)) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  facet_wrap(~vessel.orig) +
  coord_equal() +
  theme_bw()
```

```{r process-backscatter-krill}
source(here("Code/process_NASC-krill.R"))
```

```{r export-backscatter-ctd-app, include=FALSE}
# Export CSV files for CTD.app -------------------------------------------------
# Create directory for output
dir_create(here("Output/CTDapp"))

# Write each file to .csv
nasc %>%  
  arrange(vessel.name, datetime) %>% 
  group_by(vessel.name, leg) %>%  
  group_walk(~ write.csv(.x, 
                         file = here("Output/CTDapp", 
                                     paste0("CTDapp_", 
                                            unique(.y$vessel.name), "_Leg", 
                                            unique(.y$leg), ".csv")),
                         row.names = FALSE))
```

## Examine backscatter data for outliers  

The top 100 backscatter (NASC) values are plotted and labeled with the transect name and interval to look for unusual values in the integrated data from Echoview.  

(ref:plot-nasc-outliers) The top 100 backscatter (NASC) values labeled with the transect name and corresponding interval.

```{r plot-nasc-outliers,fig.cap='(ref:plot-nasc-outliers)'}
if (!is.na(nasc.max)) {
  nasc <- filter(nasc, cps.nasc < nasc.max)
}

# Select top 100 nasc values and look for outliers
big.nasc <- nasc %>%
  arrange(desc(cps.nasc)) %>%
  mutate(cps.nasc = cps.nasc/19,
         rank = seq(n()),
         label = paste0('Transect: ', transect.name,
                        ' - Distance: ', round(dist_m), " m"),
         popup = paste0('<b>Transect: </b>', transect.name, '<br/>',
                        '<b>Time: </b>', min(datetime), "-", max(datetime), ' UTC<br/>',
                        '<b>Distance: </b>', round(dist_m), ' m<br/>',
                        '<b>NASC: </b>', round(NASC), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>% 
  top_n(100, cps.nasc) %>% 
  select(rank, cps.nasc, label, popup, datetime, dist_m, sounder, 
         lat, long, transect.name, vessel.name, vessel.orig) 

# Create outlier plot
nasc.outlier.plot <- ggplot(big.nasc, aes(rank, cps.nasc, ids = label)) +
  geom_point(aes(colour = vessel.orig)) +
  geom_text_repel(data = top_n(big.nasc, 20, cps.nasc), 
                  aes(rank, cps.nasc, label = label), size = 2) +
  scale_color_discrete("Vessel") +
  xlab("\nRank") + ylab(expression(italic(s)[A]/19)) +
  theme_bw() +
  theme(legend.position      = c(0.95,0.95),
        legend.justification = c(1,1))

# Create outlier plot
nasc.outlier.plotly <- ggplot(big.nasc, 
                              aes(rank, cps.nasc, ids = label, fill = vessel.orig)) +
  geom_point(shape = 21, size = 4, alpha = 0.7) +
  ylab("NASC / 19\n") + xlab("\nRank") +
  theme_bw()

if (save.figs) {
  # Save figure
  ggsave(nasc.outlier.plot, filename = here("Figs/fig_nasc_outliers.png"), 
         height = 3, width = 5)
}

# include_graphics(here("Figs/fig_nasc_outliers.png"))
ggplotly(nasc.outlier.plotly)
```  

## Characterize day/night  

In the event that acoustic data were collected continuously (i.e., during day and night), each interval is characterized as being collected during day or night by estimating sunrise/sunset for each day based on the mean latitude and longitude of acoustic data from that day. If desired, data collected during either the day or night may be removed by changing the values of `r daynight.filter` in the `r prj.settings`. Data included in this analysis were from: `r glue::glue_collapse(daynight.filter, sep = ", ", last = " and ")`. 

(ref:plot-day-night) Acoustic intervals characterized by day or night based on local sunrise/sunset times.

```{r plot-day-night,fig.cap='(ref:plot-day-night)'}
# Summarize NASC by date and lat/long
nasc.sun <- nasc %>% 
  mutate(date = ymd(date)) %>% 
  group_by(date) %>% 
  summarise(lat = mean(lat),
            long = mean(long)) %>% 
  as.data.frame()

# Get sunrise/sunset for each survey day
nasc.daynight <- data.frame()

for (i in 1:nrow(nasc.sun)) {
  tmp <- day_night(date = nasc.sun$date[i], 
                   geocode = data.frame(lat = nasc.sun$lat[i], lon = nasc.sun$long[i]),
                   twilight = survey.twilight)
  nasc.daynight <- bind_rows(nasc.daynight, tmp)
}

# Format the results
nasc.daynight <- nasc.daynight %>% 
  mutate(sunrise = ymd_hms(paste(day, hms::as_hms(sunrise*3600))) - minutes(survey.twilight.offset),
         sunset  = sunrise + daylength*3600 + minutes(survey.twilight.offset),
         sunrise = as.character(sunrise), # convert to character to work with gather()
         sunset  = as.character(sunset)) %>% 
  select(day, sunrise, sunset) %>% 
  gather(period, time, -day) %>% 
  mutate(time    = ymd_hms(time, tz = "UTC"), # convert back to POSIX
         sun_key = as.character(time)) %>% 
  arrange(time) %>% 
  mutate(id = seq(1, nrow(.)))

# Assign NASC data to day/night intervals
nasc <- nasc %>%
  mutate(sun_key = as.character(cut(datetime, nasc.daynight$time, include.lowest = TRUE, ordered_result = TRUE))) %>% 
  left_join(select(nasc.daynight, sun_key, period)) %>% 
  mutate(day_night = case_when(
    period == "sunrise" ~ "Day",
    period == "sunset" ~ "Night",
    TRUE ~ "Other")) 

# Create date labels
nasc.sun.labels <- nasc.sun %>% 
  project_df(to = crs.proj)

if (save.figs) {
  # Plot results
  nasc.daynight.plot <- base.map + 
    geom_point(data = nasc, aes(X, Y, colour = day_night, size = day_night)) +
    geom_shadowtext(data = nasc.sun.labels, aes(X, Y, label = date), 
                    color = "black", bg.colour = "white", size = 2) +
    scale_colour_manual(name = "Time of day", values = c("Day" = "orange", "Night" = "black", "Other" = "green")) +
    scale_size_manual(name = "Time of day", values = c("Day" = 1, "Night" = 2, "Other" = 2.5)) +
    # Configure legend guides
    guides(colour = guide_legend(), size = guide_legend()) +
    coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Save and display figure
  ggsave(nasc.daynight.plot, filename = here("Figs/fig_nasc_daynight.png"), 
         width = map.width, height = map.height)  
}

# Filter day/night data
if (prj.name %in% c("1807RL-Saildrone")) {
  nasc <- nasc %>%
    left_join(select(nasc.sf, id, day_night)) %>% 
    filter(day_night %in% daynight.filter)  
} 

save(nasc, file = here("Output/nasc_daynight.Rdata"))

include_graphics(here("Figs/fig_nasc_daynight.png"))
```

## Map acoustic backscatter  
Acoustic backscatter is averaged over 2,000-m intervals and plotted along each transect. Transects are labeled by the vessel abbreviation and either a) the transect names assigned prior to or during the survey and extracted from .CSV files, or b) transect number assigned based on the rank latitude of the easternmost interval for each transect and vessel). **Backscatter values > 50,000 m^2^ nmi^-2^ should be further examined for potential problems (e.g., accidental integration of the seabed or surface noise).**  

(ref:map-nasc-tx) Survey transects performed aboard _`r survey.vessel`_ overlaid with the distribution of 38-kHz integrated backscattering coefficients (_s_~A~, m^2^ nmi^-2^;  averaged over 2000-m distance intervals and from `r cps.depth` to `r int.start`-m deep) ascribed to CPS. Panels are labeled with a) transect names (from Echoview files) and b) transect numbers (used to define sampling strata).

```{r map-nasc-tx, fig.cap='(ref:map-nasc-tx)'}  
# Create acoustic transect labels for maps
tx.labels.tmp <- nasc %>% 
  group_by(transect) %>% 
  summarise(
    vessel.name = vessel.name[1],
    transect.name = transect.name[1],
    start.lat = lat[which.max(long)],
    start.long = max(long),
    end.lat = lat[which.min(long)],
    end.long = min(long),
    brg = 90 - swfscMisc::bearing(end.lat,end.long,start.lat,start.long)[1])

tx.end.labels <- tx.labels.tmp %>% 
  filter(start.lat < 48.54116) %>% 
  select(vessel.name, transect, transect.name, lat = end.lat, long = end.long, brg) 

tx.start.labels <- tx.labels.tmp %>% 
  filter(start.lat >= 48.54116) %>% 
  select(vessel.name, transect, transect.name, lat = start.lat, long = start.long, brg) %>% 
  rbind(tx.end.labels)

tx.labels <- project_df(tx.start.labels, to = crs.proj)

# Average cps.nasc over defined interval
# Summarize by filename, not transect, so that renamed (i.e., strip.tx.chars == TRUE) transects get included.
nasc.plot <- nasc %>%
  select(filename, transect.name, transect, int, dist_m, datetime, lat, long, cps.nasc) %>% 
  group_by(filename, transect.name, transect, int) %>% 
  summarise(
    lat  = lat[1],
    long = long[1],
    NASC = mean(cps.nasc),
    label = paste0('Transect: ', transect[1], "; ",
                   'Distance: ', round(min(dist_m)), "-", round(max(dist_m)), ' m'),
    popup = paste0('<b>Transect: </b>', transect[1], '<br/>',
                   '<b>Time: </b>', min(datetime), " - ", max(datetime), ' UTC<br/>',
                   '<b>Distance: </b>', round(min(dist_m)), "-", round(max(dist_m)), ' m<br/>',
                   '<b>NASC: </b>', round(mean(NASC)), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>% 
  # Create bins for defining point size in NASC plots
  mutate(bin       = cut(NASC, nasc.breaks, include.lowest = TRUE),
         bin.level =  as.numeric(bin)) %>% 
  # st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  ungroup() %>% 
  project_df(to = crs.proj)

# Convert to sf
nasc.plot.sf <- nasc.plot %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

# Write NASC data to CSV
write.csv(nasc.plot, file = here("Output/cps_nasc_plot.csv"), 
          row.names = FALSE, quote = FALSE)

# Select plot levels for backscatter data
nasc.levels.all <- sort(unique(nasc.plot$bin.level))
nasc.labels.all <- nasc.labels[nasc.levels.all]
nasc.sizes.all  <- nasc.sizes[nasc.levels.all]
nasc.colors.all <- nasc.colors[nasc.levels.all]

# Create NASC map -------------------------------------------------------
if (save.figs) {
  # Map backscatter - label with transect name
  nasc.map.tx.name <- base.map +
    # Plot vessel track
    geom_sf(data = nav.paths.sf, colour = 'gray50', size = 0.25, alpha = 0.5) + 
    # Plot NASC data
    geom_point(data = nasc.plot, aes(X, Y, size = bin, fill = bin), 
               shape = 21, alpha = 0.75) +
    # Configure size and colour scales
    scale_size_manual(name = bquote(atop(italic(s)[A], ~'(m'^2 ~'nmi'^-2*')')),
                      values = nasc.sizes.all,labels = nasc.labels.all) +
    scale_fill_manual(name = bquote(atop(italic(s)[A], ~'(m'^2 ~'nmi'^-2*')')),
                      values = nasc.colors.all, labels = nasc.labels.all) +
    scale_colour_discrete(name = "Vessel") +
    # Plot acoustic transect labels N of Cape Flattery
    geom_shadowtext(data = tx.labels, 
                    aes(X, Y, label = transect.name,
                        angle = brg, colour = vessel.name),
                    size = 2, fontface = 'bold.italic', 
                    bg.colour = "white") +
    # Configure legend guides
    guides(fill = guide_legend(), size = guide_legend()) +
    # Plot title
    ggtitle("CPS Backscatter") +
    coord_sf(crs = crs.proj,
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Map backscatter - label with transect number
  nasc.map.tx.num <- base.map +
    # Plot vessel track
    geom_sf(data = nav.paths.sf, colour = 'gray50', size = 0.25, alpha = 0.5) + 
    # Plot NASC data
    geom_point(data = nasc.plot, aes(X, Y, size = bin, fill = bin), 
               shape = 21, alpha = 0.75) +
    # Configure size and colour scales
    scale_size_manual(name = bquote(atop(italic(s)[A], ~'(m'^2 ~'nmi'^-2*')')),
                      values = nasc.sizes.all,labels = nasc.labels.all) +
    scale_fill_manual(name = bquote(atop(italic(s)[A], ~'(m'^2 ~'nmi'^-2*')')),
                      values = nasc.colors.all, labels = nasc.labels.all) +
    scale_colour_discrete(name = "Vessel") +
    # Plot acoustic transect labels N of Cape Flattery
    geom_shadowtext(data = tx.labels, 
                    aes(X, Y, label = transect,
                        angle = brg, colour = vessel.name),
                    size = 2, fontface = 'bold.italic', 
                    bg.colour = "white") +
    # Configure legend guides
    guides(fill = guide_legend(), size = guide_legend()) +
    # Plot title
    ggtitle("CPS Backscatter") +
    coord_sf(crs = crs.proj,
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Save individual maps 
  ggsave(nasc.map.tx.name, 
         filename = here("Figs/fig_nasc_summary_map_tx_name.png"), 
         width = map.width, height = map.height)
  
  ggsave(nasc.map.tx.num,  
         filename = here("Figs/fig_nasc_summary_map_tx_num.png"),  
         width = map.width, height = map.height)
  
  # Combine maps and save
  nasc.map.tx <- plot_grid(nasc.map.tx.name, nasc.map.tx.num, 
                           nrow = 1, labels = c("a)","b)"))
  
  ggsave(nasc.map.tx, filename = here("Figs/fig_nasc_summary_map_tx.png"), 
         width = map.width*2, height = map.height) 
  
  # Create object for plotting sA
  # CONSIDER REPLACING NASC PLOT WITH NASC.PLOT.CPS THROUGHOUT
  nasc.plot.cps <- nasc.plot
  
  # Create final backscatter summary map
  source(here("Code/plot_sA_CPS.R"))
  
  # Map backscatter - Lisa Marie region only  
  if (survey.name %in% c("1707RL")) {
    # Map backscatter - no transect labels
    nasc.map.lm <- nasc.map +
      coord_sf(crs = crs.proj,
               xlim = c(map.bounds.lm["xmin"], map.bounds.lm["xmax"]), 
               ylim = c(map.bounds.lm["ymin"], map.bounds.lm["ymax"]))
    
    # Save nasc plot
    ggsave(nasc.map.lm, filename = here("Figs/fig_nasc_summary_map_LisaMarie.png"), 
           width = 3.2, height = 7) 
    
    save(nasc.map.lm, file = here("Output/nasc_plot_fig_LisaMarie.Rdata"))
  }
  
  # Map backscatter - Saildrone region only
  if (prj.name %in% c("1807RL")) {
    # Map backscatter - no transect labels
    map.bounds.sd <- nasc.sd %>% 
      st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
      st_transform(crs = crs.proj) %>% 
      st_bbox()
    
    nasc.map.sd <- nasc.map.cps +
      coord_sf(crs = crs.proj,
               xlim = c(map.bounds.sd["xmin"], map.bounds.sd["xmax"]), 
               ylim = c(map.bounds.sd["ymin"], map.bounds.sd["ymax"]))
    
    # Save nasc plot
    ggsave(nasc.map.sd, filename = here("Figs/fig_nasc_summary_map_saildrone.png"), 
           width = map.width, height = map.height) 
    
    save(nasc.map.sd, file = here("Output/nasc_plot_fig_saildrone.Rdata"))
  }
}

# load(here("Output/nasc_plot_cps.Rdata"))

include_graphics(here("Figs/fig_nasc_summary_map_tx.png"))
```  

# Process trawl data
## Import trawl data  

Trawl haul, catch, and length (both individual and binned lengths of CPS) data are imported from either an Access (at sea, generally) or SQL Server database (after the survey). To import from the SQL Server, a machine ODBC connection must be configured to the TRAWL and CUFES databases on the Estrella server (IP address: 161.55.235.187). For help configuring an ODBC connection, contact [Thanh Vu](Thanh.Vu@NOAA.gov) at the SWFSC. To request access to the Trawl database, contact [Yuhong Gu](Yuhong.Gu@NOAA.gov).  

```{r import-trawl-data, include=FALSE}
if (get.db) {
  if (trawl.source == "SQL") {
    # Configure ODBC connection to TRAWL database
    trawl.con  <- dbConnect(odbc(), 
                            Driver = "SQL Server", 
                            Server = "161.55.235.187", 
                            Database = "Trawl", 
                            Trusted_Connection = "True")
  } else if (trawl.source == "Access") {
    trawl.con  <- dbConnect(odbc(), 
                            Driver = "Microsoft Access Driver (*.mdb, *.accdb)", 
                            DBQ = file.path(here("Data/Trawl"),trawl.db.access))
  }
  
  # Import trawl database tables
  catch.all	     <- tbl(trawl.con, "Catch") %>% collect()
  haul.all       <- tbl(trawl.con, "Haul") %>% collect()
  lengths.all    <- tbl(trawl.con, "Specimen") %>% collect()
  if (dbExistsTable(trawl.con, "LengthFrequency"))
      lengthFreq.all <- tbl(trawl.con,"LengthFrequency") %>% collect()
  spp.codes      <- tbl(trawl.con, "SpeciesCodes") %>% collect()
  
  # Close database channel
  dbDisconnect(trawl.con)
  
  # Replace round herring in the database
  spp.codes$scientificName[spp.codes$species == 161743] <- "Etrumeus teres"
  
  # Save imported database data to .Rdata file
    if (exists("lengthFreq.all")) {
      save(catch.all, haul.all, lengths.all, spp.codes, lengthFreq.all, 
         file = here("Data/Trawl/trawl_data.Rdata"))
    } else {
      save(catch.all, haul.all, lengths.all, spp.codes,  
         file = here("Data/Trawl/trawl_data.Rdata"))
    }
  
  # Save species codes
  save(spp.codes, file = here("Output/species_codes.Rdata"))
  write_csv(spp.codes, here("Output/species_codes.csv"))
} else {
  # Load previously imported database data
  load(here("Data/Trawl/trawl_data.Rdata"))
}
```  

## Process trawl haul data  
Haul data are filtered, formatted, and assigned to clusters, where a trawl cluster contains only trawls conducted on the same evening (i.e., the difference in equilibrium time between trawls in the same cluster is < 12 h).

```{r process-trawl-haul-data}
# Create startLatitudeDecimal and startLongitudeDecimal for Access data
if (trawl.source == "Access") {
  if (year(haul.all$netInWaterTime[1]) >= 2021) {
    haul.all <- haul.all %>% 
      arrange(haul) %>% 
      mutate(
        startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
        startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
        stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
        stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60))) 
    
    catch.all <- catch.all %>% 
      rename(totalWeight = TotalWtKg,
             totalNum    = TotalNum)
    
  } else {
    haul.all <- haul.all %>% 
      arrange(haul) %>% 
      mutate(
        startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
        startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
        stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
        stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60)), 
        equilibriumTime  =   ymd_hms(paste(as.character(trawlDate),
                                           format(haul.all$EquilibriumTime,
                                                  format = "%H:%M:%S"))),
        haulBackTime     =   ymd_hms(paste(as.character(trawlDate),
                                           format(haul.all$haulbackTime,
                                                  format = "%H:%M:%S")))) %>%
      mutate(haulBackTime = case_when(
        haulBackTime < equilibriumTime ~ haulBackTime + days(1),
        TRUE ~ haulBackTime)) %>%
      rename(cruise = Cruise, ship = Ship, haul = Haul,
             collection = Collection, notes = Notes)
    
    # Identify hauls where date of equilibriumTime or haulBackTime is incorrect
    eq.fix <- which(c(0, diff(haul$equilibriumTime)) < 0)
    hb.fix <- which(c(0, diff(haul$haulBackTime)) < 0)
    
    # Correct equilibriumTime or haulBackTime
    haul.all$equilibriumTime[eq.fix] <- haul.all$equilibriumTime[eq.fix] + days(1)
    haul.all$haulBackTime[eq.fix]    <- haul.all$haulBackTime[eq.fix] + days(1)
  }
} else if (trawl.source == "SQL") {
  haul.all <- haul.all %>% 
    arrange(haul) %>% 
    mutate(
      equilibriumTime = ymd_hms(equilibriumTime),
      haulBackTime    = ymd_hms(haulBackTime))
  
  # Compute totalWeight and totalNum, which only exist in the Access database
  catch.all <- catch.all %>% 
    # replace_na(list(subSampleWtkg = 0, 
    #                 subSampleCount = 0,
    #                 remainingSubSampleWtkg = 0)) %>% 
    mutate(
      totalWeight = subSampleWtkg + remainingSubSampleWtkg,
      totalNum    = (subSampleCount/subSampleWtkg)*totalWeight)
}

# Classify hauls by season (spring or summer)
haul.all <- haul.all %>% 
  mutate(season = case_when(
    month(equilibriumTime) < 6 ~ "spring",
    TRUE ~ "summer"))

# Filter haul data for current survey
haul <- haul.all %>% 
  select(cruise, ship, haul, collection, startLatDecimal, startLongDecimal, 
         stopLatDecimal, stopLongDecimal, equilibriumTime, haulBackTime, 
         trawlPerformance, season, Notes) %>% 
  filter(cruise %in% cruise.name & ship %in% cruise.ship) %>%
  # Manually remove hauls
  filter(!haul %in% haul.rm) %>% 
  # Calculate haul duration
  mutate(duration = difftime(haulBackTime, equilibriumTime, units = "mins")) %>% 
  # Remove bad trawls
  filter(!trawlPerformance %in% trawl.performance) %>%
  filter(!haul %in% trawl.haul.exclude) %>%
  # Assign cluster based on yearday
  mutate(cluster = cumsum(c(0, diff(equilibriumTime)) > 12) + 1,
         sample.type = "Trawl") 

if (survey.name %in% c("2107RL")) {
  # Get max haul and cluster for Lasker to increment Carranza data
  max.cluster.rl <- max(haul$cluster)
  max.haul.rl    <- max(haul$haul)
  
  # Get Carranza data during 
  haul.jcf <- read_csv(here("Data/Trawl/JCFINP2110_haul_bitacore.csv")) %>% 
    mutate(cruise = as.character(cruise.name),
           ship = "JCF",
           equilibriumTime = with_tz(dmy_hm(startDateLocalTime, tz = "America/Los_Angeles"), 
                                     tzone = "UTC"),
           haulBackTime = with_tz(dmy_hm(stopDateLocalTime, tz = "America/Los_Angeles"), 
                                  tzone = "UTC"),
           collection = haul,
           trawl.performance = NA,
           season = case_when(
             month(equilibriumTime) < 6 ~ "spring",
             TRUE ~ "summer"), 
           notes = NA,
           duration = difftime(haulBackTime, equilibriumTime, units = "mins"),
           cluster = cumsum(c(0, diff(equilibriumTime)) > 12) + 1) %>% 
    mutate(haul = haul + max.haul.rl,
           cluster = cluster + max.cluster.rl)  %>% 
    select(cruise, ship, haul, collection, startLatDecimal, startLongDecimal,
           stopLatDecimal, stopLongDecimal, equilibriumTime, haulBackTime,
           trawl.performance:cluster) 
  
  # ggplot(haul.jcf, aes(startLongDecimal, startLatDecimal)) + geom_point() + coord_map()
  
  haul <- bind_rows(haul, haul.jcf)
  
  # ggplot(haul, aes(startLongDecimal, startLatDecimal, colour = ship)) + 
  #   geom_point() + 
  #   coord_map()  
}

if (survey.name %in% c("2207RL")) {
  # Get max haul and cluster for Lasker to increment Lisa Marie sets
  max.cluster.rl <- max(haul$cluster)
  max.haul.rl    <- max(haul$haul)
  
  ## Import LM set data and filter where it overlaps with Lasker
  haul.lm.2022 <- read_csv(here("Data/Seine/lm_sets.csv"), lazy = FALSE) %>% 
    mutate(date = mdy(date),
           datetime = ymd_hms(paste(date, time), tz = "America/Los_Angeles"),
           ship = "LM",
           key.set = paste(ship, date, set),
           haul    = seq_along(set) + max.haul.rl,
           cluster = seq_along(set) + max.cluster.rl,
           duration = as.difftime(45, units = "mins"),
           trawlPerformance = "Good") %>% 
    # Convert datetime to UTC
    mutate(datetime = with_tz(datetime, tzone = "UTC")) %>% 
    filter(lat >= 40.42) %>%
    select(ship, haul, cluster, startLatDecimal = lat, startLongDecimal = long,
           stopLatDecimal = lat, stopLongDecimal = long,
           equilibriumTime = datetime, duration, trawlPerformance, key.set) %>% 
    mutate(sample.type = "Purse seine")
  
  # The two options that used catch data for 2019 or 2021 to represent catch N of Cape Mendocino
  # was abandoned due to significant differences between results using those two data sets

    # # Get Lasker data from 2021, to replace purse seine catch from Lisa Marie
  # haul.2021 <- readRDS("C:/KLS/CODE/Github/estimATM/2107RL/Output/haul_info.rds") %>%
  #   # Remove hauls south of northernmost RL trawl from 2022
  #   filter(startLatDecimal >= 40.42) %>%
  #   mutate(haul = haul + max.haul.rl,
  #          cluster = cluster + max.cluster.rl) %>%
  #   filter(cluster <=50)
  # 
  # # Get Lasker data from 2019, to replace purse seine catch from Lisa Marie
  # haul.2019 <- readRDS("C:/KLS/CODE/Github/estimATM/1907RL/Output/haul_info.rds") %>%
  #   # Remove hauls south of northernmost RL trawl from 2022
  #   filter(startLatDecimal >= 40.42) %>%
  #   mutate(haul = haul + max.haul.rl,
  #          cluster = cumsum(c(0, diff(equilibriumTime)) > 12) + 1 + max.cluster.rl)

  # Combine haul data
  haul <- bind_rows(haul, select(haul.lm.2022, -key.set))
  # haul <- bind_rows(haul, haul.2021)
  # haul <- bind_rows(haul, haul.2019)

  # ggplot(haul, aes(startLongDecimal, startLatDecimal, colour = ship)) +
  #   geom_text(aes(label = cluster)) +
  #   coord_map() 
}

# Find midpoint of each haul as the mean lat/lon
haul.mid <- haul %>% 
  group_by(cluster, haul, sample.type) %>% 
  summarise(
    lat  = mean(c(startLatDecimal, stopLatDecimal)),
    long = mean(c(startLongDecimal, stopLongDecimal)))

# Convert to sf for plotting
haul.mid.sf <- haul.mid %>% 
  mutate(label = paste("Haul", haul)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

# Convert haul paths and midpoints to sf; CRS = crs.geog
# Create haul paths from starts and ends
haul.paths <- select(haul, haul, lat = startLatDecimal, long = startLongDecimal) %>% 
  bind_rows(select(haul, haul, lat = stopLatDecimal, long = stopLongDecimal)) %>% 
  arrange(haul) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  group_by(haul) %>% 
  summarise(do_union = FALSE) %>% 
  st_cast("LINESTRING") 

# Find midpoint of each haul cluster as the average of haul midpoints
cluster.mid <- haul.mid %>% 
  group_by(cluster, sample.type) %>% 
  summarise(
    lat  = mean(lat),
    long = mean(long)) %>% 
  ungroup() %>% 
  project_df(to = crs.proj)

# Convert to sf for plotting
cluster.mid.sf <- cluster.mid %>% 
  mutate(label = paste("Cluster", cluster)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

# Save haul data
saveRDS(haul, file = here("Output/haul_info.rds"))
```  

## Summarize trawl haul data  
Data for each trawl are summarized to identify trawl hauls with potential problems, for example where either `trawlPerformance` is not "good" (colored "yellow") or `duration` (nominal trawl duration is typically 45 min) is $\leq$ 30 min (colored "orange").   

```{r trawl-haul-summary, collapse=TRUE}
# Create and format haul summary table
haul %>% 
  replace_na(list(trawlPerformance = "Unknown")) %>% 
  select(-stopLatDecimal, -stopLongDecimal, -haulBackTime) %>% 
  mutate(equilibriumTime = format(equilibriumTime, "%m/%d/%Y %H:%M"),
         duration = cell_spec(
           duration, knitr.format, color = "black",
           background = ifelse(duration >= 30,"white","orange")),
         trawlPerformance = cell_spec(
           trawlPerformance, knitr.format, color = "black",
           background = ifelse(!trawlPerformance %in% c(trawl.performance, "Unknown"),"white","yellow"))) %>% 
  kable(format = knitr.format,booktabs = TRUE, escape = FALSE) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"), 
                full_width = FALSE) %>%
  row_spec(0, align = c("c")) %>% 
  scroll_box(height = "500px")
```  

## Check trawl clustering  

Trawl haul information is summarized by cluster. Those clusters where the difference in equilibrium time between the first and last haul in a cluster is $\geq$ 12 h are highlighted in yellow and should be examined in the Haul table of the Trawl database. 

```{r check-trawl-clusters}
# Summarize trawl clusters
cluster.check <- haul %>% 
  group_by(cluster, sample.type) %>% 
  summarise(
    nHauls         = length(cluster),
    firstHaul      = min(haul),
    lastHaul       = max(haul),
    firstHaulStart = min(equilibriumTime),
    lastHaulEnd    = max(haulBackTime),
    duration       = round(difftime(lastHaulEnd, 
                                    firstHaulStart, 
                                    units = 'hours'), 1)) %>% 
  mutate(firstHaulStart = format(firstHaulStart,"%m/%d/%Y %H:%M"),
         lastHaulEnd    = format(lastHaulEnd,"%m/%d/%Y %H:%M")) %>% 
  replace_na(list(duration = as.difftime(13, units = "hours")))

# Print cluster check table
cluster.check %>% 
  mutate(duration = cell_spec(
    duration, knitr.format, color = "black",
    background = ifelse(duration <= 12,"white","orange"))) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("c")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"),
                full_width = FALSE) %>%
  row_spec(0, align = c("c")) %>% 
  scroll_box(height = "500px")
```  

## Map trawl and trawl cluster locations

Examine the locations of trawl hauls and results of trawl clustering.  

(ref:map-trawl-clusters) Trawl paths (black lines; difficult to see at most scales, as mostly obscured by the trawl midpoints), trawl midpoints (red Xs), and cluster midpoints used to apportion putative CPS backscatter to species (green circles, numeric labels) are mapped relative to acoustic transects (heavy gray points) and vessel track (light gray line).

```{r map-trawl-clusters,fig.cap='(ref:map-trawl-clusters)'}
if (save.figs) {
  # Map trawl clusters -------------------------------------------------------
  trawl.cluster.plot <- base.map +
    # Plot vessel track
    geom_sf(data = nav.paths.sf, colour = "gray50", size = 0.25, alpha = 0.5) +
    # Plot acoustic transects
    geom_point(data = nasc.plot, aes(X, Y), 
               colour = "gray50", size = 0.5, alpha = 0.75) +
    # Plot trawl paths
    geom_sf(data = haul.paths) +
    # Plot trawl midpoint
    geom_sf(data = haul.mid.sf, shape = 4, colour = "red") +
    # Plot cluster midpoint
    geom_point(data = cluster.mid, aes(X, Y), colour = "green", shape = 21) +
    geom_shadowtext(
      data = cluster.mid, aes(X, Y, label = cluster, colour = sample.type),
      bg.colour = "white", size = 2) +
    # Plot panel label
    ggtitle("Trawl clusters") +
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Save trawl plot
  ggsave(trawl.cluster.plot,
         filename = here("Figs/fig_trawl_cluster_map.png"),
         width = map.width, height = map.height)
}

include_graphics(here("Figs/fig_trawl_cluster_map.png"))
```  

## Process trawl catch data  

Catch data are filtered, formatted, summarized by weight, and formatted for plotting.

```{r process-trawl-catch-data, message=FALSE}
# Filter catch data
catch <- catch.all %>% 
  left_join(select(spp.codes, species, scientificName, commonName)) %>% 
  filter(cruise %in% cruise.name & ship %in% cruise.ship & 
           scientificName %in% cps.spp & netSampleType == 'codend') %>% 
  inner_join(select(haul, haul, cluster)) %>% 
  mutate(key = paste(haul, scientificName),
         sample.type = "Trawl")

if (survey.name %in% c("2107RL")) {
  # Read and process catch data from Carranza
  catch.jcf <- read_csv(here("Data/Trawl/JCFINP2110_catch.csv")) %>% 
    mutate(
      cruise      = as.character(cruise.name),
      collection  = haul,
      haul        = haul + max.haul.rl,
      totalWeight = subSampleWtkg + remainingSubSampleWtkg,
      totalNum    = (subSampleCount/subSampleWtkg)*totalWeight,
      key         = paste(haul, scientificName)) %>% 
    left_join(select(spp.codes, scientificName, commonName, species)) %>% 
    left_join(select(haul, haul, cluster))
  
  # Combine catch data from each vessel
  catch <- bind_rows(catch, catch.jcf)
}

if (survey.name %in% c("2107RL")) {
  # Haul 97 had specimen lengths taken but not weights, so weight had to be 
  # estimated from length, and average weight is estimated to estimate the totalNum
  catch.weight.missing <- catch %>% 
    filter(totalNum == Inf) 
  
  lengths.missing.weights <- lengths.all %>% 
    left_join(spp.codes) %>% 
    mutate(key = paste(haul, scientificName)) %>% 
    # Get specimens with missing weights
    filter(key %in% unique(catch.weight.missing$key),
           cruise == 202107) %>% 
    # Convert native length to total length, which us used to estimate weight
    mutate(
      totalLength_mm = case_when(
        scientificName == "Clupea pallasii" ~ 
          convert_length("Clupea pallasii", .$forkLength_mm, "FL", "TL"),
        scientificName == "Engraulis mordax" ~ 
          convert_length("Engraulis mordax", .$standardLength_mm, "SL", "TL"),
        scientificName == "Sardinops sagax" ~ 
          convert_length("Sardinops sagax", .$standardLength_mm, "SL", "TL"),
        scientificName == "Scomber japonicus" ~ 
          convert_length("Scomber japonicus", .$forkLength_mm, "FL", "TL"),
        scientificName == "Trachurus symmetricus" ~ 
          convert_length("Trachurus symmetricus", .$forkLength_mm, "FL", "TL"),
        scientificName == "Doryteuthis (Loligo) opalescens" ~  as.numeric(mantleLength_mm))) %>% 
    mutate(
      weightg = estimate_weight(.$scientificName, .$totalLength_mm, season = tolower(survey.season)))
  
  # Summarize subSampleWtkg, used to estimate totalNum in the catch table
  missing.weight.summ <- lengths.missing.weights %>% 
    group_by(key) %>% 
    summarise(subSampleWt.est = sum(weightg)/1000)
  
  # Add estimated subsample weight to the catch table
  # When totalNum is missing, estimate the total number from the mean specimen weight
  catch <- catch %>% 
    left_join(missing.weight.summ) %>% 
    mutate(
      subSampleWtkg = case_when(
        subSampleWtkg == 0 ~ subSampleWt.est,
        TRUE ~ subSampleWtkg),
      totalNum = case_when(
        totalNum == Inf ~ (subSampleCount/subSampleWtkg)*totalWeight,
        TRUE ~ totalNum)) %>%
    select(-subSampleWt.est)
}

if (survey.name %in% c("2207RL")) {
  ## Import LM catch data and merge with set data
  catch.lm.2022 <- read_csv(here("Data/Seine/lm_catch.csv")) %>% 
    mutate(date = mdy(date),
           ship = "LM",
           key.set = paste(ship, date, set),
           scientificName = case_when(
             species_name == "Pacific Herring" ~ "Clupea pallasii",
             species_name == "Pacific Sardine" ~ "Sardinops sagax",
             species_name == "Pacific Mackerel" ~ "Scomber japonicus",
             species_name == "Jack Mackerel" ~ "Trachurus symmetricus",
             species_name == "Northern Anchovy" ~ "Engraulis mordax",
             species_name == "Jacksmelt" ~ "Atherinopsis californiensis",
             species_name == "Whitebait Smelt" ~ "Allosmerus elongatus",
             TRUE ~ NA_character_)) %>% 
    filter(!is.na(scientificName)) %>% 
    group_by(key.set, ship, scientificName) %>% 
    summarise(totalWeight = sum(weightkg),
              totalNum = sum(count)) %>% 
    # Compute missing variables from catch table
    mutate(subSampleWtkg = totalWeight,
           subSampleCount = totalNum) %>% 
    left_join(select(spp.codes, scientificName, commonName)) %>% 
    left_join(select(haul.lm.2022, key.set, haul, cluster, sample.type)) %>% 
    # Remove catch S of Cape Mendocino
    filter(!is.na(haul), !is.na(cluster))
  
  # # Read and process catch data from Lasker in summer 2021
  # catch.2021 <- readRDS("C:/KLS/CODE/Github/estimATM/2107RL/Output/catch_info.rds") %>%
  #   # filter(ship == "RL") %>%
  #   select(-cluster) %>%
  #   mutate(
  #     haul    = haul + max.haul.rl,
  #     # cluster = cluster + max.cluster.rl,
  #     key     = paste(haul, scientificName)) %>%
  #   left_join(select(haul, haul, cluster)) %>%
  #   filter(haul %in% hauls.2022)
  # 
  #   # Read and process catch data from Lasker in summer 2021
  # catch.2019 <- readRDS("C:/KLS/CODE/Github/estimATM/1907RL/Output/catch_info.rds") %>%
  #   # filter(ship == "RL") %>%
  #   select(-cluster) %>%
  #   mutate(
  #     totalNum = (subSampleCount/subSampleWtkg)*totalWeight,
  #     haul     = haul + max.haul.rl,
  #     # cluster = cluster + max.cluster.rl,
  #     key      = paste(haul, scientificName)) %>%
  #   left_join(select(haul, haul, cluster)) %>%
  #   filter(haul %in% hauls.2022)

  # Combine catch data from each vessel
  catch <- bind_rows(catch, catch.lm.2022)
  # catch <- bind_rows(catch, catch.2021)
  # catch <- bind_rows(catch, catch.2019)
}

# Save haul data
saveRDS(catch, file = here("Output/catch_info.rds"))

if (nrow(catch) > 0) {
  haul.summ.wt <- catch %>%
    select(haul, cluster, sample.type, scientificName, totalWeight) %>%
    tidyr::spread(scientificName, totalWeight)
  
  # Add species with zero total weight
  if (!has_name(haul.summ.wt, "Engraulis mordax"))      {haul.summ.wt$`Engraulis mordax`      <- 0}
  if (!has_name(haul.summ.wt, "Sardinops sagax"))       {haul.summ.wt$`Sardinops sagax`       <- 0}
  if (!has_name(haul.summ.wt, "Scomber japonicus"))     {haul.summ.wt$`Scomber japonicus`     <- 0}
  if (!has_name(haul.summ.wt, "Trachurus symmetricus")) {haul.summ.wt$`Trachurus symmetricus` <- 0}
  if (!has_name(haul.summ.wt, "Clupea pallasii"))       {haul.summ.wt$`Clupea pallasii`       <- 0}
  if (!has_name(haul.summ.wt, "Atherinopsis californiensis")) {haul.summ.wt$`Atherinopsis californiensis` <- 0}
  if (!has_name(haul.summ.wt, "Etrumeus acuminatus"))   {haul.summ.wt$`Etrumeus acuminatus` <- 0}
  if (!has_name(haul.summ.wt, "Other"))                 {haul.summ.wt$`Other` <- 0}
  
  # Calculate total weight of all CPS species
  haul.summ.wt <- haul.summ.wt %>%  
    replace(is.na(.), 0) %>% 
    mutate(AllCPS = rowSums(select(., -haul, -cluster, -sample.type))) %>%
    # mutate(AllCPS = rowSums(.[, 3:ncol(.)])) %>%
    rename("Jacksmelt"  = "Atherinopsis californiensis",
           "PacHerring" = "Clupea pallasii",
           "Anchovy"    = "Engraulis mordax",
           "Sardine"    = "Sardinops sagax",
           "PacMack"    = "Scomber japonicus",
           "JackMack"   = "Trachurus symmetricus",
           "RndHerring" = "Etrumeus acuminatus",
           "Other"      = "Other") 
  
  # Summarise catch by cluster
  cluster.summ.wt <- haul.summ.wt %>% 
    select(-haul, -AllCPS, -sample.type) %>% 
    group_by(cluster) %>% 
    summarise_all(list(sum)) %>% 
    mutate(AllCPS = rowSums(select(., -cluster))) %>% 
    right_join(cluster.mid) %>% 
    replace(is.na(.), 0)
  
  # Add lat/long to haul summary for plotting
  haul.summ.wt <- haul.summ.wt %>% 
    right_join(haul.mid) %>% 
    replace(is.na(.), 0)
  
} else {
  # Summarize trawl catch by species
  haul.summ.wt <- bind_cols(select(haul, haul, cluster),
                            data.frame(
                              "Jacksmelt"  = rep(0, nrow(haul)),
                              "PacHerring" = rep(0, nrow(haul)),
                              "Anchovy"    = rep(0, nrow(haul)),
                              "Sardine"    = rep(0, nrow(haul)),
                              "PacMack"    = rep(0, nrow(haul)),
                              "JackMack"   = rep(0, nrow(haul)),
                              "RndHerring" = rep(0, nrow(haul)),
                              "Other"      = rep(0, nrow(haul)),  
                              "AllCPS"     = rep(0, nrow(haul)))) %>% 
    right_join(haul.mid)
  
  # Summarise catch by cluster
  cluster.summ.wt <- haul.summ.wt %>% 
    select(-haul, -AllCPS) %>% 
    group_by(cluster) %>% 
    summarise_all(list(sum)) %>% 
    mutate(AllCPS = rowSums(select(., -cluster))) %>%
    right_join(cluster.mid) %>% 
    replace(is.na(.), 0)
}

# Prepare catch data for plotting ----------------------------------------------
# Select and rename trawl data for pie charts
haul.pie <- haul.summ.wt %>% 
  select(haul, long, lat, Anchovy, JackMack, 
         Jacksmelt, Other, PacHerring, PacMack, 
         RndHerring, Sardine, AllCPS, sample.type) %>% 
  mutate(bin       = cut(AllCPS, trawl.breaks, include.lowest = TRUE),
         bin.level = as.numeric(bin)) %>% 
  arrange(haul) %>% 
  project_df(to = crs.proj) %>% 
  mutate(
    label = paste("Haul", haul),
    popup = paste('<b>Cluster:', haul, '</b><br/>',
                  'Anchovy:', Anchovy, 'kg<br/>',
                  'Sardine:', Sardine, 'kg<br/>',
                  'Jack Mackerel:', JackMack, 'kg<br/>',
                  'P. herring:', PacHerring, 'kg<br/>',
                  'P. mackerel:', PacMack, 'kg<br/>',
                  'R. herring:', RndHerring, 'kg<br/>',
                  'Other:', Other, 'kg<br/>',
                  'All CPS:', AllCPS, 'kg'))

cluster.pie <- cluster.summ.wt %>% 
  select(cluster, long, lat, Anchovy, JackMack, 
         Jacksmelt, Other, PacHerring, PacMack, 
         RndHerring, Sardine, AllCPS, sample.type) %>% 
  mutate(bin       = cut(AllCPS, trawl.breaks, include.lowest = TRUE),
         bin.level = as.numeric(bin)) %>% 
  project_df(to = crs.proj) %>% 
  mutate(
    label = paste("Cluster", cluster),
    popup = paste('<b>Cluster:', cluster, '</b><br/>',
                  'Anchovy:', Anchovy, 'kg<br/>',
                  'Sardine:', Sardine, 'kg<br/>',
                  'Jack Mackerel:', JackMack, 'kg<br/>',
                  'P. herring:', PacHerring, 'kg<br/>',
                  'P. mackerel:', PacMack, 'kg<br/>',
                  'R. herring:', RndHerring, 'kg<br/>',
                  'Other:', Other, 'kg<br/>',
                  'All CPS:', AllCPS, 'kg'))

# Filter for empty trawls
haul.zero    <- filter(haul.pie, AllCPS == 0)

cluster.zero <- filter(cluster.pie, AllCPS == 0)

# Calculate pie radius based on latitude range
pie.radius <- as.numeric(abs(map.bounds$ymin - map.bounds$ymax)*pie.scale)

# Calculate pie radius of each pie, based on All CPS landings
if (scale.pies) {
  haul.pie$r    <- pie.radius*log(haul.pie$bin.level+1)
  cluster.pie$r <- pie.radius*log(cluster.pie$bin.level+1)
} else {
  haul.pie$r    <- pie.radius
  cluster.pie$r <- pie.radius
}

# Filter for positive hauls and clusters
haul.pos <- filter(haul.pie, AllCPS > 0) %>% 
  arrange(X)

cluster.pos <- filter(cluster.pie, AllCPS > 0) %>% 
  arrange(X)

# Substitute very small value for species with zero catch, just for pie charts
if (nrow(haul.pos) > 0) {
  haul.pos <- haul.pos %>% 
    replace(. == 0, 0.0000001) 
  
  cluster.pos <- cluster.pos %>% 
    replace(. == 0, 0.0000001) 
}

# Add catch to haul paths for Leaflet plots
haul.paths <- haul.paths %>% 
  left_join(select(haul.summ.wt, -cluster)) %>%
  replace(is.na(.), 0) %>% 
  mutate(
    distance = round(as.numeric(st_length(.))/1852,1),
    label    = paste("Haul", haul),
    popup    = paste('<b>Haul:', haul, '</b><br/>',
                     'Anchovy:', Anchovy, 'kg<br/>',
                     'Sardine:', Sardine, 'kg<br/>',
                     'Jack Mackerel:', JackMack, 'kg<br/>',
                     'P. herring:', PacHerring, 'kg<br/>',
                     'P. mackerel:', PacMack, 'kg<br/>',
                     'R. herring:', RndHerring, 'kg<br/>',
                     'Other:', Other, 'kg<br/>',
                     'All CPS:', AllCPS, 'kg')) 

# Select positive clusters
super.clusters <- filter(cluster.mid, cluster %in% unique(cluster.pos$cluster))

super.hauls <- filter(haul.mid, haul %in% unique(haul.pos$haul)) %>% 
  ungroup() %>% 
  project_df(to = crs.geog)

# Save trawl summary data
save(haul.summ.wt, cluster.summ.wt, haul.pie, cluster.pie, haul.zero, cluster.zero,
     file = here("Output/catch_info.Rdata"))
```

```{r get-herring-limits}
# Get positive herring hauls
herring.hauls <- haul.summ.wt %>% 
  select(haul, weight_kg = PacHerring) %>% 
  filter(weight_kg > 0) %>% 
  left_join(select(haul.mid, haul, lat, long))

if (nrow(herring.hauls) > 0) {
  # Get bathymetry data across range of nav data (plus/minus one degree lat/long)
  if (get.bathy) {
    # Get boundaries for bathymetry grid
    bathy.bounds <- herring.hauls %>%
      st_as_sf(coords = c("long", "lat"), crs = crs.geog) %>% 
      st_bbox() 
    
    # Download bathy grid
    noaa.bathy <- getNOAA.bathy(
      lon1 = floor(bathy.bounds$xmin) - 1, 
      lon2 = floor(bathy.bounds$xmax) + 1,
      lat1 = floor(bathy.bounds$ymax) + 1, 
      lat2 = floor(bathy.bounds$ymin) - 1, 
      resolution = 4)
    
    # Save bathy results
    save(noaa.bathy, file = paste(here("Data/GIS"), "/bathy_data_",
                                  survey.name,".Rdata", sep = ""))  
  } else {
    load(paste(here("Data/GIS"), "/bathy_data_",
               survey.name,".Rdata", sep = ""))
  }
  
  # Get depth of positive herring hauls
  herring.depth <- get.depth(noaa.bathy, 
                             herring.hauls$long, 
                             herring.hauls$lat, 
                             locator = FALSE, distance = FALSE) 
  
  # Add depth data to herring df
  herring.hauls$depth <- herring.depth$depth
  
  # Save to CSV
  write_csv(herring.hauls, here("Output/herring_hauls.csv"))
  
  # Set padding around data  
  herring.hauls <- herring.hauls %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    st_transform(crs = crs.proj)
  
  # Set padding around data  
  herring.bounds <- herring.hauls %>% 
    st_transform(crs = crs.proj) %>% 
    st_bbox()
  
  if (save.figs) {
    # Create map of herring hauls colored by seabed depth
    herring.map <- base.map + 
      geom_sf(data = herring.hauls, aes(fill = depth, size = weight_kg), 
              shape = 21, show.legend = "point") +
      scale_fill_viridis_c("Seabed depth (m)") +
      scale_size_area("Catch (kg)") + 
      ggtitle("Herring trawl locations") +
      coord_sf(crs = crs.proj, 
               xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
               ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
    
    # Save map
    ggsave(herring.map, filename = here("Figs/fig_herring_trawls.png"),
           height = map.height, width = map.width)  
    
    # Create histogram of bottom depths near herring trawl locatiosn
    herring.histogram <- ggplot(herring.hauls, aes(depth)) + 
      geom_histogram(colour = "black") +
      ggtitle("Herring trawl depths") +
      theme_bw()
    
    # Save histogram
    ggsave(herring.histogram, filename = here("Figs/fig_herring_depth_histogram.png"))
    
    # Combine map and histogram
    herring.combo <- plot_grid(herring.map, herring.histogram, nrow = 1, align = "h")
    
    # Save combo map
    ggsave(herring.combo, filename = here("Figs/fig_herring_map_histogram.png"),
           height = map.height, width = map.width*2)
  }
}
```

## Summarize and export "single-species" haul data  

Trawl hauls where a single species makes up $\geq$ 80% of the catch (by weight) are identified and haul metadata exported for further analysis in Echoview to estimate _in situ_ target strength of various CPS.  

(ref:single-species-hauls) The location of "single-species" hauls symbolized by the dominant species in each haul.

```{r export-single-species-hauls,fig.cap='(ref:single-species-hauls)'}
# Summarize hauls with single species CPS catch for target strength estimation
# Calculate total sample weight for each CPS species
catch.ts <- catch %>% 
  mutate(totalSampleWeight = subSampleWtkg + remainingSubSampleWtkg) 

# Calculate total CPS weight per
catch.ts.summ <- catch.ts %>% 
  group_by(haul) %>% 
  summarise(totalHaulWeight = sum(totalSampleWeight))

# Merge and filter for CPS > 80% totalSampleWeight
catch.ts <- catch.ts %>% 
  left_join(catch.ts.summ) %>% 
  mutate(pctTotalCPS = totalSampleWeight/totalHaulWeight*100) %>% 
  filter(pctTotalCPS >= 80) %>% 
  select(haul, scientificName, totalSampleWeight, pctTotalCPS)

# Format haul data and merge with catch
haul.ts <- haul %>% 
  select(cruise, ship, haul, equilibriumTime, haulBackTime, 
         lat = startLatDecimal, long = startLongDecimal) %>% 
  mutate(
    eqTimeUTC       = format(equilibriumTime + hours(8), "%F %T"),
    hbTimeUTC       = format(haulBackTime + hours(8), "%F %T"),
    equilibriumTime = format(equilibriumTime, "%F %T"),
    haulBackTime    = format(haulBackTime, "%F %T")) %>% 
  left_join(catch.ts) %>% 
  project_df(to = crs.proj)

# Export haul data for single-target TS estimation
write_csv(haul.ts, here("Output/single_species_hauls.csv"), na = "")

if (save.figs) {
  # Map single species hauls
  haul.ts.map <- base.map + 
    # Plot vessel track
    geom_sf(data = nav.paths.sf, colour = 'gray50', size = 0.25, alpha = 0.5) + 
    # Plot NASC data
    geom_path(data = nasc.plot, aes(X, Y, group = transect), 
              linewidth = 0.5, alpha = 0.75) +
    # Plot acoustic transect labels
    geom_shadowtext(data = tx.labels, aes(X, Y, label = transect.name, angle = brg), 
                    size = 1, hjust = 1.5, fontface = 'bold.italic', 
                    colour = "black", bg.colour = "white") +
    geom_shadowtext(data = filter(haul.ts, is.na(pctTotalCPS)), 
                    aes(X, Y, label = haul),
                    size = 1, colour = "black", bg.colour = "white") +
    geom_shadowtext(data = filter(haul.ts, !is.na(pctTotalCPS)), 
                    aes(X, Y, label = haul, colour = scientificName),
                    size = 2, bg.colour = "white", fontface = "bold") +
    scale_colour_discrete(name = "Species") +
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Save haul.ts map
  ggsave(haul.ts.map, 
         filename = here("Figs/fig_haul_target_strength_map.png"), 
         height = map.height, width = map.width)
}

include_graphics(here("Figs/fig_haul_target_strength_map.png"))
```  

## Assign backscatter data to trawl clusters

```{r assign-trawl-clusters}
# Assign nearest trawl cluster to each NASC interval -------------------------------------------------------
saveRDS(nasc, here("Output/nasc_match.rds"))
# nasc <- readRDS(here("Output/nasc_match.rds"))

nasc.match <- nasc %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog)

cluster.match <- super.clusters %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog)

# Find nearest cluster ----------------------------
# Returns a vector of nearest clusters
nearest.cluster <- st_nearest_feature(nasc.match, cluster.match)

# Expand clf to match nasc ------------------------
cluster.sp <- cluster.match[nearest.cluster, ] %>% 
  select(geometry) %>% 
  as_Spatial()

# Make nasc sp
# Removing the other data (i.e., only retaining the geometry) decreases the size of nasc from 50 to 1 MB
nasc.sp <- nasc.match %>% 
  select(geometry) %>% 
  as_Spatial()

# Compute distances with {geosphere}
## Must be done in WGS84 projection
nasc.match <- nasc.match %>% 
  mutate(cluster = cluster.match$cluster[nearest.cluster],
         cluster.distance = distGeo(nasc.sp, cluster.sp)*0.000539957) 

# Create cluster polygons
nasc.super.clusters <- nasc.match %>% 
  group_by(cluster) %>% 
  summarise() %>% 
  st_convex_hull()

# Remove geometry
nasc.match <- st_set_geometry(nasc.match, NULL) 

# Add clusters and cluster distances to nasc
nasc <- nasc %>% 
  bind_cols(select(nasc.match, cluster, cluster.distance)) 
```

## Map trawl cluster polygons around acoustic intervals  

Backscatter from each 100 m-long acoustic interval is apportioned by species according to the nearest (in space) trawl cluster.  

(ref:acoustic-trawl-clusters) Acoustic intervals symbolized by nearest trawl clusters. Cluster numbers in **bold** are positive clusters.

```{r map-acoustic-trawl-clusters,fig.cap='(ref:acoustic-trawl-clusters)'}
if (save.figs) {
  # Map trawl clusters -------------------------------------------------------
  nasc.cluster.plot <- base.map +
    # Plot nasc data
    geom_point(data = nasc, aes(X, Y), size = 0.5, show.legend = FALSE) +
    # Plot convex hull around NASC clusters
    geom_sf(data = nasc.super.clusters, colour = 'black', alpha = 0.5, show.legend = FALSE) +
    scale_fill_discrete(name = "Cluster") +
    scale_colour_discrete(name = "Cluster") +
    # Plot cluster midpoints
    geom_shadowtext(data = cluster.mid, aes(X, Y, label = cluster),
                    colour = 'gray20', bg.colour = "white", size = 2) +
    # Plot positive trawl cluster midpoints
    geom_shadowtext(data = filter(cluster.mid, cluster %in% super.clusters$cluster), 
                    aes(X, Y, label = cluster, colour = sample.type), 
                    size = 2, bg.colour = "white", fontface = "bold") +
    # Plot panel label
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # save trawl plot
  ggsave(nasc.cluster.plot,
         filename = here("Figs/fig_nasc_cluster_map.png"),
         width = map.width, height = map.height)
  
  save(nasc.cluster.plot, file = here("Output/nasc_cluster_plot.Rdata"))
}

include_graphics(here("Figs/fig_nasc_cluster_map.png"))
```  

## Map trawl-cluster species proportions by weight 

(ref:trawl-species-proportions) Acoustic intervals symbolized by nearest trawl clusters (left) and survey transects performed aboard _`r survey.vessel`_ overlaid with proportions of CPS species in trawl clusters (black points indicate trawl clusters with no CPS, right).

```{r map-trawl-species-proportions,fig.cap='(ref:trawl-species-proportions)'}
# Map trawl species proportions -------------------------------------------------------
if (save.figs) {
  # Create trawl haul and cluster proportion figures
  source(here("Code/plot_haul_proportion_wt.R"))
  source(here("Code/plot_cluster_proportion_wt.R"))
  
  # Combine nasc.cluster.plot and trawl.pie.cluster.wt for report
  nasc.trawl.cluster.wt <- plot_grid(nasc.cluster.plot, trawl.pie.cluster.wt,
                                     nrow = 1, labels = c("a)", "b)"))
  
  ggsave(nasc.trawl.cluster.wt,
         filename = here("Figs/fig_nasc_trawl_cluster_wt.png"),
         width = map.width*2, height = map.height)
  
  save(trawl.pie.cluster.wt, trawl.pie.cluster.wt, nasc.trawl.cluster.wt,
       file = here("Output/trawl_species_proportion_map.Rdata"))
  
} else {
  load(here("Output/trawl_species_proportion_map.Rdata"))
}

include_graphics(here("Figs/fig_nasc_trawl_cluster_wt.png"))
```  

## Process trawl length data  

```{r process-trawl-length-data}
# Process trawl length data -------------------------------------------------------
if (exists("lengthFreq.all")) {
  if (nrow(lengthFreq.all) > 0) {
    # Process binned length data from all surveys
    lengths.expanded.all <- lengthFreq.all %>%
      left_join(select(spp.codes, species, scientificName, commonName)) %>%
      # Remove samples from 4meshnet
      filter(netSampleType == 'codend') %>%
      select(cruise, ship, haul, collection, species, scientificName, length,
             lengthType, sexUnknown, male, totalFemale) %>% 
      gather(sex, count, -cruise, -ship, -haul, -collection, -species, 
             -scientificName, -lengthType, -length) %>%
      filter(count != 0) %>% 
      droplevels() %>% 
      # Expand data frame by counts
      uncount(weights = count)
    
    # Extract data by length type (SL, FL, and TL) and combine
    lengths.expanded.final <- data.frame()
    
    for (i in unique(lengths.expanded.all$lengthType)) {
      l.temp <- filter(lengths.expanded.all, lengthType == i)
      
      names(l.temp)[names(l.temp) == 'length'] <- as.character(i)
      
      lengths.expanded.final <- bind_rows(lengths.expanded.final, l.temp)
    }
    
    # Add missing length columns
    if (is.null(lengths.expanded.final$FL)) {lengths.expanded.final$FL <- NA}
    if (is.null(lengths.expanded.final$SL)) {lengths.expanded.final$SL <- NA}
    if (is.null(lengths.expanded.final$TL)) {lengths.expanded.final$TL <- NA}
    if (is.null(lengths.expanded.final$ML)) {lengths.expanded.final$ML <- NA}
    
    # Remove unwanted columns and rename length columns  
    lengths.expanded.final <- lengths.expanded.final %>% 
      # select(-lengthType, -count) %>%
      rename(forkLength_mm     = FL,
             standardLength_mm = SL,
             totalLength_mm    = TL,
             mantleLength_mm   = ML) %>% 
      mutate(
        flaggedData = "N",
        isRandomSample = "Y",
        binned = TRUE)
  }
}

lengths.all <- lengths.all  %>% 
  mutate(standardLength_mm = as.numeric(standardLength_mm),
         totalLength_mm    = as.numeric(totalLength_mm),
         forkLength_mm     = as.numeric(forkLength_mm),) %>% 
  # Add scientific and common names
  left_join(select(spp.codes, species, scientificName, commonName)) %>%
  # Filter for CPS species
  filter(scientificName %in% cps.spp) %>% 
  # Select desired columns
  select(cruise, ship, haul, collection, species, individual_ID, 
         scientificName, commonName, specimenNumber, 
         standardLength_mm, forkLength_mm, totalLength_mm, 
         sex, weightg, isRandomSample, flaggedData) %>%
  # Convert individual IDs to numeric
  mutate(individual_ID = as.numeric(individual_ID)) %>% 
  # Standardize sex values
  mutate(sex    = tolower(trimws(sex)),
         binned = FALSE) 

# Append expanded binned lengths, if any
if (exists("lengths.expanded.final")) {
  lengths.all <- lengths.all %>% 
  bind_rows(lengths.expanded.final)
}

lengths.all <- lengths.all %>% 
  # Create unique key and replace unused sex categories
  mutate(key = paste(cruise, ship, haul, collection, species, specimenNumber),
         sex = str_replace(sex,"totalFemale","female"),
         sex = str_replace(sex,"sexUnknown","unknown")) %>%
  # Add season from haul
  left_join(select(haul.all, cruise, ship, haul, season)) 

if (survey.name %in% c("1507SH")) {
  # In summer 2015, some herring were measured to SL and some to TL. The code requires fork length
  # as the native length, and there is not a conversion for SL to FL, so SL must first be converted to TL,
  # then TL can be converted to FL
  
  saveRDS(lengths.all, file = here("Output", paste0("lengths_all_", survey.name, ".rds")))
  
  lengths.all <- lengths.all %>% 
    mutate(totalLength_mm = case_when(
      scientificName == "Clupea pallasii" & cruise == cruise.name & !is.na(standardLength_mm) ~ 
        convert_length("Clupea pallasii", .$standardLength_mm, "SL", "TL"),
      TRUE ~ totalLength_mm)) %>% 
    mutate(forkLength_mm = case_when(
      scientificName == "Clupea pallasii" & cruise == cruise.name & is.na(forkLength_mm) ~ 
        convert_length("Clupea pallasii", .$totalLength_mm, "TL", "FL"),
      TRUE ~ forkLength_mm))
}

if (survey.name == "1807RL") {
  # Estimate SL from FL for Anchovy during 1807RL
  lengths.all <- lengths.all %>% 
    mutate(
      standardLength_mm = case_when(
        is.na(standardLength_mm) & scientificName == "Engraulis mordax" ~ (0.965*forkLength_mm - 5.736), 
        TRUE ~ standardLength_mm))  
}

# Save length data to file
save(lengths.all, file = here("Output/lengths_all.Rdata"))

# Convert lengths to totalLength_mm for TS estimates ---------------------------
lengths.all  <- lengths.all %>%
  mutate(
    totalLength_mm = case_when(
      scientificName == "Clupea pallasii" ~ 
        convert_length("Clupea pallasii", .$forkLength_mm, "FL", "TL"),
      scientificName == "Engraulis mordax" ~ 
        convert_length("Engraulis mordax", .$standardLength_mm, "SL", "TL"),
      scientificName == "Sardinops sagax" ~ 
        convert_length("Sardinops sagax", .$standardLength_mm, "SL", "TL"),
      scientificName == "Scomber japonicus" ~ 
        convert_length("Scomber japonicus", .$forkLength_mm, "FL", "TL"),
      scientificName == "Trachurus symmetricus" ~ 
        convert_length("Trachurus symmetricus", .$forkLength_mm, "FL", "TL"),
      scientificName == "Etrumeus acuminatus" ~ 
        convert_length("Etrumeus acuminatus", .$forkLength_mm, "FL", "TL")))
    
if ("mantleLength_mm" %in% names(lengths.all)) {
  lengths.all <- lengths.all %>% 
    mutate(totalLength_mm = case_when(
      scientificName == "Doryteuthis (Loligo) opalescens" ~  as.numeric(mantleLength_mm),
      TRUE ~ totalLength_mm))
}

# Flag missing lengths and filter CPS specimens
lengths.all <- lengths.all %>% 
  mutate(missing.length = case_when(
    is.na(totalLength_mm) ~ TRUE, 
    TRUE ~ FALSE)) %>% 
  filter(scientificName %in% cps.spp)

# Estimate missing weights from lengths -------------------------------------------------------
# Use Palance et al. 2019 models to estimate missing L and W
lengths.all <- lengths.all %>% 
  mutate(
    weightg = case_when(
      is.na(weightg) ~ estimate_weight(.$scientificName, .$totalLength_mm, season = tolower(survey.season)),
      TRUE  ~ weightg),
    totalLength_mm = case_when(
      is.na(totalLength_mm) ~ estimate_length(.$scientificName, .$weightg, season = tolower(survey.season)),
      TRUE ~ totalLength_mm),
    K = round((weightg/totalLength_mm*10^3)*100))

# Filter length data for current cruise and vessel
lengths <- lengths.all %>% 
  # Filter for cruise specific data
  filter(cruise %in% cruise.name & ship %in% cruise.ship & 
           scientificName %in% cps.spp & toupper(isRandomSample) == "Y") %>% 
  filter(!haul %in% haul.rm)

if (survey.name %in% c("2107RL")) {
  # Read specimen data from Carranza
  lengths.jcf <- read_csv(here("Data/Trawl/JCFINP2110_specimens.csv")) %>% 
    mutate(cruise = as.character(cruise.name),
           ship = "JCF",
           collection = haul,
           haul = haul + max.haul.rl) %>% 
    rename(scientificName = species,
           weightg = totalWeightg) %>% 
    mutate(
      key = paste(cruise, ship, collection, consecutiveNumber),
      totalLength_mm = case_when(
        scientificName == "Clupea pallasii" ~ 
          convert_length("Clupea pallasii", .$standardLength_mm, "SL", "TL"),
        scientificName == "Engraulis mordax" ~ 
          convert_length("Engraulis mordax", .$standardLength_mm, "SL", "TL"),
        scientificName == "Sardinops sagax" ~ 
          convert_length("Sardinops sagax", .$standardLength_mm, "SL", "TL"),
        scientificName == "Scomber japonicus" ~ 
          convert_length("Scomber japonicus", .$forkLength_mm, "FL", "TL"),
        scientificName == "Trachurus symmetricus" ~ 
          convert_length("Trachurus symmetricus", .$forkLength_mm, "FL", "TL"),
        scientificName == "Etrumeus acuminatus" ~ 
          convert_length("Etrumeus acuminatus", .$standardLength_mm, "SL", "TL")),
      missing.length = case_when(is.na(totalLength_mm) ~ T, TRUE ~ FALSE)) %>% 
    mutate(
      weightg = estimate_weight(.$scientificName, .$totalLength_mm, season = tolower(survey.season)),
      # weightg = case_when(
      #   is.na(weightg) ~ estimate_weight(.$scientificName, .$totalLength_mm, season = tolower(survey.season)),
      #   TRUE  ~ weightg),
      K = round((weightg/totalLength_mm*10^3)*100),
      sex = case_when(
        gender == 1 ~ "male",
        gender == 2 ~ "female",
        gender == 3 ~ "unknown",
        TRUE ~ NA_character_)) %>% 
    filter(scientificName %in% cps.spp) %>% 
    select(cruise, sex, ship, haul, collection, 
           scientificName,
           standardLength_mm, forkLength_mm, totalLength_mm,
           weightg, missing.length, K, key) %>% 
    # Add season from haul
    left_join(select(haul, haul, season)) 
  
  # ggplotly(ggplot(lengths.jcf, aes(totalLength_mm, weightg, colour = sex, label = key)) + geom_point() + facet_wrap(~scientificName, scales = "free"))
  
  # ggplotly(ggplot(lengths.jcf, aes(forkLength_mm, weightg, colour = sex, label = key)) + geom_point() + facet_wrap(~scientificName, scales = "free"))
  
  # ggplot(lengths.jcf, aes(standardLength_mm, forkLength_mm, label = key)) + geom_point() + facet_wrap(~scientificName)
  
  lengths <- bind_rows(lengths, lengths.jcf)
}

if (survey.name %in% c("2207RL")) {
  # Read specimen data from Lisa Marie in 2022
  ## Code borrowed from Code/processSeine_2207RL.r; same as for nearshore sampling
  lengths.lm.2022 <- read_csv(here("Data/Seine/lm_specimens.csv"), lazy = FALSE) %>% 
    mutate(date = mdy(date),
           ship = "LM",
           key.set = paste(ship, date, set),
           label = paste("Date:", date, "Set:", set, "Fish num:", fish_number),
           scientificName = case_when(
             species_name == "Pacific Herring" ~ "Clupea pallasii",
             species_name == "Pacific Sardine" ~ "Sardinops sagax",
             species_name == "Chub Mackerel" ~ "Scomber japonicus",
             species_name == "Jack Mackerel" ~ "Trachurus symmetricus",
             species_name == "Northern Anchovy" ~ "Engraulis mordax",
             species_name == "Jacksmelt" ~ "Atherinopsis californiensis",
             species_name == "Whitebait Smelt" ~ "Allosmerus elongatus",
             TRUE ~ NA_character_),
           missing.weight = case_when(is.na(weightg)   ~ T, TRUE ~ FALSE),
           missing.length = case_when(is.na(fish_length) ~ T, TRUE ~ FALSE),
           sex = case_when(
             sex_name == "Not Sexed" ~ "unknown",
             TRUE ~ tolower(sex_name))) %>% 
    mutate(
      forkLength_mm = case_when(
        length_type == "Fork length" ~ fish_length,
        TRUE ~ NA_real_),
      standardLength_mm = case_when(
        length_type == "Standard length" ~ fish_length,
        TRUE ~ NA_real_)) %>% 
    filter(scientificName %in% cps.spp, !is.na(set)) %>% 
    mutate(
      totalLength_mm = case_when(
        scientificName == "Clupea pallasii" ~ 
          convert_length("Clupea pallasii", .$forkLength_mm, "FL", "TL"),
        scientificName == "Engraulis mordax" ~ 
          convert_length("Engraulis mordax", .$standardLength_mm, "SL", "TL"),
        scientificName == "Sardinops sagax" ~ 
          convert_length("Sardinops sagax", .$standardLength_mm, "SL", "TL"),
        scientificName == "Scomber japonicus" ~ 
          convert_length("Scomber japonicus", .$forkLength_mm, "FL", "TL"),
        scientificName == "Trachurus symmetricus" ~ 
          convert_length("Trachurus symmetricus", .$forkLength_mm, "FL", "TL"))) %>% 
    mutate(
      weightg = case_when(
        is.na(weightg) ~ estimate_weight(.$scientificName, .$totalLength_mm, season = tolower(survey.season)),
        TRUE  ~ weightg),
      totalLength_mm = case_when(
        is.na(totalLength_mm) ~ estimate_length(.$scientificName, .$weightg, season = tolower(survey.season)),
        TRUE ~ totalLength_mm),
      K = round((weightg/totalLength_mm*10^3)*100)) %>% 
    left_join(select(haul.lm.2022, key.set, haul, cluster)) %>% 
    filter(!is.na(haul)) %>% 
    select(ship, haul, scientificName, standardLength_mm, 
           forkLength_mm, totalLength_mm, weightg, missing.length, sex, K)
  
  # # Read specimen data from Lasker in 2021
  # lengths.2021 <- read_csv("C:/KLS/CODE/Github/estimATM/2107RL/Output/lengths_final.csv") %>%
  #   # select(-cluster) %>%
  #   mutate(
  #     cruise = as.character(cruise),
  #     haul    = haul + max.haul.rl) %>%
  #   # left_join(select(haul, haul, cluster)) %>%
  #   filter(haul %in% hauls.2022)
  # 
  #   # Read specimen data from Lasker in 2021
  # lengths.2019 <- read_csv("C:/KLS/CODE/Github/estimATM/1907RL/Output/lengths_final.csv") %>%
  #   # select(-cluster) %>%
  #   mutate(
  #     cruise = as.character(cruise),
  #     haul    = haul + max.haul.rl) %>%
  #   # left_join(select(haul, haul, cluster)) %>%
  #   filter(haul %in% hauls.2022)

  # Combine length data
  lengths <- bind_rows(lengths, lengths.lm.2022)
  # lengths <- bind_rows(lengths, lengths.2021)
  # lengths <- bind_rows(lengths, lengths.2019)
}

# Get max TL for plotting L/W models
L.max <- lengths %>% 
  group_by(scientificName) %>% 
  summarise(max.TL = max(totalLength_mm, na.rm = TRUE))

# Data frame for storing results
lw.df <- data.frame()

# Generate length/weight curves
for (i in unique(L.max$scientificName)) {
  # Create a length vector for each species
  L <- seq(0, L.max$max.TL[L.max$scientificName == i])
  
  # Calculate weights from lengths
  W <- estimate_weight(i, L, season = tolower(survey.season))
  
  # Combine results
  lw.df <- bind_rows(lw.df, data.frame(scientificName = i, L, W))
}

# Save final length data frames
save(lengths.all, lengths, lw.df,
     file = here("Output/lengths_final.Rdata"))

# Summarize Fulton's condition factor (K) for identifying outliers
K.summ <- lengths %>%
  group_by(scientificName) %>%
  summarise(
    K.lower = quantile(K, probs = 0.001, na.rm = TRUE),
    K.upper = quantile(K, probs = 0.999, na.rm = TRUE))

# Select outliers
length.outliers.all <- lengths %>% 
  left_join(K.summ) %>% 
  filter(K <= K.lower | K >= K.upper) %>% 
  filter(binned == FALSE) %>% 
  select(haul, collection, scientificName, specimenNumber, standardLength_mm, 
         forkLength_mm, totalLength_mm, weightg, sex, K, flaggedData) %>%
  arrange(scientificName, haul, specimenNumber)

# Select only outliers that have not yet been flagged
length.outliers <- length.outliers.all %>%
  filter(is.na(flaggedData))

# Plot lengths and bounds of outliers
length.outlier.plot <- ggplot(lengths, aes(K)) + geom_histogram() +
  geom_vline(data = K.summ, aes(xintercept =  K.lower)) +
  geom_vline(data = K.summ, aes(xintercept =  K.upper)) +
  facet_wrap(~scientificName, scales = "free") +
  xlab("Fulton's Condition Factor (K)") +
  ylab("Frequency") +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "italic"))

# Save length outlier plot
ggsave(length.outlier.plot, 
       filename = here("Figs/fig_length_outliers.png"),
       height = 5, width = 7)

# Write outliers to file
write_csv(length.outliers, here("Output/specimen_outliers.csv"))

# Save final length table
write_csv(lengths, here("Output/lengths_final.csv"))

# Summarise lengths by species
length.summ <- lengths %>% 
  group_by(scientificName) %>% 
  summarise(
    TL.min = round(min(totalLength_mm, na.rm = TRUE)/10,0),
    TL.max = round(max(totalLength_mm, na.rm = TRUE)/10,0),
    SL.min = round(min(standardLength_mm, na.rm = TRUE)/10,0),
    SL.max = round(max(standardLength_mm, na.rm = TRUE)/10,0),
    FL.min = round(min(forkLength_mm, na.rm = TRUE)/10,0),
    FL.max = round(max(forkLength_mm, na.rm = TRUE)/10,0),
    w.min  = round(min(weightg, na.rm = TRUE),1),
    w.max  = round(max(weightg, na.rm = TRUE),1))

# Filter binned lengths for the present survey
lengths.binned <- lengths.all %>%
  filter(cruise %in% cruise.name & ship %in% cruise.ship & 
           scientificName %in% cps.spp & binned == TRUE) %>% 
  droplevels()

# If binned lengths are present, plot their distribution
if (nrow(lengths.binned) > 0) {
  binned.length.plot <- ggplot(lengths.binned, aes(totalLength_mm)) +
    geom_histogram() + 
    facet_wrap(~scientificName, scales = "free") + 
    xlab("Length (cm)") + ylab("Count") +
    theme_bw() +
    theme(strip.background.x = element_blank(),
          strip.text.x = element_text(face = "italic"))
  
  # Save plot
  ggsave(binned.length.plot,
         file = here("Figs/fig_binned_length_histogram.png"),
         height = 6, width = 6)
}

# Save results
save(length.summ, file = here("Output/length_summary_all.Rdata"))

# Save trawl data-final
save(catch, haul, lengths,
     file = here("Data/Trawl/all_trawl_data-final.Rdata"))
```  

## QA/QC of trawl data
### Compare weight from haul and length tables  

The subsampled weight from the **Catch** table (`subSampleWtkg`) should equal the summed weight of subsampled individuals in the **Specimen** table (`totalWtSpecimens`)(i.e., `diffWt` == 0), and the subsample count from the **Catch** table (`subSampleCount`) should equal the number of subsampled individuals in the **Specimen** table (`totalCtSpecimens`)(i.e., `diffCt` == 0). Hauls with unequal values are in **bold**;  count differences are highlighted in yellow and weight differences are highlighted in orange. Hauls with missing specimen lengths our counts are highlighted in red. Hauls where binned lengths were present are highlighted in green.

```{r catch-comparison}
# Summarize individual weights for comparison with total weight in the catch table
summ.lengths <- lengths %>% 
  group_by(scientificName, haul) %>% 
  summarise(
    totalWtSpecimens = sum(weightg)/1000,
    totalCtSpecimens = length(weightg),
    binnedLengths    = sum(binned)) %>% 
  mutate(key = paste(haul, scientificName)) %>% 
  ungroup()

# Merge catch table with weight summary and arrange by species and haul
catch.comp <- left_join(select(catch, ship, haul, scientificName, subSampleWtkg, subSampleCount),
                        select(summ.lengths, haul, scientificName, totalWtSpecimens,
                               totalCtSpecimens, binnedLengths)) %>%
  arrange(scientificName, haul) %>% 
  # Calculate difference between trawl subsample weight and summed weight from individual specimens
  mutate(diffWt    = subSampleWtkg - totalWtSpecimens,
         diffWtPct = abs(diffWt / subSampleWtkg * 100),
         diffCt    = subSampleCount - totalCtSpecimens) %>%
  # Reorder columns
  select(scientificName, ship, haul, subSampleWtkg, totalWtSpecimens, diffWt, 
         diffWtPct, subSampleCount, totalCtSpecimens, diffCt, binnedLengths) %>% 
  replace(is.na(.), -999)

# Write to CSV
write.csv(catch.comp, file = here("Output/catch_comparison.csv"), 
          quote = FALSE, row.names = FALSE)

# Display results
catch.comp %>% 
  mutate(
    totalWtSpecimens = cell_spec(round(totalWtSpecimens,digits = 4),
                                 knitr.format, color = "black",
                                 background = ifelse(is.na(totalWtSpecimens),"red","white")),
    totalCtSpecimens = cell_spec(round(totalCtSpecimens,digits = 4),
                                 knitr.format,color = "black",
                                 background = ifelse(is.na(totalCtSpecimens),"red","white")),
    diffWt           = cell_spec(round(diffWt,digits = 4),
                                 knitr.format,color = "black",
                                 background = ifelse(diffWt == 0,"white","orange")),
    diffCt           = cell_spec(diffCt,knitr.format,color = "black",
                                 background = ifelse(diffCt == 0,"white","yellow")),
    binnedLengths    = cell_spec(binnedLengths,knitr.format,color = "black",
                                 background = ifelse(binnedLengths == 0,"white","green"))) %>%
  kable(format = knitr.format,booktabs = TRUE, escape = FALSE,
        align = c("c","l","l",rep("r",ncol(catch.comp) - 2)),
        digits = c(0,0,0,3,3,4,0,0,0,0),
        format.args = list(big.mark = ",")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"),full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>%
  row_spec(which(catch.comp$diffCt != 0), bold = TRUE) %>%
  row_spec(which(catch.comp$diffWt != 0), bold = TRUE) %>%
  row_spec(0, align = c("c")) %>%
  collapse_rows(columns = 1) %>% 
  scroll_box(height = "500px")

# Filter hauls with diffCt or diffWt != zero
catch.comp.errors <- catch.comp %>% 
  filter(diffCt != 0 | diffWt != 0 | is.na(totalCtSpecimens) | is.na(totalWtSpecimens)) 

# Save output to CSV
if (nrow(catch.comp.errors) > 0) {
  write.csv(catch.comp.errors,file = here("Output/catch_comparison_errors.csv"),quote = FALSE, row.names = FALSE)
}
```  

This table includes only those hauls where `diffWt` and `diffCt` are not equal to zero.  

```{r catch-comparison-errors}
# Filter hauls with diffCt or diffWt != zero
catch.comp.errors <- catch.comp %>% 
  filter(diffCt != 0 | diffWt != 0 | is.na(totalCtSpecimens) | is.na(totalWtSpecimens)) 

# Save output to CSV
if (nrow(catch.comp.errors) > 0) {
  write.csv(catch.comp.errors, file = here("Output/catch_comparison_errors.csv"),
            quote = FALSE, row.names = FALSE)
  
  # Display results
  catch.comp %>% 
    filter(diffCt != 0 | diffWt != 0 | is.na(totalCtSpecimens) | is.na(totalWtSpecimens)) %>% 
    mutate(
      totalWtSpecimens = cell_spec(round(totalWtSpecimens, digits = 4),
                                   knitr.format, color = "black",
                                   background = ifelse(is.na(totalWtSpecimens), "red", "white")),
      totalCtSpecimens = cell_spec(round(totalCtSpecimens, digits = 4),
                                   knitr.format,color = "black",
                                   background = ifelse(is.na(totalCtSpecimens), "red", "white")),
      diffWt           = cell_spec(round(diffWt, digits = 4),
                                   knitr.format, color = "black",
                                   background = ifelse(diffWt == 0, "white", "orange")),
      diffCt           = cell_spec(diffCt, knitr.format, color = "black",
                                   background = ifelse(diffCt == 0, "white", "yellow")),
      binnedLengths    = cell_spec(binnedLengths, knitr.format, color = "black",
                                   background = ifelse(binnedLengths == 0, "white", "green"))) %>% 
    arrange(haul, scientificName) %>% 
    kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
          align = c("c","l","l",rep("r",ncol(catch.comp) - 2)),
          digits = c(0,0,0,3,3,4,0,0,0,0),
          format.args = list(big.mark = ",")) %>% 
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>%
    row_spec(0, align = c("c")) %>%
    collapse_rows(columns = 1) %>% 
    scroll_box(height = "250px") 
  
} else {
  print("Hooray, no (obvious) errors!")
}
```

### Examine potential length errors

Specimens below include potential outliers based on the distribution of Fulton's condition factor (_K_; $(w/TL^3)*100$).

```{r lw-outlier-table}
# Print table of length outliers
if (nrow(length.outliers) == 0) {
  cat("No outilers detected.")
} else {
  length.outliers %>%
    rename(SL = standardLength_mm, TL = totalLength_mm, FL = forkLength_mm) %>% 
    mutate(TL = round(TL)) %>% 
    # replace_na(list(SL = "", TL = "", FL = "", flaggedData = "")) %>%
    kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
          align = c("c","l",rep("r",ncol(length.outliers) - 2)),
          digits = c(0,0,3,3,4,0,0,0,0,0)) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
    column_spec(3, italic = TRUE) %>%
    row_spec(0, align = c("c")) %>%
    scroll_box(height = "500px")
}
```

### Examine specimen L-W data  

The relationship between length and weight of all specimens is visually compared to those from historic surveys and also to L/W models derived from those specimens (**Insert references to Palance et al.; present equations.**). If missing length or weight measurements are present, they are estimated from these models using the following equations and the coefficients in the table below:  

$$W = a*L^b\text{,  and}$$  

$$L = (W/a)^{(1/b)}\text{.}$$   

Coefficients used to estimate total length (TL, mm) or weight in the equations above. Model types are: 'lm' = linear model, 'nlm' = naive linear model, and 'glm' = general linear model [@Palance2019]. Season is presently either spring or summer, and is defined in the survey info file.    

```{r lw-model-table, eval = FALSE}
# # Filter table of L/W models used
# lw.models %>% 
#   arrange(scientificName) %>% 
#   left_join(select(spp.codes, scientificName, commonName)) %>%
#   select(scientificName, commonName, everything()) %>% 
#   rename(`Scientific name` = scientificName,
#          `Common name`     = commonName,
#          `Model type`      = model_type) %>% 
#   kable(format = knitr.format,booktabs = TRUE, escape = FALSE,
#         digits = c(0,0,8,5,0),
#         align = c("l","l","r","r","l")) %>% 
#   kable_styling(bootstrap_options = c("striped","hover","condensed"), 
#                 full_width = FALSE) %>%
#   row_spec(0, align = c("c")) %>%
#   column_spec(1, italic = TRUE)
```  

(ref:lw-plot) Length-weight relationships from the current survey [pink (female), blue (male), and green (unknown) points] and all previous surveys in the same season (gray points). Dashed lines represent the modeled (linear model with bias correction) relationships between length and weight for each species during the survey season. Large red and blue points indicate individuals where length or weight (typically individuals with binned lengths) were missing, respectively. Those missing values were estimated using the relationship between length and weight for each species.

```{r plot-lw-data,fig.cap='(ref:lw-plot)'}
# Plot L/W data from past and current survey -----------------------------------
lw.plot <- ggplot() + 
  # Plot L/W data from all years/surveys
  geom_point(data = filter(lengths.all, 
                           scientificName %in% unique(lengths$scientificName),
                           season == tolower(survey.season)), 
             aes(totalLength_mm, weightg),
             colour = "gray70", alpha = 0.3) +
  # Plot seasonal length models for each species
  geom_line(data = filter(lw.df, scientificName %in% unique(lengths$scientificName)), 
            aes(L, W), linetype = 'dashed') +
  scale_colour_manual(name = "Season", values = c("forestgreen","blue")) +
  # Plot L/W data for current survey
  geom_point(data = lengths, 
             aes(totalLength_mm, weightg,group = sex, fill = sex), 
             shape = 21, alpha = 0.9) + 
  scale_fill_manual(name = "Sex", values = c("pink","lightblue","green")) +
  # Plot individuals with missing lengths and weights
  geom_point(data = filter(lengths, missing.length == TRUE), 
             aes(totalLength_mm, weightg),
             shape = 21, fill = 'red',  size = 2.5) +
  # geom_point(data = filter(lengths, missing.weight == TRUE), 
  #            aes(totalLength_mm, weightg),
  #            shape = 21, fill = 'blue', size = 2.5) +
  # Facet by species
  facet_wrap(~scientificName, scales = "free") +
  # Format plot
  xlab("Total length (mm)") + ylab("Mass (g)") +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "italic"))

# save length/weight plot
ggsave(lw.plot, filename = here("Figs/fig_LW_plots.png"),
       width = 10, height = 7) 

# Examine length differences by leg
lengths.leg <- lengths %>% 
  
  left_join(select(haul, haul, datetime = equilibriumTime)) %>% 
  mutate(leg = cut(as.numeric(date(datetime)), leg.breaks, labels = FALSE))

lw.plot.leg <- ggplot() + 
  # Plot seasonal length models for each species
  geom_line(data = filter(lw.df, scientificName %in% unique(lengths$scientificName)), 
            aes(L, W), linetype = 'dashed') +
  # Plot L/W data for current survey
  geom_point(data = lengths.leg, 
             aes(totalLength_mm, weightg, group = sex, fill = factor(leg)), 
             shape = 21, alpha = 0.9) + 
  scale_fill_discrete(name = "Leg") +
  # Plot individuals with missing lengths and weights
  geom_point(data = filter(lengths, missing.length == TRUE), 
             aes(totalLength_mm, weightg),
             shape = 21, fill = 'red',  size = 2.5) +
  # geom_point(data = filter(lengths, missing.weight == TRUE), 
  #            aes(totalLength_mm, weightg),
  #            shape = 21, fill = 'blue', size = 2.5) +
  # Facet by species
  facet_wrap(~scientificName, scales = "free") +
  # Format plot
  xlab("Total length (mm)") + ylab("Mass (g)") +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "italic"))

# save length/weight plot
ggsave(lw.plot.leg, filename = here("Figs/fig_LW_plots_leg.png"),
       width = 10, height = 7) 

# Add L/W plot
include_graphics(here("Figs/fig_LW_plots.png"))
```

# Process CUFES data

## Import CUFES data  

During surveys, or for surveys for which CUFES data have not been verified and uploaded to SQL Server, data in SQLite format may be obtained by contacting [Amy Hays](Amy.Hays@NOAA.gov). To import from the SQL Server, a machine ODBC connection must be configured to the CUFES databases on the Estrella server (IP address: 161.55.235.187). To request access to the CUFES database, contact [Ed Weber](Ed.Weber@NOAA.gov). 

```{r import-cufes-data}
if (get.db) {
  if (cufes.source == "SQLite") {
    # Configure ODBC connection to TRAWL database
    cufes.filename <- path_file(dir_ls(here("Data/CUFES"), regexp = "*.sqlite"))
    cufes.con      <- dbConnect(SQLite(), dbname = here("Data/CUFES", cufes.filename))
    # Create the pointer to the CUFES table
    cufes.all <- tbl(cufes.con, "cufessqlite") %>% collect()
    
    # Close connection
    dbDisconnect(cufes.con)  
  } else if (cufes.source == "SQL") {
    cufes.con  <- dbConnect(odbc::odbc(), 
                            Driver = "SQL Server", 
                            Server = "161.55.235.187", 
                            Database = "CUFES", 
                            Trusted_Connection = "True")
    # Create the pointer to the CUFES table
    cufes.all <- tbl(cufes.con, "CUFES") %>% collect()
    
    # Close connection
    dbDisconnect(cufes.con)  
  } else if (cufes.source == "CSV") {
    # cufes.source = "CSV"
    cufes.filename <- file.path(here("Data/CUFES", cufes.db.csv))
    
    cufes.all <- read_csv(cufes.filename) %>% 
      mutate(Cruise = as.character(Cruise))
    
    if (is.null(cufes.all$Comments)) cufes.all$Comments <- NA_character_
  }
  
  # Read CUFES data
  cufes.all <- cufes.all %>%
    # collect() %>% 
    mutate(
      Start = case_when(
        cufes.date.format == "mdy" ~ mdy_hms(Start), #"06/01/2019-15:43:00"
        cufes.date.format == "ymd" ~ ymd_hms(Start)),#"1996-03-15 15:43:00 -08:00"
      Stop = case_when(
        cufes.date.format == "mdy" ~ mdy_hms(Stop), #"06/01/2019-15:43:00"
        cufes.date.format == "ymd" ~ ymd_hms(Stop)),#"1996-03-15 15:43:00 -08:00"
      Duration = as.numeric(difftime(Stop, Start, units = "mins")),
      Year = year(Start),
      AllEggs = SardineEggs + AnchovyEggs + JackMackerelEggs) %>% 
    filter(between(Start, date(cufes.start), date(cufes.end)),
           Ship == cruise.ship) 
  
  if (survey.name %in% c("1507SH")) {
    cufes.all <- cufes.all %>% 
      rename(lat = StopLatitude, long = StopLongitude) %>% 
      project_df(to = crs.proj)
  } else {
    cufes.all <- cufes.all %>% 
      rename(lat = StartLatitude, long = StartLongitude)%>% 
      project_df(to = crs.proj)
  }
  
  # Save imported database data to .Rdata file
  save(cufes.all, file = here("Data/CUFES/cufes_data.Rdata"))
} else {
  # Load previously imported database data
  load(here("Data/CUFES/cufes_data.Rdata"))
}
```  

## Process CUFES data

```{r process-cufes-data}
# For Summer 2021, remove CUFES counts from Mexico that include positive sardine eggs
if (survey.name %in% c("2107RL")) {
  cufes.all$SardineEggs[date(cufes.all$Start) >= date("2021-10-07")] <- 0
}

# Convert cufes to long format for plotting
cufes <- cufes.all %>% 
  select(
    SampleNumber, Year, Ship, Cruise, lat, long, X, Y, Duration, 
    SardineEggs, AnchovyEggs, JackMackerelEggs, SquidEggs, HakeEggs, OtherFishEggs,
    Comments) %>%
  gather(Species, Counts, -SampleNumber, -Year, -Ship, -Cruise, 
         -lat, -long, -X, -Y, -Duration, -Comments) %>% 
  mutate(Density = Counts/Duration/0.64,
         # Create bins for defining point size in NASC plots
         bin = cut(Density, cufes.breaks, include.lowest = T),
         bin.level = as.numeric(bin)) %>% 
  left_join(select(cufes.all, SampleNumber, Start, Stop)) 

if (survey.name %in% c("2107RL")) {
  # Import and format CUFES data from Carranza
  cufes.jcf.all <- read_csv(here("Data/CUFES/cufes_jcfinp2110_rev.csv")) %>% 
    mutate(Start = with_tz(dmy_hms(paste(date, startLocalTime), tz = "America/Los_Angeles"), tzone = "UTC"),
           Stop  = with_tz(dmy_hms(paste(date, stopLocalTime), tz = "America/Los_Angeles"), tzone = "UTC"),
           Ship  = "JCF",
           Cruise = as.character(cruise.name),
           Duration = as.numeric(difftime(Stop, Start, units = "mins")),
           Year = year(Start),
           AllEggs = SardineEggs + AnchovyEggs + JackMackerelEggs) %>% 
    rename(lat = startLatDecimal,
           long = startLongDecimal) %>% 
    project_df(to = crs.proj) 
  
  # Convert to long form
  cufes.jcf <- cufes.jcf.all %>% 
    select(
      SampleNumber, Year, Ship, Cruise, lat, long, X, Y, Duration, 
      SardineEggs, AnchovyEggs, JackMackerelEggs, SquidEggs, HakeEggs, OtherFishEggs,
      Comments) %>% 
    gather(Species, Counts, -SampleNumber, -Year, -Ship, -Cruise, 
           -lat, -long, -X, -Y, -Duration, -Comments) %>% 
    mutate(Density = Counts/Duration/0.64,
           # Create bins for defining point size in NASC plots
           bin = cut(Density, cufes.breaks, include.lowest = T),
           bin.level = as.numeric(bin)) %>% 
    left_join(select(cufes.jcf.all, SampleNumber, Start, Stop))
  
  # Combine with CUFES data from Lasker
  cufes     <- bind_rows(cufes, cufes.jcf)
  cufes.all <- bind_rows(cufes.all, cufes.jcf.all)
  
  # ggplot(cufes, aes(long, lat, colour = Ship)) + geom_point() + coord_map()
}

# Select CUFES data from CPS
cufes.plot <- cufes %>% 
  filter(Density > 0, Species %in% cufes.plot.spp) %>%
  arrange(desc(Density))

# Select CUFES sample with zero density for plotting
cufes.neg <- filter(cufes.all, AllEggs == 0) %>%
  filter(Cruise %in% cruise.name,
         Ship %in% cufes.vessels,
         AllEggs == 0, !is.na(Duration)) %>%
  mutate(bin.level = 1) %>% 
  select(X, Y, SampleNumber)

# Identify bad CUFES samples
cufes.bad <- filter(cufes.all, Duration <= 0)

save(cufes.bad, file = here("Output/cufes_bad.Rdata"))

# Write CUFES data from current survey to CSV
write.csv(cufes, file = here("Output/cufes_data.csv"), 
          row.names = FALSE, quote = FALSE)
```  

## Map CUFES egg densities 

(ref:cufes-egg-densities) Egg densities (eggs m^-3^) for anchovy, jack mackerel, and sardine from the CUFES. Crosses indicate CUFES samples with no eggs from any CPS species. Point size indicates egg density and point color indicates species.

```{r map-cufes-egg-density,fig.cap='(ref:cufes-egg-densities)'}
if (save.figs) {
  # Plot CUFES for sardine, anchovy, and jack mackerel -------------------------  
  source(here("Code/plot_cufes.R"))
  
  save(cufes.density.all, cufes.density.facet,
       file = here("Output/cufes_egg_density_maps.Rdata"))
  
} else {
  load(here("Output/cufes_egg_density_maps.Rdata"))
}

include_graphics(here("Figs/fig_cufes_egg_density.png"))
```  

## Combine backscatter, CUFES, and species proportion plots  

(ref:nasc-cufes-trawl-wt) The a) distribution of 38-kHz integrated backscattering coefficients (_s_~A~, m^2^ nmi^-2^; averaged over 2000-m distance intervals and from 5 to 70-m deep) ascribed to CPS; b) CUFES egg density (eggs m^-3^) for anchovy, sardine, and jack mackerel; and c) proportions of CPS species in trawl clusters (by weight, black points indicate trawls with no CPS).

```{r nasc-cufes-trawl-wt,fig.cap='(ref:nasc-cufes-trawl-wt)'}
if (save.figs) {
  # Combine backscatter, CUFES, and trawl maps
  nasc.cufes.trawl.plot      <- plot_grid(nasc.map.cps, cufes.density.all, trawl.pie.haul.wt,
                                          nrow = 1, labels = c("a)", "b)", "c)"))
  
  nasc.cufes.trawl.plot.long <- plot_grid(nasc.map.cps, cufes.density.all, trawl.pie.haul.wt,
                                          ncol = 1, labels = c("a)", "b)", "c)"))
  # Save maps
  ggsave(nasc.cufes.trawl.plot, 
         filename = here("Figs/fig_nasc_cufes_haul_wt.png"),
         width = map.width*3, height = map.height)
  
  ggsave(nasc.cufes.trawl.plot.long, 
         filename = here("Figs/fig_nasc_cufes_haul_wt_long.png"),
         width = map.width, height = map.height*3)
  
  save(nasc.cufes.trawl.plot, nasc.cufes.trawl.plot.long, 
       file = here("Output/nasc_cufes_trawl_map.Rdata"))
}

include_graphics(here("Figs/fig_nasc_cufes_haul_wt_long.png"))
```

# Calculate target strengths (TS) from lengths 
## Calculate TS from TL  

View the parameters used to estimate target strength in the `{atm::estimate_ts}` function.

```{r estimate-target-strength}
# Import TS calculation variables, if needed
# Currently these variable are not used; rather variables are hard-coded
# in the estimate_ts() function above
ts.vars <- read.csv(here("Data/Acoustic/ts_variables.csv"))

# Estimate TS
ts.df <- estimate_ts(lengths$scientificName, lengths$totalLength_mm)

# Add TS estimates to lengths data frame
lengths <- bind_cols(lengths, select(ts.df, -species, -TL)) %>% 
  # Add cluster to lengths data frame
  left_join(select(haul, haul, cluster)) %>% 
  # Arrange
  arrange(scientificName, collection, specimenNumber)

# Save results
write.csv(ts.df,   file = here("Output/ts_estimates.csv"), quote = FALSE, row.names = FALSE)
write.csv(lengths, file = here("Output/ts_lengths.csv"),   quote = FALSE, row.names = FALSE)
```  

## Plot TS estimates  

(ref:target-strength-comparison) To determine whether target strength is being calculated correctly, target strength estimates (_TS_~ind~, white points) are compared to theoretical target strength (black line) (top). The frequency distribution of target strength (_TS_~ind~) for each species is also examined (bottom).

```{r plot-target-strength,fig.cap='(ref:target-strength-comparison)'}
# Calculate theoretical TS for each species
ts.theory <- data.frame()

for (i in unique(length.max$species)) {
  ts.theory <- bind_rows(ts.theory,
                         estimate_ts(i, seq(0, length.max$sl[length.max$species == i]*10, 0.5)))
}

# Rename columns to match lengths data frame
ts.theory <- ts.theory %>% 
  rename(scientificName = species, totalLength_mm = TL) %>% 
  filter(between(TS.ind, min(lengths$TS.ind), max(lengths$TS.ind))) %>% 
  filter(scientificName %in% unique(lengths$scientificName))

# Create scatter plot of theoretical vs. estimated TS for each species
ts.theory.plot <- ggplot(ts.theory) + 
  geom_line(aes(totalLength_mm, TS.ind)) + 
  geom_point(data = lengths, aes(totalLength_mm, TS.ind), 
             shape = 21, fill = "white") + 
  facet_wrap(~scientificName, scales = "free_x", nrow = 1) +
  xlab("\nTotal length (mm)") + 
  ylab(expression(italic(TS)[ind]~(dB))) +
  theme_bw() +  
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "bold.italic")) 

ts.width = n_distinct(ts.theory$scientificName) * 2

# Save theoretical TS plot
ggsave(ts.theory.plot, 
       filename = here("Figs/fig_ts_theoretical_scatter.png"), 
       width = ts.width, height = 2)

# Create TS histrograms by species
ts.histogram <- ggplot(lengths) + 
  geom_histogram(aes(TS.ind)) + 
  facet_wrap(~scientificName, scales = "free_x", nrow = 1) + 
  xlab(expression(italic(TS)[ind]~(dB))) + 
  ylab("\nFrequency") +
  theme_bw() +  
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "bold.italic")) +
  coord_flip()

# Save estimated TS histogram
ggsave(ts.histogram, 
       filename = here("Figs/fig_ts_histograms.png"), 
       width = ts.width, height = 2)

# Combine scatter plot and histogram
ts.combo.plot <- plot_grid(ts.theory.plot, ts.histogram,
                           ncol = 1, align = "v")

# Save combination plot
ggsave(ts.combo.plot, 
       filename = here("Figs/fig_ts_combo_plot.png"), 
       height = 4, width = ts.width)

include_graphics(here("Figs/fig_ts_combo_plot.png"))
```  

## Plot sigma estimates  

(ref:plot-sigmas) Comparison of sigma estimates using the methods of **X** (x-axis) and **Y** (y-axis) by a) haul and b) cluster. If done correctly, all points should fall along the 1-to-1 lines.

```{r plot-sigmas,fig.cap='(ref:plot-sigmas)'}
# Plot TS estimates
sigma.plot <- ggplot(lengths, aes(1/sigma.wg,1/sigma.ind*estimated.wg)) + 
  geom_point() + geom_abline() + 
  facet_wrap(~scientificName,scales = "free") + 
  xlab("\n1/sigma.wg") + 
  ylab("1/sigma.ind*estimated.wg\n") +
  theme_bw() +  
  theme(strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "italic"))      
# save TS plot
ggsave(sigma.plot,
       filename = here("Figs/fig_sigma_plots.png"), 
       width = 10, height = 7)   

include_graphics(here("Figs/fig_sigma_plots.png"))
```

# Calculate acoustic proportions
## Calculate acoustic proportion by number  
Summarize all data to produce the final file used to estimate the biomass of each species.  

First, total number from each haul is estimated from the subsample weight, subsample count, and total weight. Next, total numbers from each haul are summed over each trawl cluster. The summary by haul and cluster are plotted to look for errors.  

(ref:summarize-ts) A comparison of cross-sectional backscatter coefficient estimates per weight and individual. If done correctly, all points should fall along the 1-to-1 lines.

```{r summarize-ts,fig.cap='(ref:summarize-ts)'}
# Calculate numeric abundance by species and haul
n.summ.haul <- catch %>% 
  group_by(scientificName, cluster, haul) %>%
  filter(netSampleType %in% c('codend', NA)) %>% 
  summarise(num = totalWeight/(subSampleWtkg/subSampleCount))

# Summarise weights and sigmas by haul
l.summ.haul <- lengths %>% 
  group_by(scientificName, cluster, haul) %>% 
  summarise(
    meanwg       = mean(estimated.wg),
    sigmaindiv   = mean(sigma.ind),
    sigmawg      = sum(estimated.wg*sigma.wg)/sum(estimated.wg)) %>% 
  left_join(n.summ.haul) %>% 
  filter(!is.na(cluster))

# Summarise weights and sigmas by cluster
l.summ.cluster <- l.summ.haul %>% 
  group_by(scientificName, cluster) %>% 
  summarise(
    num.tot    = sum(num),
    meanwg.c   = sum(meanwg*num)/sum(num),
    sigmawg    = sum(meanwg*sigmawg*num)/sum(meanwg*num),
    sigmaindiv = sum(sigmaindiv*num)/sum(num)) %>% 
  rename(
    num    = num.tot,
    meanwg = meanwg.c)

# Create a data frame with abbreviations
trawl.ts.names <- data.frame(
  scientificName = c("Clupea pallasii","Engraulis mordax","Etrumeus acuminatus", 
                     "Sardinops sagax","Scomber japonicus","Trachurus symmetricus"),
  shortName      = c("her","anch","rher",
                     "sar","mack","jack"))

# Combine results to compare with Juan's output
for (k in unique(l.summ.haul$scientificName)) {
  # Summarize length summary by species
  l.summ.tmp <- l.summ.haul %>%
    filter(scientificName == k) %>% 
    ungroup() %>% 
    select(haul, sigmawg, sigmaindiv)
  
  # Rename columns per species
  names(l.summ.tmp)[2:3] <- paste(names(l.summ.tmp)[2:3], 
                                  trawl.ts.names$shortName[trawl.ts.names$scientificName == k], 
                                  sep = ".")
  
  # Combine results
  if (exists("trawl.ts")) {
    trawl.ts <- full_join(trawl.ts, l.summ.tmp) %>% 
      arrange(haul)
  } else {
    trawl.ts <- l.summ.tmp
  }
}

# Write results to CSV
write.csv(n.summ.haul, file = here("Output/n_summ_haul.csv"), 
          quote = FALSE, row.names = FALSE)
write.csv(l.summ.haul, file = here("Output/l_summ_haul.csv"), 
          quote = FALSE, row.names = FALSE)
write.csv(l.summ.cluster, file = here("Output/l_summ_cluster.csv"), 
          quote = FALSE, row.names = FALSE)
write.csv(trawl.ts, file = here("Output/trawl_ts_EstimateCPS.csv"), 
          quote = FALSE, row.names = FALSE, na = "0")

if (save.figs) {
  # Compare results to check for errors in haul summary
  sigma.plot.haul <- ggplot(l.summ.haul, aes(1/sigmaindiv*meanwg, 1/sigmawg)) + 
    geom_point() +
    geom_abline(intercept = 0, slope = 1) + 
    facet_wrap(~scientificName,scales = 'free') +
    theme_bw() +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "italic"))
  
  # Compare results to check for errors in cluster summary
  sigma.plot.cluster <- ggplot(l.summ.cluster, aes(1/sigmaindiv*meanwg, 1/sigmawg)) + 
    geom_point() +
    geom_abline(intercept = 0, slope = 1) + 
    facet_wrap(~scientificName,scales = 'free') +
    theme_bw() +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "italic"))
  
  # Combine results of haul and cluster summaries and save
  sigma.plot.all <- plot_grid(sigma.plot.haul, sigma.plot.cluster, 
                              nrow = 2, align = 'h', labels = c("a)","b)"))
  ggsave(sigma.plot.all, 
         filename = here("Figs/fig_sigma_comparisons_all.png"), 
         height = 10, width = 10)  
}

include_graphics(here("Figs/fig_sigma_comparisons_all.png"))
```  

## Calculate acoustic proportion by weight  

The mean weight of each species in each cluster is estimated by 1) estimatiing the expected weight of each fish in each trawl using the the length-to-weight relationship in the `estimate_ts` function, 2) calculating the mean weight per trawl using the expected weights in Step 1), and 3) calculating the mean weight per cluster as the weighted average of the the trawl mean weight (from Step 2) and using the number of fish per trawl for weighting.  

```{r summarize-ts-by-weight}
# Summarize target strength proportions by cluster and species
ts.summ <- select(l.summ.cluster, cluster, scientificName, 
                  meanwg, num, sigmawg, sigmaindiv) %>% 
  ungroup()

# Save to file
write.csv(ts.summ, file = here("Output/ts_summ_cluster.csv"), 
          quote = FALSE, row.names = FALSE)

# Subset sardine results
ts.sub.sar <- filter(ts.summ, scientificName == "Sardinops sagax") %>% 
  select(-scientificName)
names(ts.sub.sar) <- paste(names(ts.sub.sar), "sar", sep = ".")
# Subset anchovy results
ts.sub.anch <- filter(ts.summ, scientificName == "Engraulis mordax") %>% 
  select(-scientificName)
names(ts.sub.anch) <- paste(names(ts.sub.anch), "anch", sep = ".")
# Subset mackerel results
ts.sub.mack <- filter(ts.summ, scientificName == "Scomber japonicus") %>% 
  select(-scientificName)
names(ts.sub.mack) <- paste(names(ts.sub.mack), "mack", sep = ".")
# Subset jack mackerel results
ts.sub.jack <- filter(ts.summ, scientificName == "Trachurus symmetricus") %>% 
  select(-scientificName)
names(ts.sub.jack) <- paste(names(ts.sub.jack), "jack", sep = ".") 
# Subset P. herring results
ts.sub.her <- filter(ts.summ, scientificName == "Clupea pallasii") %>% 
  select(-scientificName)
names(ts.sub.her) <- paste(names(ts.sub.her), "her", sep = ".") 
# Subset round herring results
ts.sub.rher <- filter(ts.summ, scientificName == "Etrumeus acuminatus") %>% 
  select(-scientificName)
names(ts.sub.rher) <- paste(names(ts.sub.rher), "rher", sep = ".") 
# Subset "other" results
ts.sub.other <- filter(ts.summ, scientificName == "Other") %>% 
  select(-scientificName)
names(ts.sub.other) <- paste(names(ts.sub.other), "other", sep = ".") 
```  

# Create final files for biomass estimation  
## Summarize `sigmawg` and `sigmaindiv`  

Calculate and combine sigmas by weight (`sigmawg`) and number (`sigmaindiv`) for each species and summarize total CPS catch by weight (`CPS.wg`) and number (`CPS.num`).

```{r combine-species-proportions}
# Combine all TS estimates
# Add sardine TS estimates to trawl clusters
clf <- cluster.mid %>% 
  left_join(ts.sub.sar,by  = c("cluster" = "cluster.sar")) %>% 
  # Add anchovy TS estimates to clf
  left_join(ts.sub.anch,by = c("cluster" = "cluster.anch")) %>% 
  # Add mackerel TS estimates to clf
  left_join(ts.sub.mack,by = c("cluster" = "cluster.mack")) %>% 
  # Add jack mackerel TS estimates to clf
  left_join(ts.sub.jack,by = c("cluster" = "cluster.jack")) %>% 
  # Add P. herring TS estimates to clf
  left_join(ts.sub.her,by  = c("cluster" = "cluster.her")) %>% 
  # Add round herring TS estimates to clf
  left_join(ts.sub.rher,by  = c("cluster" = "cluster.rher")) %>% 
  # Add other TS estimates to clf
  left_join(ts.sub.other,by  = c("cluster" = "cluster.other"))

# Calculate total CPS number in each cluster
catch.summ.num <- clf %>% 
  group_by(cluster) %>% 
  summarise(CPS.num = sum(num.sar, num.anch, num.mack, num.jack, 
                          num.her, num.rher, num.other, na.rm = TRUE))

# Calculate total CPS weight in each cluster
cluster.summ.wt <- catch %>% 
  filter(scientificName %in% cps.spp) %>% 
  group_by(cluster) %>% 
  summarise(CPS.wg = sum(totalWeight))

# Replace NA's with 0's
clf[is.na(clf)] <- 0

# Save to file
write_csv(clf, file = here("Output/clf_cluster_summary.csv"))
```  

## Calculate acoustic proportions  

The acoustic proportion, by number, of each species in each trawl cluster is computed as the product of the number of fish and it's sigma divided by the weighted average number of all species present.

The acoustic proportion, by weight, of each species in each trawl cluster is computed similarly, but with a nuance. TS per weight has embedded the length-weight relationship of each species, meaning that the cluster weight of a given species will not be the actual measured weight, but instead the product of the number of each species and their expected mean weight.

```{r calculate-acoustic-proportions}
# Calculate species proportion (weighted average, by number and weight) in each trawl cluster  
ts.proportions <- clf %>% 
  group_by(cluster) %>% 
  summarise(
    # Calculate the weighted number of each species
    weighted.num = (num.sar     * sigmaindiv.sar  + 
                      num.anch    * sigmaindiv.anch +
                      num.her     * sigmaindiv.her  +
                      num.mack    * sigmaindiv.mack + 
                      num.jack    * sigmaindiv.jack + 
                      num.rher    * sigmaindiv.rher + 
                      num.other   * sigmaindiv.other),
    # Calculate the weighted weight of each species
    weighted.wg  = (meanwg.sar  * num.sar  * sigmawg.sar +
                      meanwg.anch * num.anch * sigmawg.anch + 
                      meanwg.her  * num.her  * sigmawg.her +
                      meanwg.mack * num.mack * sigmawg.mack + 
                      meanwg.jack * num.jack * sigmawg.jack + 
                      meanwg.rher * num.rher * sigmawg.rher + 
                      meanwg.other* num.other* sigmawg.other),
    # Calculate the proportion, by number and weight, for each species
    prop.sar     = (num.sar     * sigmaindiv.sar)  / weighted.num,
    prop.sar.wg  = (meanwg.sar  * sigmawg.sar  * num.sar) / weighted.wg,
    prop.anch    = (num.anch    * sigmaindiv.anch) / weighted.num,
    prop.anch.wg = (meanwg.anch * sigmawg.anch * num.anch) / weighted.wg,
    prop.mack    = (num.mack    * sigmaindiv.mack) / weighted.num,
    prop.mack.wg = (meanwg.mack * sigmawg.mack * num.mack) / weighted.wg,
    prop.jack    = (num.jack    * sigmaindiv.jack) / weighted.num,
    prop.jack.wg = (meanwg.jack * sigmawg.jack * num.jack) / weighted.wg,
    prop.her     = (num.her     * sigmaindiv.her)  / weighted.num,
    prop.her.wg  = (meanwg.her  * sigmawg.her  * num.her) / weighted.wg,
    prop.rher    = (num.rher    * sigmaindiv.rher)  / weighted.num,
    prop.rher.wg = (meanwg.rher * sigmawg.rher  * num.rher) / weighted.wg,
    prop.other   = (num.other   * sigmaindiv.other)  / weighted.num,
    prop.other.wg= (meanwg.other* sigmawg.other  * num.other) / weighted.wg) %>% 
  replace(is.na(.), 0) 

# Replace all NaNs with zeros
ts.proportions[atm:::is.nan.df(ts.proportions)] <- NA

# Save to file
write_csv(ts.proportions, file = here("Output/ts_proportions_raw.csv"))

# Add cluster weights, numbers, and TS proportions
clf <- clf %>% 
  left_join(catch.summ.num,  by = 'cluster') %>% 
  left_join(cluster.summ.wt, by = 'cluster') %>% 
  left_join(ts.proportions,  by = 'cluster')

# Replace 0's with 1's for sigmaindiv and sigmawg when proportions == 0
clf$sigmaindiv.anch[clf$prop.anch == 0]   <- 1
clf$sigmaindiv.her[clf$prop.her   == 0]   <- 1
clf$sigmaindiv.jack[clf$prop.jack == 0]   <- 1
clf$sigmaindiv.mack[clf$prop.mack == 0]   <- 1
clf$sigmaindiv.sar[clf$prop.sar   == 0]   <- 1
clf$sigmaindiv.rher[clf$prop.rher == 0]   <- 1
clf$sigmaindiv.other[clf$prop.other == 0] <- 1

clf$sigmawg.anch[clf$prop.anch    == 0]   <- 1
clf$sigmawg.her[clf$prop.her      == 0]   <- 1
clf$sigmawg.jack[clf$prop.jack    == 0]   <- 1
clf$sigmawg.mack[clf$prop.mack    == 0]   <- 1
clf$sigmawg.sar[clf$prop.sar      == 0]   <- 1
clf$sigmawg.rher[clf$prop.rher    == 0]   <- 1
clf$sigmawg.other[clf$prop.other  == 0]   <- 1

# Add sample type and adjusted to clf, for combination with seine data and for
# when species proportions must be adjusted (e.g., 2022, N of Cape Mendocino)
clf <- clf %>%
  mutate(adjusted = as.logical(FALSE))

# Save to file
write_csv(clf, file = here("Output/clf_ts_proportions.csv"))

save(clf, file = here("Output/clf_ts_proportions.Rdata"))

# In summer 2022, sardine proportions were adjusted based on catches from 2018-2021
# and for clusters with sardine present, jack mackerel were assumed to make up the remaining proportion
if (survey.name == "2207RL") {
  # Read file adjusted by Juan
  clf.adjusted <- read_csv(here("Output/clf_ts_proportions_JPZ.csv"))
  
  # Replace existing clf file
  clf <- clf.adjusted
}

# Calculate haul length frequencies, for use with nearshore sampling
source(here("Code/calculate_haul_length_frequency.R"))
```

## Map acoustic proportions by number and weight  

(ref:map-acoustic-proportions) CPS catch in each trawl cluster is mapped by a) proportion of total weight, b) acoustic proportion by number, and c) acoustic proportion by weight; if done correctly, panels b) and c) should be the same.

```{r map-acoustic-proportions,fig.cap='(ref:map-acoustic-proportions)'}
# Get acoustic proportions for mapping
acoustic.prop.indiv <- clf %>%
  filter(!is.na(CPS.wg), CPS.wg > 0) %>% 
  select(cluster, lat, long, prop.anch, prop.jack, prop.her,
         prop.mack, prop.sar, prop.rher, prop.other, sample.type) %>% 
  replace(. == 0, 0.0000001) %>% 
  project_df(to = crs.proj)

acoustic.prop.wg <- clf %>%
  filter(!is.na(CPS.wg), CPS.wg > 0) %>% 
  select(cluster, lat, long, prop.anch.wg, prop.jack.wg, prop.her.wg,
         prop.mack.wg, prop.sar.wg, prop.rher.wg, prop.other.wg, sample.type) %>% 
  replace(. == 0, 0.0000001) %>% 
  project_df(to = crs.proj)

if (save.figs) {
  # Create trawl figure
  acoustic.prop.cluster.indiv <- base.map +
    # Plot transects data
    geom_sf(data = transects.sf, size = 0.5, colour = "gray70", 
            alpha = 0.75, linetype = "dashed") +
    # plot ship track data
    geom_sf(data = nav.paths.sf, colour = "gray50", size = 0.5, alpha = 0.5) +
    # Plot trawl pies
    geom_scatterpie(data = acoustic.prop.indiv, 
                    aes(X, Y, group = cluster, r = pie.radius, colour = sample.type),
                    cols = c("prop.anch","prop.her","prop.jack",
                             "prop.mack", "prop.rher", "prop.sar", "prop.other"),
                    alpha = 0.8) +
    # Plot empty trawl locations
    geom_point(data = cluster.zero, aes(X, Y),
               size = 3, shape = 21, fill = 'black', colour = 'white') +
    # Configure pie outline colors
    scale_colour_manual(name = "Sample type", 
                        labels = c("Purse seine", "Trawl"),
                        values = c("Seine" = seine.color, "Trawl" = trawl.color),
                        guide = "none") +
    # Configure trawl scale
    scale_fill_manual(name = 'Species',
                      labels = c("Anchovy", "P. herring", "J. mackerel",
                                 "P. mackerel", "R. herring", "Sardine", "Other"),
                      values = c(anchovy.color, pac.herring.color, jack.mack.color,  
                                 pac.mack.color, rnd.herring.color,
                                 sardine.color, other.color)) +
    # Plot panel label
    ggtitle("Acoustic Proportions (Number) by Cluster") +
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Create trawl figure
  acoustic.prop.cluster.wg <- base.map +
    # Plot transects data
    geom_sf(data = transects.sf, size = 0.5, colour = "gray70", 
            alpha = 0.75, linetype = "dashed") +
    # plot ship track data
    geom_sf(data = nav.paths.sf, colour = "gray50", size = 0.5, alpha = 0.5) +
    # Plot trawl pies
    geom_scatterpie(data = acoustic.prop.wg, 
                    aes(X, Y, group = cluster, r = pie.radius, colour = sample.type),
                    cols = c("prop.anch.wg","prop.her.wg","prop.jack.wg",
                             "prop.mack.wg", "prop.rher.wg", "prop.sar.wg", "prop.other.wg"),
                    alpha = 0.8) +
    # Plot empty trawl locations
    geom_point(data = cluster.zero, aes(X, Y),
               size = 3, shape = 21, fill = 'black', colour = 'white') +
    # Configure pie outline colors
    scale_colour_manual(name = "Sample type", 
                        labels = c("Purse seine", "Trawl"),
                        values = c("Seine" = seine.color, "Trawl" = trawl.color),
                        guide = "none") +
    # Configure trawl scale
    scale_fill_manual(name = 'Species',
                      labels = c("Anchovy", "P. herring", "J. mackerel",
                                 "P. mackerel", "R. herring", "Sardine", "Other"),
                      values = c(anchovy.color, pac.herring.color, jack.mack.color,  
                                 pac.mack.color, rnd.herring.color,
                                 sardine.color, other.color)) +
    # Plot panel label
    ggtitle("Acoustic Proportions (Weight) by Cluster") +
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Combine acoustic proportion maps
  acoustic.prop.comparison <- plot_grid(acoustic.prop.cluster.indiv, 
                                        acoustic.prop.cluster.wg,
                                        nrow = 1, labels = c("a)", "b)"))
  
  # Save trawl species proportions plots
  ggsave(acoustic.prop.comparison,
         filename = here("Figs/fig_acoustic_proportion_comparison.png"),
         width = map.width*2, height = map.height)
  
  save(acoustic.prop.cluster.indiv, acoustic.prop.cluster.wg,
       file = here("Output/acoustic_proportion_comp_map.Rdata"))
  
} else {
  load(here("Output/acoustic_proportion_comp_map.Rdata"))
}

include_graphics(here("Figs/fig_acoustic_proportion_comparison.png"))
```

## Create final backscatter, CUFES, and acoustic proportion maps  

(ref:map-nasc-cufes-acoustic-proportion) Survey transects overlaid with (a) the distribution of 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^;  averaged over 2000-m distance intervals and from `r int.start`- to `r cps.depth`-m deep) ascribed to CPS; (b) egg densities (eggs m^-3^) for Northern Anchovy, Jack Mackerel, and Pacific Sardine from the CUFES; and (c) acoustic proportions of CPS species in each trawl cluster (black points indicate trawls with no CPS).

```{r map-nasc-cufes-acoustic-proportion,fig.cap='(ref:map-nasc-cufes-acoustic-proportion)'}
# Create trawl figure
acoustic.prop.cluster.final <- base.map +
  # Plot transects data
  geom_sf(data = transects.sf, size = 0.5, colour = "gray70", 
          alpha = 0.75, linetype = "dashed") +
  # plot ship track data
  geom_sf(data = nav.paths.sf, colour = "gray50", size = 0.5, alpha = 0.5) +
  # Plot trawl pies
  geom_scatterpie(data = acoustic.prop.indiv, 
                  aes(X, Y, group = cluster, r = pie.radius, colour = sample.type),
                  cols = c("prop.anch","prop.her","prop.jack",
                           "prop.mack", "prop.rher", "prop.sar","prop.other"),
                  color = 'black', alpha = 0.8) +
  # Plot empty trawl locations
  geom_point(data = cluster.zero, aes(X, Y),
             size = 3, shape = 21, fill = 'black', colour = 'white') +
  # Configure pie outline colors
  scale_colour_manual(name = "Sample type", 
                      labels = c("Purse seine", "Trawl"),
                      values = c("Seine" = seine.color, "Trawl" = trawl.color),
                      guide = "none") +
  # Configure trawl scale
  scale_fill_manual(name = 'Species',
                    labels = c("Anchovy", "P. herring", "J. mackerel", 
                               "P. mackerel", "R. herring", "Sardine", "Other"),
                    values = c(anchovy.color, pac.herring.color, jack.mack.color, 
                               pac.mack.color, rnd.herring.color, sardine.color, other.color)) +
  coord_sf(crs = crs.proj, 
           xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
           ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))

if (save.figs) {
  nasc.cufes.prop.plot      <- plot_grid(nasc.map.cps, cufes.density.all, acoustic.prop.cluster.final,
                                         nrow = 1, labels = c("a)", "b)", "c)"))
  
  nasc.cufes.prop.plot.long <- plot_grid(nasc.map.cps, cufes.density.all, acoustic.prop.cluster.final,
                                         ncol = 1, labels = c("a)", "b)", "c)"))
  
  # Plot trawl clusters and acoustic proportions
  nasc.trawl.acoustic.prop <- plot_grid(nasc.cluster.plot, acoustic.prop.cluster.final,
                                        nrow = 1, labels = c("a)", "b)"))
  # Save maps
  ggsave(nasc.cufes.prop.plot, 
         filename = here("Figs/fig_nasc_cufes_acoustic_cluster.png"),
         width = map.width*3, height = map.height)
  
  ggsave(nasc.cufes.prop.plot.long, 
         filename = here("Figs/fig_nasc_cufes_acoustic_cluster_long.png"),
         width = map.width, height = map.height*3)  
  
  ggsave(nasc.trawl.acoustic.prop, 
         filename = here("Figs/fig_nasc_acoustic_cluster.png"),
         width = map.width*2, height = map.height)
  
  save(nasc.cufes.prop.plot, nasc.cufes.prop.plot.long, nasc.trawl.acoustic.prop,
       file = here("Output/nasc_cufes_prop_map.Rdata"))
}

include_graphics(here("Figs/fig_nasc_cufes_acoustic_cluster_long.png"))
```

## Create final cluster-length-frequency files  

Calculate length frequencies and create final files for biomass estimation.  

```{r calculate-length-frequencies}
# Calculate length frequencies for each species and trawl cluster --------------------
# Create a list for storing final species-specific cluster results
haul.final    <- list()
cluster.final <- list()
lf.final      <- data.frame()

# For each species, calculate length frequencies, combine with clf, and write final file
for (i in unique(lengths$scientificName)) {
  # Create a data frame for results
  lf.df <- data.frame()
  
  for (ii in unique(lengths$haul)) {
    # Subset specimen data by species and trawl cluster
    lengths.sub <- droplevels(filter(lengths, scientificName == i & haul == ii))
    # Define length bins
    lf.breaks <- seq(length.min - 0.5, length.max$sl[length.max$species == i] + 0.5, 1)
    lf.labels <- seq(length.min, length.max$sl[length.max$species == i], 1)
    # Calculate the proportion (histogram density) of individuals in each size class
    # Setting right = F includes X.5 in the lower class (e.g., 14.5 = 14, 14.6 = 15)
    # Length inputs are native lengths (i.e., SL for sardine and anchovy, FL for herring and mackerels)
    if (i %in% c("Sardinops sagax", "Engraulis mordax")) {
      f <- hist(lengths.sub$standardLength_mm/10, breaks = lf.breaks, plot = FALSE, right = FALSE)$density      
    } else if (i %in% c("Scomber japonicus", "Trachurus symmetricus", "Clupea pallasii", "Etrumeus acuminatus")) {
      f <- hist(lengths.sub$forkLength_mm/10, breaks = lf.breaks, plot = FALSE, right = FALSE)$density        
    }
    # Create a vector of size class
    lf.bin <- lf.breaks[1:length(lf.breaks) - 1]
    # Create a vector of cluster number
    # haul <- rep(ii, length(f))
    # Add results to data frame
    lf.df <- rbind(lf.df, data.frame(haul = ii, lf.bin, lf.labels, f))
  }
  
  # Replace NaN values with zeros
  lf.df$f[is.nan(lf.df$f)] <- 0
  
  # Get estimated numbers of individuals for each haul
  n.summ.haul.sub <- filter(n.summ.haul, as.character(scientificName) == i) %>% 
    select(haul,cluster,num)
  
  # Add estimated total number of individuals in each cluster (based on subsample weight) 
  # to the length frequency data frame
  lf.df <- left_join(lf.df, n.summ.haul.sub) %>% 
    rename(spp.num = num) %>% 
    replace_na(list(spp.num = 0)) %>%
    mutate(counts = f * spp.num) 
  
  
  # Summarise lengths by cluster, to filter subsequent data frames
  lf.df.summ <- lf.df %>% 
    group_by(cluster, haul) %>% 
    summarise(nIndiv = sum(counts)) %>% 
    filter(nIndiv > 0)
  
  
  # Calculate the estimated number of individuals in each size class
  lf.df <- lf.df %>% 
    mutate(counts = f * spp.num) %>% 
    filter(is.na(cluster) == FALSE)
  
  # Combine length frequency data for plotting later
  lf.final <- bind_rows(lf.final, lf.df)
  
  # Reshape data frame by cluster for adding to clf
  lf.table <- reshape2::dcast(lf.df, cluster ~ lf.labels, value.var = 'counts', sum, margins = 'lf.labels')
  lf.table.h <- reshape2::dcast(lf.df, haul ~ lf.labels, value.var = 'counts', sum, margins = 'lf.labels')
  
  # Convert counts to relative frequencies
  lf.table[ ,2:ncol(lf.table)] <- lf.table[ , 2:ncol(lf.table)]/lf.table$`(all)`
  lf.table.h[ ,2:ncol(lf.table.h)] <- lf.table.h[ , 2:ncol(lf.table.h)]/lf.table.h$`(all)`
  
  # Rename columns
  names(lf.table)[2:ncol(lf.table)] <- paste0("L",names(lf.table)[2:ncol(lf.table)])
  lf.table <- left_join(select(cluster.mid, cluster), lf.table)
  
  names(lf.table.h)[2:ncol(lf.table.h)] <- paste0("L",names(lf.table.h)[2:ncol(lf.table.h)])
  lf.table.h <- left_join(select(haul.mid, haul), lf.table.h) %>% 
    ungroup() %>% 
    select(-cluster)
  
  # Replace NA values with zeros
  lf.table[is.na(lf.table)] <- 0
  lf.table.h[is.na(lf.table.h)] <- 0
  
  # Add length frequencies for each species to clf for final analysis
  clf.final <- left_join(clf, lf.table, by = 'cluster')
  hlf.final <- left_join(hlf, lf.table.h, by = "haul")
  
  # Add the species name to clf (for plotting)
  clf.final$species <- i
  hlf.final$species <- i
  
  # Write final data frame to .csv for each species
  write_csv(clf.final,
            file = paste0(here("Output/cluster_length_frequency_"), 
                          i, "_",survey.name, ".csv"))
  write_csv(hlf.final,
            file = paste0(here("Output/haul_length_frequency_"), 
                          i, "_",survey.name, ".csv"))
  
  # Add species-specific results to list of results
  cluster.final[[i]] <- clf.final
  haul.final[[i]]    <- hlf.final
  
  # Plot length frequencies by species and cluster
  lf.plot <- ggplot(lf.df, aes(lf.labels, counts)) + geom_bar(stat = 'identity') + 
    facet_wrap(~cluster,scales = 'free_y') + theme_bw() + 
    xlab("Standard length (cm)") + ylab("Counts") + ggtitle(i)
  
  lf.plot.haul <- ggplot(lf.df, aes(lf.labels, counts)) + geom_bar(stat = 'identity') + 
    facet_wrap(~haul,scales = 'free_y') + theme_bw() + 
    xlab("Standard length (cm)") + ylab("Counts") + ggtitle(i)
  
  # Save plot
  ggsave(lf.plot, 
         filename = paste0(here("Figs/fig_cluster_length_frequency_"), i, ".png"),
         height = 7, width = 10)
  
  ggsave(lf.plot.haul, 
         filename = paste0(here("Figs/fig_haul_length_frequency_"), i, ".png"),
         height = 7, width = 10)
}

# In summer 2022, the clf files for sardine and jack mackerel were adjusted N of Cape Mendocino
  # Read adjusted files from 
if (survey.name == "2207RL") {
  cluster.final.sar.adj  <- read_csv(here("Output/cluster_length_frequency_Sardinops sagax_2207RL_JPZ.csv"))
  cluster.final.jack.adj <- read_csv(here("Output/cluster_length_frequency_Trachurus symmetricus_2207RL_JPZ.csv"))
  
  # Replace cluster.final[[i]] for sardine and jack mackerel
  cluster.final[["Sardinops sagax"]]       <- cluster.final.sar.adj
  cluster.final[["Trachurus symmetricus"]] <- cluster.final.jack.adj
}

# Save results
save(cluster.final, file = here("Output/cluster_length_frequency_all.Rdata"))
save(haul.final,    file = here("Output/haul_length_frequency_all.Rdata"))
save(lf.final,      file = here("Output/cluster_length_frequency_tables.Rdata"))
```

## Combine species proportions and integrated acoustic data  

Species proportions by weight and number are assigned to each 100-m vertically integrated acoustic sample to estimate abundance and biomass.  

```{r create-final-nasc-file}
# Save nasc and clf for troubleshooting
save(nasc, clf, hlf, file = here("Output/nasc_clf.Rdata"))

# Join NASC and cluster length frequency data frames by cluster
nasc <- nasc %>% 
  left_join(select(clf, -lat, -long, -X, -Y), by = c("cluster" = "cluster"))

# Substitute cps.nasc, if necessary
if (survey.name == "1707RL") {
  # Apply correction to cps.nasc for herring off Vancouver Is.
  # North of 48N, cps.nasc is the lesser of cps.nasc and NASC.70
  # Preserve cps.nasc (cps.nasc.orig)
  nasc <- nasc %>% 
    mutate(
      cps.nasc.orig = cps.nasc,
      cps.nasc = case_when(
        lat > 48.0275 & cps.nasc > NASC.70 ~ NASC.70,
        TRUE ~ cps.nasc))  
} else {
  # Substitute NASC.70 for cps.nasc where herring are present AND
  # where cps.nasc > NASC.70
  nasc <- nasc %>% 
    mutate(
      cps.nasc.orig = cps.nasc,
      cps.nasc = case_when(
        prop.her > 0 ~ NASC.70,
        TRUE ~ cps.nasc))
}

# Save results
save(nasc, file = here("Output/cps_nasc_prop.Rdata"))

# Write results to CSV
write.csv(nasc, file = here("Output/cps_nasc_prop.csv"), 
          quote = FALSE, row.names = FALSE)
```  

# Define sampling strata  
## Map acoustic proportions by species  

For each species, the relative proportion of acoustic backscatter (e.g., `prop.anch`) is mapped along with the acoustic backscatter from all CPS (i.e., `cps.nasc`).  

(ref:apportion-backscatter) Proportion of backscatter from each species (red points) relative to the total backscatter from all species (black points).

```{r apportion-backscatter,fig.cap='(ref:apportion-backscatter)'}
# Create data frame for plotting acoustic proportions by species
nasc.prop.all <- nasc %>%
  mutate(`Engraulis mordax`      = cps.nasc*prop.anch,
         `Sardinops sagax`       = cps.nasc*prop.sar,
         `Trachurus symmetricus` = cps.nasc*prop.jack,
         `Scomber japonicus`     = cps.nasc*prop.mack,
         `Clupea pallasii`       = cps.nasc*prop.her,
         `Etrumeus acuminatus`   = cps.nasc*prop.rher) # %>% project_df(to = crs.proj)

# Prepare nasc.prop.all for facet plotting
nasc.prop.spp <- nasc.prop.all %>% 
  select(X, Y, `Engraulis mordax`, `Sardinops sagax`, `Trachurus symmetricus`,
         `Scomber japonicus`, `Clupea pallasii`, `Etrumeus acuminatus`) %>% 
  gather(scientificName, nasc, -X, -Y)

if (save.figs) {
  # Create a base map with relative CPS backscatter
  map.prop.all <- base.map + 
    # Plot backscatter for all CPS nasc
    geom_point(data = nasc.prop.all, aes(X, Y, size = cps.nasc), 
               colour = "gray20") +
    # Plot proportion of backscatter from each species present
    geom_point(data = filter(nasc.prop.spp, nasc > 0),
               aes(X, Y, size = nasc), colour = "red") +
    # Facet by species
    facet_wrap(~scientificName, nrow = 2) +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "italic")) +
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Save map
  ggsave(here("Figs/fig_nasc_acoustic_proportions.png"), map.prop.all,
         width = map.width*3, height = map.height*2)
  
  # Save plot objects
  save(map.prop.all, file = here("Output/acoustic_proportion_maps.Rdata"))
  
} else {
  
  # Load plot objects
  load(here("Output/acoustic_proportion_maps.Rdata"))
}

include_graphics(here("Figs/fig_nasc_acoustic_proportions.png"))
```  

## Summarize biomass density by transect 

For each species, biomass density is summarized by transect, and is one criteria for defining sampling strata. Only two consecutive transects where log10(biomass + 1) = 0 are allowed withing a sampling strata, and each strata must have a transect with zero biomass on each end.

```{r estimate-acoustic-biomass-density}
# Calculate biomass density for each species (units = tons/nmi^2)
nasc <- nasc %>% 
  mutate( 
    anch.dens = cps.nasc*prop.anch / (4*pi*sigmawg.anch) / 1000,
    her.dens  = cps.nasc*prop.her  / (4*pi*sigmawg.her)  / 1000,
    jack.dens = cps.nasc*prop.jack / (4*pi*sigmawg.jack) / 1000,
    mack.dens = cps.nasc*prop.mack / (4*pi*sigmawg.mack) / 1000,
    sar.dens  = cps.nasc*prop.sar  / (4*pi*sigmawg.sar)  / 1000,
    rher.dens = cps.nasc*prop.rher / (4*pi*sigmawg.rher) / 1000)

# Add other.dens?

# Format for plotting
nasc.density <- nasc %>%
  select(transect, transect.orig, int, lat, long, 
         anch.dens, her.dens, jack.dens, mack.dens, sar.dens, rher.dens) %>% 
  # When transects have multiple sections (e.g., 041-1, 041-2), interval is not unique
  # So create a int.key for computing density along unique intervals for plotting
  mutate(int.key = paste(transect.orig, int)) %>% 
  # Then summarize by transect and unique interval
  group_by(transect, int.key) %>%
  summarise(
    lat = lat[1],
    long = long[1],
    `Engraulis mordax`      = mean(anch.dens),
    `Clupea pallasii`       = mean(her.dens),
    `Trachurus symmetricus` = mean(jack.dens),
    `Scomber japonicus`     = mean(mack.dens),
    `Sardinops sagax`       = mean(sar.dens),
    `Etrumeus acuminatus`   = mean(rher.dens)) %>% 
  gather(scientificName, density, -transect, -int.key, -lat, -long) %>% 
  mutate(bin       = cut(density, dens.breaks, include.lowest = TRUE),
         bin.level = as.numeric(bin))

# Summarise biomass density by transect and species
nasc.density.summ <- nasc.density %>% 
  group_by(scientificName, transect) %>% 
  summarise(density = mean(density)) %>% 
  filter(scientificName %in% unique(lengths$scientificName)) %>% 
  left_join(select(tx.labels.tmp, -end.lat, -end.long, -brg))

# Save biomass density data
save(nasc.density, nasc.density.summ, 
     file = here("Output/nasc_biomass_density.Rdata"))

write_csv(nasc.density, here("Output/nasc_density.csv"))
write_csv(nasc.density.summ, here("Output/nasc_density_summary.csv"))

# Select legend objects 
dens.levels.all <- sort(unique(nasc.density$bin.level))
dens.labels.all <- dens.labels[dens.levels.all]
dens.sizes.all  <- dens.sizes[dens.levels.all]
dens.colors.all <- dens.colors[dens.levels.all]

# Combine haul summaries and cluster midpoints
pos.clusters <- n.summ.haul %>% 
  left_join(cluster.mid) %>% 
  mutate(stock = case_when(
    scientificName == "Engraulis mordax" & lat >= stock.break.anch ~ "Northern",
    scientificName == "Engraulis mordax" & lat <  stock.break.anch ~ "Central",
    scientificName == "Sardinops sagax"  & lat >= stock.break.sar  ~ "Northern",
    scientificName == "Sardinops sagax"  & lat <  stock.break.sar  ~ "Southern",
    scientificName %in% c("Clupea pallasii","Scomber japonicus",
                          "Trachurus symmetricus", "Etrumeus acuminatus") ~ "All"))

# ggplot(pos.clusters, aes(long, lat, label = cluster, colour = stock)) + geom_point() + coord_map() + facet_wrap(~scientificName)
```  

## Examine distances between acoustic intervals and positve trawl clusters 

(ref:frequency-by-cluster-distance) Frequency (top) and cumulative density (bottom) of positive 100 m-long acoustic intervals (i.e., intervals with CPS backscatter present) versus distance to the nearest positive trawl cluster.

```{r frequency-by-cluster-distance,fig.cap='(ref:frequency-by-cluster-distance)'}
# Summarize acoustic density by species and distance from nearest trawl cluster
# Compute distance between NASC intervals and positive trawl clusters
nasc.clust.hist <- nasc %>% 
  select(cluster.distance, anch.dens, her.dens, 
         jack.dens, mack.dens, sar.dens, rher.dens) %>% 
  rename(     
    `Engraulis mordax`      = anch.dens,
    `Clupea pallasii`       = her.dens,
    `Trachurus symmetricus` = jack.dens,
    `Scomber japonicus`     = mack.dens,
    `Sardinops sagax`       = sar.dens,
    `Etrumeus acuminatus`   = rher.dens,) %>% 
  gather(species, density, -cluster.distance)

# Export nasc cluster histogram data
save(nasc.clust.hist, file = here("Output/cluster_distance_data.Rdata"))

# Plot histogram of positive interval distance
clust.dist.hist <- ggplot(filter(nasc.clust.hist, density > 0)) + 
  geom_histogram(aes(cluster.distance)) + 
  facet_wrap(~species, nrow = 1) + 
  theme_bw() + 
  xlab("Distance to positive cluster (nmi)") + 
  ylab("Frequency") +
  # ggtitle("Positive Intervals") +
  theme(axis.title.x = element_blank(),
        strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "italic"))

# Plot ECDF of positive interval distance
clust.dist.ecdf <- ggplot(filter(nasc.clust.hist, density > 0)) + 
  stat_ecdf(aes(cluster.distance)) + 
  facet_wrap(~species, nrow = 1) + 
  theme_bw() + 
  xlab("Distance to positive cluster (nmi)") + 
  ylab("Cumulative density") +
  theme(strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "italic"))

# Combine plots
clust.dist.all <- plot_grid(clust.dist.hist, clust.dist.ecdf, 
                            ncol = 1, align = "v")

# Save plot
ggsave(clust.dist.all, 
       file = here("Figs/fig_cluster_interval_distance_histogram.png"), 
       height = 5, width = 10)

include_graphics(here("Figs/fig_cluster_interval_distance_histogram.png"))
```  

## Examine cumulative acoustic biomass by distance to nearest positive trawl cluster  

(ref:biomass-by-cluster-distance) Total (top) and cumulative (bottom) acoustic biomass versus distance to the nearest positive trawl cluster.

```{r biomass-by-cluster-distance,fig.cap='(ref:biomass-by-cluster-distance)'}
# Compute acoustic biomass for each interval versus distance to positive clusters
nasc.clust.biom <- nasc.clust.hist %>% 
  filter(density > 0) %>% 
  mutate(
    dist.bin = cut(cluster.distance,
                   seq(0, ceiling(max(cluster.distance)), 
                       ceiling(max(cluster.distance)/30)),
                   labels = FALSE) - 1) %>% 
  group_by(species, dist.bin) %>% 
  summarise(total.density = sum(density)) %>% 
  mutate(distance = dist.bin * ceiling(max(nasc$cluster.distance)/30))

nasc.clust.biom.summ <- nasc.clust.biom %>%
  group_by(species) %>%
  summarise(max.density = sum(total.density))

# Calculate cumulative acoustic biomass versus distance to positive clusters
nasc.clust.biom <- nasc.clust.biom %>% 
  left_join(nasc.clust.biom.summ) %>% 
  group_by(species) %>% 
  mutate(cum.biom = cumsum(total.density),
         rel.cum.biom = cum.biom/max(cum.biom),
         prop.biom = total.density/sum(total.density))

# Summarize ECDF to get max cluster distance to X % cumulative biomass
nasc.clust.biom.summ <- nasc.clust.biom %>% 
  group_by(species) %>% 
  summarise(max.cluster.dist = distance[min(which(rel.cum.biom >= cum.biomass.limit))])

# Plot histogram of acoustic biomass
clust.biom.hist <- ggplot(nasc.clust.biom, aes(distance, prop.biom)) + 
  geom_bar(stat = "identity") + 
  facet_wrap(~species, nrow = 1) +
  theme_bw() + xlab("Distance to positive cluster (nmi)") + 
  ylab("Biomass-Proportion") +
  # ggtitle("Biomass") +
  theme(axis.title.x = element_blank(),
        strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "italic"))

# Plot ECDF
clust.biom.ecdf <- ggplot(nasc.clust.biom, aes(distance, rel.cum.biom)) + 
  geom_line() + 
  geom_vline(data = nasc.clust.biom.summ, 
             aes(xintercept = max.cluster.dist),
             linetype = "dashed") +
  facet_wrap(~species, nrow = 1) +
  theme_bw() + 
  xlab("Distance to positive cluster (nmi)") + 
  ylab("Biomass-Cumulative") +
  theme(strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "italic"))

# Combine plots
clust.biom.all <- plot_grid(clust.biom.hist, clust.biom.ecdf, 
                            ncol = 1, align = "v")

# Save plot
ggsave(clust.biom.all, 
       file = here("Figs/fig_cluster_distance_cumulative_biomass.png"), 
       height = 5, width = 10)

include_graphics(here("Figs/fig_cluster_distance_cumulative_biomass.png"))
```

## Determine transect spacing  

Transect spacing is measured as the shortest distance between the midpoint of each transect and the midpoint of all other transects. Transect spacing is one consideration of the algorithm used to automatically select sampling strata for biomass estimation.  

```{r estimate-transect-spacing}
# Get transect spacing for plotting --------------------------
# Get the midpoint (mean) lat/long of each transect
tx.mid <- nasc %>% 
  group_by(vessel.name, transect, transect.name) %>% 
  summarise(
    lat  = mean(lat, na.rm = TRUE),
    long = mean(long, na.rm = TRUE)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog)

# Create a data frame for results
# tx.nn <- data.frame()

for (i in unique(tx.mid$transect)) {
  # Get the mid lat/long for each transect
  tx.i      <- filter(tx.mid, transect == i)
  # Get midpoint data for all other transects
  tx.others <- filter(tx.mid, transect != i, vessel.name %in% tx.i$vessel.name)
  # Get the transect info and spacing based on shortest distance
  # Find nearest feature
  nn.tx <- st_nearest_feature(tx.i, tx.others)
  # Calculate distance between nearest transect
  min.dist <- distGeo(as_Spatial(tx.i), as_Spatial(tx.others[nn.tx,]))*0.000539957
  
  # Add results to sf object
  tx.i <- tx.i %>% 
    mutate(nn.tx = nn.tx,
           min.dist = min.dist)
  
  # Add to results
  if (exists("tx.nn")) {
    tx.nn <- bind_rows(tx.nn, tx.i)
  } else {
    tx.nn <- tx.i
  }
  
  
  # # Get NASC data for all other transects
  # nasc.temp <- filter(tx.mid, transect != i, vessel.name %in% tx.i$vessel.name)
  # # Calculate distance between transect midpoint and all other NASC values
  # nn.dist   <- swfscMisc::distance(tx.i$lat, tx.i$long,
  #                                  nasc.temp$lat, nasc.temp$long)
  # # Get the transect info and spacing based on shortest distance
  # nn.tx     <- nasc.temp$transect[which.min(nn.dist)]
  # min.dist  <- nn.dist[which.min(nn.dist)]
  # nn.lat    <- nasc.temp$lat[which.min(nn.dist)]
  # nn.long   <- nasc.temp$long[which.min(nn.dist)]
  # # Add to results
  # tx.nn     <- bind_rows(tx.nn, 
  #                        data.frame(tx.i, nn.tx, min.dist, nn.lat, nn.long))
}

# Bin transects by spacing
tx.nn <- tx.nn %>% 
  mutate(dist.bin = cut(tx.nn$min.dist, tx.spacing.bins),
         spacing  = tx.spacing.dist[as.numeric(dist.bin)],
         dist.cum = cumsum(spacing)) %>% 
  arrange(transect)

# Save nearest neighbor distance info
save(tx.nn, file = here("Output/transect_spacing.Rdata"))

# Add tx.nn info to nasc density summary
# load(here("Output/nasc_biomass_density.Rdata"))
nasc.density.summ <- nasc.density.summ %>% 
  left_join(select(tx.nn, transect, vessel.name, dist.cum, dist.bin)) %>% 
  mutate(positive = density > 0)
```

## Create final sampling strata  

Sampling strata are defined automatically according to survey vessel, transect spacing, coastline features, and 
biomass density. For a stratum to be included in the analysis, it must:

* Contain a minimum of `r nTx.min` transects,
* Have a transect with zero biomass at the beginning and end,
* Have no more than two consecutive zero biomass transects. 

If the strata are unable to be defined automatically using the rules above, the analyst may define them manually in the appropriate survey info file (e.g., `r paste("Code/survey_info_", survey.name,".R")`). 

```{r stratify-sampling}
# Define sampling strata
if (stratify.manually) {
  # Use manually defined strata
  strata.final <- strata.manual %>% 
    mutate(stratum.orig = stratum)
  
} else {
  # Define strata automatically
  strata.final <- data.frame()
  
  # Define strata boundaries and transects for each species
  for (i in unique(nasc.density.summ$scientificName)) {
    # Select positive transects and calculate differences between transect numbers
    # diffs >= 2 define stratum breaks
    temp.spp <- filter(nasc.density.summ, scientificName == i) %>% 
      filter(positive == TRUE) %>% 
      mutate(diff = c(1, diff(transect))) %>% 
      ungroup()
    
    if (nrow(temp.spp) > 0) {
      # Find the start of each positive stratum
      spp.starts <- temp.spp %>% 
        filter(diff > max.diff) 
      
      # If the start of the stratum == 1, stratum start is 1, else min transect number
      survey.start <- ifelse(min(temp.spp$transect) == 1, 1, min(temp.spp$transect) - 1)
      
      # A vector of stratum starts
      stratum.start <- c(survey.start, spp.starts$transect - 1)
      
      # If the end of the stratum is the last transect in the survey, 
      # select the last, else the last transect + 1
      survey.end <- ifelse(max(temp.spp$transect) == max(nasc.density.summ$transect),
                           max(nasc.density.summ$transect),
                           max(temp.spp$transect) + 1)
      
      # A vector of stratum ends
      stratum.end <- c(temp.spp$transect[which(temp.spp$diff > max.diff) - 1] + 1, 
                       survey.end)
      
      # Combine starts and ends in to a data frame for plotting and generating stratum vectors
      strata.spp <- data.frame(scientificName = i, 
                               stratum = seq(1,length(stratum.start)),
                               start = stratum.start,
                               end = stratum.end) %>% 
        mutate(n.tx = end - start + 1)
      
      # Create stratum vectors
      strata.df <- data.frame()
      for (j in 1:nrow(strata.spp)) {
        # Create a vector of transects from start to end
        transect <- seq(strata.spp$start[j],strata.spp$end[j])
        
        # Combine results
        strata.df <- bind_rows(strata.df, 
                               data.frame(scientificName = i, 
                                          stratum = j,
                                          transect))
      }
      
      # Add vessel name and distance bin to strata.df for final cuts
      strata.df <- strata.df %>% 
        left_join(filter(select(nasc.density.summ, transect, vessel.name, dist.bin), 
                         scientificName == i)) %>% 
        mutate(stratum.key = factor(paste(stratum,vessel.name,dist.bin))) 
      
      # Summarise strata by key, remove strata with less than 3 transects, 
      # and reassign stratum numbers
      strata.df.summ <- strata.df %>% 
        group_by(stratum.key) %>% 
        summarise(n.tx = n()) %>% 
        filter(n.tx >= nTx.min) %>% 
        mutate(stratum = seq(1, n()))
      
      # Remove strata with less than minimum number of transects
      strata.df <- strata.df %>% 
        rename(stratum.orig = stratum) %>% 
        filter(stratum.key %in% strata.df.summ$stratum.key) %>% 
        left_join(select(strata.df.summ, stratum.key, stratum))
      
      # Combine with stratum vectors for other species
      strata.final <- bind_rows(strata.final, strata.df)
    }
  }
}

# Add start latitude and longitude to strata table
strata.final <- strata.final %>% 
  left_join(select(tx.labels.tmp, -end.lat, -end.long, -brg)) %>% 
  filter(!is.na(vessel.name))
```  

## Prune sparse strata

Remove strata that have a minimum number of trawl clusters (`nClusters` $\geq$ `r nClusters.min`) or number of individuals (`nIndiv` $\geq$ `r nIndiv.min`).

```{r prune-strata}
# Create data frame for results
strata.summ.all <- data.frame()

# For each species and stratum, summarize trawl clusters and catch to remove sparse strata
for (i in unique(strata.final$scientificName)) {
  # Subset strata for species i
  strata.spp <- filter(strata.final, scientificName == i) %>% 
    select(transect, stratum)
  
  # Get unique clusters per stratum
  nasc.summ.stratum <- nasc %>%
    left_join(strata.spp) %>% 
    filter(!is.na(stratum)) %>% 
    group_by(stratum, cluster) %>%
    tally()
  
  # Summarize number of individual specimens per cluster
  catch.summ.cluster <- lf.final %>% 
    filter(scientificName == i) %>% 
    group_by(cluster) %>% 
    summarise(nIndiv = round(sum(counts)))
  
  # Combine nasc and catch summaries, summarise by stratum, 
  # and filter by min numbers of each
  strata.summ.spp <- nasc.summ.stratum %>% 
    left_join(catch.summ.cluster) %>%
    filter(!is.na(nIndiv)) %>%
    group_by(stratum) %>% 
    summarise(nClusters = n_distinct(cluster),
              nIndiv = sum(nIndiv)) %>% 
    filter(nClusters >= nClusters.min, nIndiv >= nIndiv.min) %>% 
    mutate(scientificName = i,
           key = paste(scientificName, stratum),
           stratum = as.numeric(as.factor(stratum))) %>% 
    select(scientificName, everything())
  
  # Combine results
  strata.summ.all <- bind_rows(strata.summ.all, strata.summ.spp)
}

# Filter strata.final using strata.filter
strata.final <- strata.final %>% 
  mutate(key = paste(scientificName, stratum)) %>% 
  select(-stratum) %>% 
  left_join(select(strata.summ.all, key, stratum, nClusters, nIndiv)) 

# Select removed strata
strata.rm <- filter(strata.final, is.na(stratum))

# Select retained strata
strata.final <- filter(strata.final, !is.na(stratum)) %>% 
  select(-key)

# Remove unwanted columns
strata.summ.all <- select(strata.summ.all, -key)
```

## Summarize stratum definitions  

A table showing the stratum number, start (first transect), end (last transect), and total number of transects (`nTx`), clusters (`nClust`), and individuals caught in trawls (`nIndiv`). Strata with less than the minimum number of transects (3), clusters (2), or individuals (10) are highlighted in red, else are highlighted in green.  

```{r summarize-strata}
# Summarise strata transects
strata.summ <- strata.final %>% 
  group_by(vessel.name, scientificName, stratum) %>% 
  summarise(
    start     = min(transect),
    end       = max(transect),
    lat.start = min(start.lat),
    lat.end   = max(start.lat),
    nTx       = n(),
    nClust    = unique(nClusters),
    nIndiv    = round(unique(nIndiv))) %>% 
  arrange(scientificName, stratum)

# Summarise removed strata transects
strata.summ.rm <- strata.rm %>% 
  group_by(vessel.name, scientificName, stratum.orig) %>% 
  summarise(
    start     = min(transect),
    end       = max(transect),
    lat.start = min(start.lat),
    lat.end   = max(start.lat),
    nTx       = n(),
    nClust    = unique(nClusters),
    nIndiv    = round(unique(nIndiv))) %>% 
  arrange(scientificName, stratum.orig)

# Save strata definitions and summary
save(strata.final, strata.summ, strata.summ.rm,
     file = here("Output/strata_info.Rdata"))

# Write results to .csv file
write.csv(strata.final, file  = here("Output/strata_final.csv"),  
          quote = FALSE,row.names = FALSE)

write.csv(strata.summ, file   = here("Output/strata_summary.csv"),
          quote = FALSE,row.names = FALSE)

# Print strata summary table
strata.summ %>% 
  rename(Vessel = vessel.name,
         Species = scientificName) %>% 
  mutate(nTx = cell_spec(nTx, knitr.format, color = "black",
                         background = ifelse(nTx >= nTx.min,"green","red")),
         nClust = cell_spec(nClust, knitr.format, color = "black",
                            background = ifelse(nClust >= 2,"green","red")),
         nIndiv = cell_spec(nIndiv, knitr.format, color = "black",
                            background = ifelse(nIndiv >= 10,"green","red"))) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("l","c","r","r","r","r","r")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"), 
                full_width = FALSE) %>%
  row_spec(0, align = c("c")) %>% 
  column_spec(c(1,2), italic = TRUE) %>% 
  collapse_rows(columns = c(1,2))
```  

## Plot biomass density by transect  

View results of strata definition algorithm compared to transect spacing, biomass density, etc.

(ref:stratification-biomass-density) Biomass density (log(t + 1) nmi^-2^) versus latitude (easternmost portion of each transect) and strata used to estimate biomass and abundance (shaded regions; outline indicates stratum number) for each species and survey vessel (labels above plots; e.g., SH = _Bell M. Shimada_, RL = _Reuben Lasker_, LM = _Lisa Marie_). Blue number labels correspond to the transect numbers with positive biomass (log(t + 1) > 0.01) to facilitate discrimination of stratum breaks. Point fills indicate transect spacing (i.e., the shortest distance between the midpoint of each transect and midpoint of all other transects, in nmi), which is used to define different sampling strata, for example when adaptive sampling occurs. Solid horizontal lines indicate prominent biogeographic landmarks that often delineate stock boundaries (e.g., Cape Mendocino for the central and northern stocks of Northern anchovy and Pt. Conception for the northern and southern stocks of Pacific sardine). Dashed red lines indicate the actual boundaries used for assigning biomass to various stocks, if different than above.

```{r stratification-biomass-density,fig.cap='(ref:stratification-biomass-density)'}
# Create data frame with relevant landmarks
landmarks <- data.frame(
  name = c("U.S.-Mexico", "Pt. Conception", "Cape Mendocino", "Cape Flattery"),
  lat.start = c(32.529, 34.46, 40.50, 48.490),
  y = rep(0,4)) %>% 
  filter(lat.start > min(nasc.density$lat),
         lat.start < max(nasc.density$lat))

stock.breaks <- data.frame(
  scientificName = c("Sardinops sagax", "Engraulis mordax"),
  lat.start = c(stock.break.sar, stock.break.anch),
  y = rep(0,2)) %>% 
  filter(lat.start > min(nasc.density$lat),
         lat.start < max(nasc.density$lat))

# Get max density for setting y limits
max.tx.dens.log <- ceiling(max(log(nasc.density.summ$density + 1), na.rm = TRUE))
max.tx.dens     <- ceiling(max(nasc.density.summ$density, na.rm = TRUE))

if (nrow(strata.summ.rm) > 0) {
  # If strata were removed
  # Biomass density by species and transect, showing stratum breaks
  biomass.dens.plot.lat <- ggplot(strata.summ) + 
    geom_rect(aes(xmin = lat.start, xmax = lat.end, ymin = 0, ymax = max.tx.dens.log, 
                  group = stratum, colour = factor(stratum)), 
              fill = 'gray70', alpha = 0.5) +
    geom_rect(data = strata.summ.rm, aes(xmin = lat.start, xmax = lat.end, ymin = 0, ymax = max.tx.dens.log,
                                         group = stratum.orig),
              fill = 'gray50', alpha = 0.5, linetype = "dotted") +
    geom_hline(yintercept = 0, colour = 'gray20') +
    geom_vline(xintercept = landmarks$lat.start, linetype = "dashed") +
    geom_vline(xintercept = stock.breaks$lat.start, linetype = "dashed", colour = "red") +
    geom_text(data = landmarks, 
              aes(lat.start, max.tx.dens.log, label = name), 
              inherit.aes = FALSE, nudge_x = 0.1, hjust = 1, vjust = 0, 
              fontface = "italic", alpha = 0.5) +
    geom_path(data = nasc.density.summ,  
              aes(start.lat, log(density + 1), group = scientificName)) +
    geom_point(data = nasc.density.summ, 
               aes(start.lat, log(density + 1), group = scientificName,
                   fill = dist.bin), shape = 21, size = 3) +
    # Label non-zero biomass density to facilitate picking strata
    geom_text_repel(data = filter(nasc.density.summ, log(density + 1) > 0),
                    aes(start.lat, log(density + 1), label = transect, group = scientificName),
                    colour = 'blue', size = 3, fontface = 'italic', nudge_y = 1) +
    scale_colour_discrete("Stratum") +
    scale_fill_discrete("Spacing (nmi)") +
    facet_wrap(scientificName ~ vessel.name, nrow = 1) + 
    scale_x_continuous("Start latitude", 
                       breaks = seq(floor(min(strata.summ$lat.start)), 
                                    ceiling(max(strata.summ$lat.end)),1)) + 
    scale_y_continuous(expression(Mean~log~biomass~density~(log(t~nmi^-2+1)))) +
    theme_bw() + 
    theme(strip.text.x       = element_text(face = "bold.italic"),
          strip.background.x = element_rect(fill = NA)) +
    coord_flip()
  
  # Original plot, based on transect number on the x-axis
  biomass.dens.plot.tx <- ggplot(strata.summ) +
    geom_rect(aes(xmin = start - 0.4, xmax = end + 0.4, 
                  ymin = 0, ymax = max.tx.dens.log, 
                  group = stratum, colour = factor(stratum)),
              fill = 'gray70', alpha = 0.5) +
    geom_rect(data = strata.summ.rm, aes(xmin = start - 0.4, xmax = end + 0.4, 
                                         ymin = 0, ymax = max.tx.dens.log, 
                                         group = stratum.orig),
              fill = 'gray50', alpha = 0.5, linetype = "dotted") +
    geom_hline(yintercept = 0, colour = 'gray20') +
    geom_path(data = nasc.density.summ, 
              aes(transect, log(density + 1), group = scientificName)) +
    geom_point(data = nasc.density.summ, 
               aes(transect, log(density + 1), group = scientificName, fill = dist.bin), 
               shape = 21, size = 3) +
    # Label non-zero biomass density to facilitate picking strata
    geom_text_repel(data = filter(nasc.density.summ,log(density + 1) > 0),
                    aes(transect, log(density + 1), label = transect, group = scientificName),
                    colour = 'blue', size = 3, fontface = 'italic', nudge_y = 1) +
    scale_colour_discrete("Stratum") +
    scale_fill_discrete("Spacing (nmi)") +
    facet_wrap(~scientificName,ncol = 1) +
    xlab("Transect") + 
    scale_y_continuous(expression(Mean~log~biomass~density~(log(t~nmi^-2)+1)),
                       limits = c(-0.5, max.tx.dens.log), expand = c(0,0)) +
    theme_bw() +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "italic"))
  
} else {
  # If no strata were removed
  # Biomass density by species and transect, showing stratum breaks
  biomass.dens.plot.lat <- ggplot(strata.summ) + 
    geom_rect(aes(xmin = lat.start, xmax = lat.end, ymin = 0, ymax = max.tx.dens.log, 
                  group = stratum, colour = factor(stratum)), 
              fill = 'gray70', alpha = 0.5) +
    geom_hline(yintercept = 0, colour = 'gray20') +
    geom_vline(xintercept = landmarks$lat.start) +
    geom_vline(data = stock.breaks, aes(xintercept = lat.start, group = scientificName), 
               linetype = "dashed", colour = "red") +
    geom_text(data = landmarks, 
              aes(lat.start, max.tx.dens.log, label = name), 
              inherit.aes = FALSE, nudge_x = 0.1, hjust = 1, vjust = 0, 
              fontface = "italic", alpha = 0.5) +
    geom_text(data = stock.breaks,
              aes(lat.start, max.tx.dens.log, label = scientificName, group = scientificName),
              inherit.aes = FALSE, nudge_x = -0.1, hjust = 1, vjust = 1,
              fontface = "italic", alpha = 0.5, colour = "red") +
    geom_path(data = nasc.density.summ,  
              aes(start.lat, log(density + 1), group = scientificName)) +
    geom_point(data = nasc.density.summ, 
               aes(start.lat, log(density + 1), group = scientificName,
                   fill = dist.bin), shape = 21, size = 3) +
    # Label non-zero biomass density to facilitate picking strata
    geom_text_repel(data = filter(nasc.density.summ, log(density + 1) > 0),
                    aes(start.lat, log(density + 1), label = transect, group = scientificName),
                    colour = 'blue', size = 3, fontface = 'italic', nudge_y = 1) +
    scale_colour_discrete("Stratum") +
    scale_fill_discrete("Spacing (nmi)") +
    facet_wrap(~scientificName, nrow = 1) + 
    scale_x_continuous("Start latitude", 
                       breaks = seq(floor(min(strata.summ$lat.start)), 
                                    ceiling(max(strata.summ$lat.end)),1)) + 
    scale_y_continuous(expression(Biomass~density~(log(t+1)~nmi^-2))) +
    theme_bw() + 
    theme(strip.text.x       = element_text(face = "bold.italic"),
          strip.background.x = element_rect(fill = NA)) +
    coord_flip()
  
  # Original plot, based on transect number on the x-axis
  biomass.dens.plot.tx <- ggplot(strata.summ) +
    geom_rect(aes(xmin = start - 0.4, xmax = end + 0.4, 
                  ymin = 0, ymax = max.tx.dens.log, 
                  group = stratum, colour = factor(stratum)),
              fill = 'gray70', alpha = 0.5) +
    geom_hline(yintercept = 0, colour = 'gray20') +
    geom_path(data = nasc.density.summ, 
              aes(transect, log(density + 1), group = scientificName)) +
    geom_point(data = nasc.density.summ, 
               aes(transect, log(density + 1), group = scientificName, fill = dist.bin), 
               shape = 21, size = 3) +
    # Label non-zero biomass density to facilitate picking strata
    geom_text_repel(data = filter(nasc.density.summ,log(density + 1) > 0),
                    aes(transect, log(density + 1), label = transect, group = scientificName),
                    colour = 'blue', size = 3, fontface = 'italic', nudge_y = 1) +
    scale_colour_discrete("Stratum") +
    scale_fill_discrete("Spacing (nmi)") +
    facet_wrap(~scientificName,ncol = 1) +
    xlab("Transect") + 
    scale_y_continuous(expression(Biomass~density~(log(t+1)~nmi^-2)), 
                       limits = c(-0.5,max.tx.dens.log), expand = c(0,0)) +
    theme_bw() +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "italic"))
}

# Save plots
if (diff(range(nasc.density.summ$start.lat)) > 6) {
  ggsave(biomass.dens.plot.lat, 
         filename = here("Figs/fig_biomass_density_transect_lat.png"),
         height = 12, width = 12*n_distinct(strata.summ$vessel.name))
  
  ggsave(biomass.dens.plot.tx, 
         filename = here("Figs/fig_biomass_density_transect_tx.png"),
         height = 13, width = 13)  
} else {
  ggsave(biomass.dens.plot.lat, 
         filename = here("Figs/fig_biomass_density_transect_lat.png"),
         height = 8, width = 8*n_distinct(strata.summ$vessel.name))
  
  ggsave(biomass.dens.plot.tx, 
         filename = here("Figs/fig_biomass_density_transect_tx.png"),
         height = 8, width = 8) 
}

# Add plot by latitude
include_graphics(here("Figs/fig_biomass_density_transect_lat.png"))
```  

## Define stratum polygons and compute area  

For each species, polygons are drawn around backscatter within each strata and the area of each polygon is calculated. The results are stored in a named list (by scientific name) and made available to the point and bootstrap estimate functions below.  

```{r create-pseudo-transects}
# Draw pseudo-transects --------------------------------------------------------
# Get transect ends, calculate bearing, and add transect spacing
tx.ends <- nasc %>% 
  group_by(transect.name, transect, vessel.name) %>% 
  summarise(
    lat.i  = lat[which.max(long)],
    long.i = max(long),
    lat.o  = lat[which.min(long)],
    long.o = min(long)) %>% 
  left_join(select(tx.nn, transect.name, spacing)) %>% 
  mutate(
    brg = swfscMisc::bearing(lat.i, long.i,
                             lat.o, long.o)[1])

# Get original inshore transect ends -------------------------------------------
# Select original inshore waypoints
tx.i <- tx.ends %>% 
  select(-lat.o, -long.o) %>% 
  rename(lat = lat.i, long = long.i) %>% 
  mutate(
    grp = "original",
    loc = "inshore",
    order = 2)

# Get N and S inshore waypoints ------------------------------------------------
# Calculate inshore/north transects
tx.i.n <- tx.ends %>% 
  select(-lat.o, -long.o) %>% 
  rename(lat = lat.i, long = long.i) %>% 
  mutate(
    lat  = destination(lat, long, brg + 90, spacing/2, units = "nm")["lat"],
    long = destination(lat, long, brg + 90, spacing/2, units = "nm")["lon"],
    grp = "north",
    loc = "inshore",
    order = 1)

# Calculate inshore/south transects
tx.i.s <- tx.ends %>% 
  select(-lat.o, -long.o) %>% 
  rename(lat = lat.i, long = long.i) %>% 
  mutate(
    lat  = destination(lat, long, brg - 90, spacing/2, units = "nm")["lat"],
    long = destination(lat, long, brg - 90, spacing/2, units = "nm")["lon"],
    grp = "south",
    loc = "inshore",
    order = 3)

# Combine all inshore transects
tx.i <- tx.i %>%
  bind_rows(tx.i.n) %>%
  bind_rows(tx.i.s) %>%
  arrange(transect, desc(order))

# Get original offshore transect ends ------------------------------------------
tx.o <- tx.ends %>% 
  select(-lat.i, -long.i) %>% 
  rename(lat = lat.o, long = long.o) %>% 
  mutate(
    grp = "original",
    loc = "offshore",
    order = 2)

# Get N and S offshore waypoints -----------------------------------------------
# Calculate offshore/north transects
tx.o.n <- tx.ends %>% 
  select(-lat.i, -long.i) %>% 
  rename(lat = lat.o, long = long.o) %>% 
  mutate(
    lat  = destination(lat, long, brg + 90, spacing/2, units = "nm")["lat"],
    long = destination(lat, long, brg + 90, spacing/2, units = "nm")["lon"],
    grp = "north",
    loc = "offshore",
    order = 3)

# Calculate offshore/south transects
tx.o.s <- tx.ends %>% 
  select(-lat.i, -long.i) %>% 
  rename(lat = lat.o, long = long.o) %>% 
  mutate(
    lat  = destination(lat, long, brg - 90, spacing/2, units = "nm")["lat"],
    long = destination(lat, long, brg - 90, spacing/2, units = "nm")["lon"],
    grp = "south",
    loc = "offshore",
    order = 1)

for (v in unique(tx.o$vessel.name)) {
  if (v == "SD1024") {
    tx.o.tmp <- filter(tx.o, vessel.name == v)
  } else {
    tx.o.tmp <- filter(tx.o, vessel.name == v) %>% 
      bind_rows(filter(tx.o.n, vessel.name == v)) %>% 
      bind_rows(filter(tx.o.s, vessel.name == v))
  }
  
  if (exists("tx.o.final")) {
    tx.o.final <- bind_rows(tx.o.final, tx.o.tmp)
  } else {
    tx.o.final <- tx.o.tmp
  }
}

tx.o <- tx.o.final %>% 
  arrange(desc(transect), desc(order))

# Assemble the final data frame with all waypoints -----------------------------
strata.points <- tx.i %>% 
  bind_rows(tx.o)   %>%
  mutate(key = paste(transect.name, grp)) 

# Convert to points
strata.points.sf <- st_as_sf(strata.points, coords = c("long","lat"), crs = crs.geog) 

# Create polygons
strata.super.polygons <- strata.points.sf %>%
  group_by(vessel.name) %>%
  summarise(do_union = FALSE) %>%
  st_cast("POLYGON") %>%
  st_make_valid() %>%
  st_difference(st_union(bathy_20m_poly)) %>%
  mutate(area = st_area(.))

# Convert to lines
tx.lines.sf <- strata.points.sf %>% 
  group_by(transect, grp) %>% 
  summarise(do_union = FALSE) %>% 
  st_cast("LINESTRING")

# Create polygons for clipping nearshore strata
# Get original inshore transect ends -------------------------------------------
# Select original inshore waypoints
tx.c <- tx.ends %>% 
  select(-lat.o, -long.o) %>% 
  rename(lat = lat.i, long = long.i) %>% 
  mutate(
    lat  = destination(lat, long, brg, -20, units = "nm")["lat"],
    long = destination(lat, long, brg, -20, units = "nm")["lon"],
    grp = "original",
    loc = "onshore",
    order = 2)

# Get N and S inshore waypoints ------------------------------------------------
# Calculate inshore/north transects
tx.c.n <- tx.ends %>% 
  select(-lat.o, -long.o) %>% 
  rename(lat = lat.i, long = long.i) %>% 
  mutate(
    lat1  = destination(lat, long, brg + 90, spacing/2, units = "nm")["lat"],
    long1 = destination(lat, long, brg + 90, spacing/2, units = "nm")["lon"],
    lat2  = destination(lat1, long, brg, -20, units = "nm")["lat"],
    long2 = destination(lat1, long, brg, -20, units = "nm")["lon"],
    grp = "north",
    loc = "onshore",
    order = 1) %>% 
  select(-lat, -long, -lat1, -long1) %>% 
  rename(lat = lat2, long = long2)

tx.c.s <- tx.ends %>% 
  select(-lat.o, -long.o) %>% 
  rename(lat = lat.i, long = long.i) %>% 
  mutate(
    lat1  = destination(lat, long, brg - 90, spacing/2, units = "nm")["lat"],
    long1 = destination(lat, long, brg - 90, spacing/2, units = "nm")["lon"],
    lat2  = destination(lat1, long, brg, -20, units = "nm")["lat"],
    long2 = destination(lat1, long, brg, -20, units = "nm")["lon"],
    grp = "south",
    loc = "onshore",
    order = 3) %>% 
  select(-lat, -long, -lat1, -long1) %>% 
  rename(lat = lat2, long = long2)

# Combine all inshore transects
tx.c <- tx.c %>% 
  bind_rows(tx.c.n) %>% 
  bind_rows(tx.c.s) %>%   
  arrange(transect, desc(order))
```

```{r create-final-strata-polygons}
# # Read 5 m isobath points; used to create nearshore stratum polygons
# nearshore.points <- read.csv(here("Data/GIS/isobath_5m_final.csv")) %>%
#   mutate(order = seq(1, n()))
# 
# nearshore.points.sf <- st_as_sf(nearshore.points, coords = c("long","lat"), crs = crs.geog)

# Read 20 m isobath points; used to create nearshore stratum polygons
nearshore.points.sf <- st_read(here("Data/GIS/bathy_20m_points.shp")) 

nearshore.points <- nearshore.points.sf %>% 
  mutate(
    long = as.data.frame(st_coordinates(.))$X,
    lat = as.data.frame(st_coordinates(.))$Y,
    order = seq(1, n())) %>% 
  select(-Id) %>% 
  st_set_geometry(NULL)

# Ensure strata objects do not exist
if (exists("strata.primary")) rm(strata.primary)
if (exists("strata.nse.temp")) rm(strata.nse.temp)
if (exists("strata.inshore")) rm(strata.inshore)
if (exists("nearshore.clip")) rm(nearshore.clip)

# Create final strata and calculate area
# Create df for transect-level stock info
nasc.stock <- data.frame()

for (i in unique(strata.final$scientificName)) {
  # Select each strata per species
  strata.sub <- filter(strata.final, scientificName == i) %>% 
    select(transect, stratum)  
  
  # Define strata to stock
  nasc.stock.temp <- strata.points %>% 
    filter(loc == "inshore", grp == "original") %>%
    mutate(stock = case_when(
      i == "Engraulis mordax" & lat >= stock.break.anch ~ "Northern",
      i == "Engraulis mordax" & lat <  stock.break.anch ~ "Central",
      i == "Sardinops sagax"  & lat >= stock.break.sar  ~ "Northern",
      i == "Sardinops sagax"  & lat <  stock.break.sar  ~ "Southern",
      i %in% c("Clupea pallasii","Scomber japonicus",
               "Trachurus symmetricus","Etrumeus acuminatus") ~ "All"),
      scientificName = i) %>% 
    select(transect, stock, scientificName) %>% 
    distinct()
  
  # Combine results
  nasc.stock <- bind_rows(nasc.stock, nasc.stock.temp)
  
  for (j in sort(unique(strata.sub$stratum))) {
    # Create offshore stratum polygons ----------------------------------------
    # Add stratum numbers and stock designation to strata.points
    primary.poly.temp <- strata.points %>% 
      left_join(strata.sub) %>%
      left_join(nasc.stock.temp) %>% 
      filter(stratum == j) %>%
      mutate(scientificName = i) %>% 
      ungroup()
    
    # Select the southern-most inshore point for j-th stratum
    primary.poly.j.s <- primary.poly.temp %>%
      filter(loc == "inshore") %>% 
      slice(1)
    
    # Select the northern-most inshore point for j-th stratum
    primary.poly.j.n <- primary.poly.temp %>%
      filter(loc == "inshore") %>% 
      slice(n())
    
    # Select only the original inshore waypoints for j-th stratum
    primary.poly.j.i <- primary.poly.temp %>% 
      filter(loc == "inshore", grp == "original") %>% 
      mutate(scientificName = i)
    
    # Create the final polygon
    primary.poly.j <- primary.poly.temp %>% 
      filter(loc == "offshore") %>% 
      bind_rows(primary.poly.j.s) %>%
      bind_rows(primary.poly.j.i) %>%
      bind_rows(primary.poly.j.n) %>% 
      st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
      group_by(stratum, stock) %>% 
      summarise(do_union = FALSE) %>% 
      st_cast("POLYGON") %>% 
      mutate(scientificName = i)
    
    # Create nearshore stratum polygons ----------------------------------------
    # Select the inshore portions of offshore strata
    nearshore.temp <- primary.poly.j.s %>%
      bind_rows(primary.poly.j.i) %>%
      bind_rows(primary.poly.j.n) %>% 
      select(long, lat, scientificName, stratum, loc, stock)
    
    # Create polygon for clipping nearshore strata -----------------------------
    # Get the points on land
    clip.temp <- tx.c %>%
      left_join(strata.sub) %>%
      left_join(nasc.stock.temp) %>%
      filter(stratum == j) %>%
      ungroup()
    
    # Combine with offshore points from nearshore polygons
    clip.poly.j <- nearshore.temp %>%
      arrange(desc(lat)) %>%
      mutate(scientificName = i,
             stratum = j,
             loc = "nearshore",
             stock = unique(primary.poly.temp$stock)) %>% 
      bind_rows(clip.temp) %>% 
      st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
      group_by(stratum, stock) %>% 
      summarise(do_union = FALSE) %>% 
      st_cast("POLYGON") %>% 
      mutate(scientificName = i) %>% 
      st_make_valid() %>% 
      st_difference(bathy_5m_poly)
    
    # Find nearest point on the 5 m isobath *change to 20 m isobath
    ns.bound.lower <- st_as_sf(primary.poly.j.s, coords = c("long","lat"), crs = crs.geog)
    ns.bound.upper <- st_as_sf(primary.poly.j.n, coords = c("long","lat"), crs = crs.geog)
    
    # Get the latitude of the nearest points on the 20 m isobath, +/- 50 points
    ns.lat.upper <- nearshore.points$lat[st_nearest_feature(ns.bound.upper, nearshore.points.sf)]
    ns.lat.lower <- nearshore.points$lat[st_nearest_feature(ns.bound.lower, nearshore.points.sf)]
    
    # Combine with the points from the 5 m isobath
    nearshore.poly.j <- nearshore.points %>% 
      filter(between(lat, ns.lat.lower, ns.lat.upper)) %>%
      arrange(desc(order)) %>% 
      select(-order) %>% 
      mutate(scientificName = i,
             stratum = j,
             loc = "nearshore",
             stock = unique(primary.poly.temp$stock)) %>% 
      bind_rows(nearshore.temp) %>% 
      st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
      group_by(stratum, stock) %>% 
      summarise(do_union = FALSE) %>% 
      st_cast("POLYGON") %>% 
      mutate(scientificName = i) %>% 
      st_make_valid()
    
    # Combine with other polygons ----------------------------------------
    if (exists("strata.primary")) {
      strata.primary <- rbind(strata.primary, primary.poly.j)
    } else {
      strata.primary <- primary.poly.j
    }
    
    if (exists("strata.nse.temp")) {
      strata.nse.temp <- rbind(strata.nse.temp, nearshore.poly.j)
    } else {
      strata.nse.temp <- nearshore.poly.j
    }
    
    if (exists("nearshore.clip")) {
      nearshore.clip <- rbind(nearshore.clip, clip.poly.j)
    } else {
      nearshore.clip <- clip.poly.j
    }
    
    if (exists("strata.inshore")) {
      strata.inshore <- bind_rows(strata.inshore, primary.poly.j.i)
    } else {
      strata.inshore <- primary.poly.j.i
    }
  }
}

# Save strata polygons
save(strata.primary, 
     file = here("Output/strata_primary_raw.Rdata"))

save(strata.nse.temp, 
     file = here("Output/strata_nse_raw.Rdata"))

# Clip primary polygons using the 5 m isobathy polygon -------------------------
strata.primary <- strata.primary %>% 
  st_make_valid() %>% 
  st_difference(st_union(bathy_20m_poly)) %>% 
  st_difference(st_union(bathy_5m_poly)) %>% 
  ungroup() %>% 
  mutate(area = st_area(.)) %>% 
  left_join(select(strata.summ, 
                   scientificName, stratum, vessel.name))

# Manually substitute stratum polygons
# if (survey.name == "1606RL") {
#   polygon.reorder <- FALSE
#   
#   source(here("Sandbox/externalStrata.R"))
#   
#   # area.orig <- filter(strata.primary, scientificName == "Sardinops sagax", stock == "Northern") %>% 
#   #   select(stratum, area) %>% 
#   #   st_set_geometry(NULL)
#   # 
#   # area.juan <- filter(strata.polygon.final) %>% 
#   #   select(stratum, area) %>% 
#   #   st_set_geometry(NULL)
#   # 
#   # area.comp <- area.orig %>% 
#   #   left_join(select(area.juan, stratum, area.juan = area))
#   # 
#   # ggplot(area.comp, aes(as.numeric(area), as.numeric(area.juan), label = stratum)) + 
#   #   geom_text() + 
#   #   geom_abline(slope = 1, intercept = 0) + 
#   #   coord_equal()
#   # 
#   
#   strata.primary <- strata.primary %>%
#     mutate(key = paste(scientificName, stock, stratum)) %>% 
#     filter(!key %in% strata.polygon.final$key) %>% 
#     bind_rows(strata.polygon.final) %>% 
#     arrange(key)
# }

# Ensure that strata are ordered by number
strata.primary <- arrange(strata.primary, scientificName, stratum)

# Save clipped primary polygons
save(strata.primary, 
     file = here("Output/strata_primary_final.Rdata"))

# Write final strata to shapefile
strata.primary.sub <- strata.primary %>% 
  filter(!sf::st_geometry_type(.) == "GEOMETRYCOLLECTION") %>% 
  mutate(area = round(as.numeric(area))) %>% 
  ungroup() 

# Write polygons to shapefile
strata.primary.sub %>% 
  select(-area) %>% 
  sf::st_write(here::here("Output/strata_primary.shp"),
               delete_layer = TRUE)

# Clip nearshore polygons using the 5 m isobath polygon -----------------------
# Remove self-intersecting portions of polygons
strata.nse.temp <- st_make_valid(strata.nse.temp) %>% 
  ungroup()

if (exists("strata.nse")) rm(strata.nse)

for (k in unique(strata.nse.temp$scientificName)) {
  # Clip strata for each species
  strata.nse.diff <- strata.nse.temp %>% 
    filter(scientificName == k) %>%
    ungroup() %>% 
    st_difference(bathy_20m_poly) %>% 
    mutate(area = st_area(.))
  
  # Combine features
  if (exists("strata.nse")) {
    strata.nse <- rbind(strata.nse,
                        strata.nse.diff)
  } else {
    strata.nse <- strata.nse.diff
  }
}

# Add vessel name to nearshore strata
strata.nse <- strata.nse %>% 
  left_join(select(strata.summ, scientificName, stratum, vessel.name))

# Exclude nearshore area sampled by Saildrone in 1807RL
if (prj.name %in% c("1807RL")) {
  # Read mask shapefile
  sd.mask <- st_read(here("Data/GIS/saildrone_mask.shp"))
  
  # Extract Saildrone strata in a temporary object
  strata.nse.sd <- strata.nse %>%
    filter(vessel.name == "SD1024")
  
  # Keep the difference between nearshore stata and the Saildrone mask
  strata.nse <- strata.nse %>%
    filter(vessel.name == "RL") %>%
    st_difference(sd.mask) %>%
    mutate(area = st_area(.)) %>%
    select(-Id)
  
  # Recombine
  strata.nse <- rbind(strata.nse, strata.nse.sd)
}

# Save final nearshore polygons
save(strata.nse, 
     file = here("Output/strata_nse_final.Rdata"))

# Convert polygons to points and add coordinates -------------------------------
strata.primary.points  <- strata.primary %>% 
  st_cast("MULTIPOINT") %>%
  st_cast("POINT") %>%
  mutate(
    long = as.data.frame(st_coordinates(.))$X,
    lat = as.data.frame(st_coordinates(.))$Y,
    grp = paste(scientificName, stock, stratum)) %>% 
  st_set_geometry(NULL)

strata.nse.points <- strata.nse %>% 
  st_cast("MULTIPOINT") %>%
  st_cast("POINT") %>% 
  mutate(
    long = as.data.frame(st_coordinates(.))$X,
    lat = as.data.frame(st_coordinates(.))$Y,
    grp = paste(scientificName, stock, stratum)) %>% 
  st_set_geometry(NULL)

# Save final strata points
save(strata.primary.points,  
     file = here("Output/strata_points_primary.Rdata"))

save(strata.nse.points, 
     file = here("Output/strata_points_nearshore.Rdata"))

# Write primary stata points to CSV
write.csv(strata.primary.points,  
          file = here("Output/strata_points_primary.csv"),
          quote = FALSE, row.names = FALSE)

# Summarize nasc.strata by stock
strata.summ.primary <- strata.primary %>% 
  select(scientificName, stratum, stock, area) %>%
  mutate(area = as.numeric(area)) %>% 
  st_set_geometry(NULL)

strata.summ.nse <- strata.nse %>% 
  select(scientificName, stratum, stock, area) %>%
  mutate(area = as.numeric(area)) %>% 
  st_set_geometry(NULL)

# Write stata summaries to CSV
write.csv(strata.summ.primary,  
          file = here("Output/strata_summary_primary.csv"),
          quote = FALSE, row.names = FALSE)

write.csv(strata.summ.nse,  
          file = here("Output/strata_summary_nse.csv"),
          quote = FALSE, row.names = FALSE)
```  

## Map final stratum polygons  

Map final stratum polygons for each species and the acoustic backscatter for each species relative to backscatter from all species.  

(ref:map-final-stratum-polygons) Final strata used to compute abundance and biomass for each species, total acoustic backscatter (black points), and acoustic backscatter attributed to each species (red points). Polygon color indicates stock designation.

```{r map-final-stratum-polygons,fig.cap='(ref:map-final-stratum-polygons)'}
if (save.figs) {
  # Add strata polygons to acoustic proportions map
  map.stratum.all <- base.map + 
    # Plot proportion of backscatter from each species present
    geom_point(data = nasc.prop.all, aes(X, Y, size = cps.nasc), 
               colour = "gray20", show.legend = FALSE) +
    geom_point(data = filter(nasc.prop.spp, nasc > 0),
               aes(X, Y, size = nasc), colour = "red", show.legend = FALSE) +
    # Plot final strata
    geom_sf(data = strata.primary, aes(colour = factor(stratum), 
                                       fill = stock), alpha = 0.5) +
    scale_colour_discrete("Stratum") +
    scale_fill_manual("Stock", 
                      values = c("All" = "yellow", "Central" = "green", 
                                 "Northern" = "blue", "Southern" = "orange")) +
    # Facet by species
    facet_wrap(~scientificName, nrow = 2) +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "italic"),
          legend.background  = element_blank()) +
    coord_sf(crs = crs.proj, 
             xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
             ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
  
  # Save figure
  ggsave(here("Figs/fig_nasc_acoustic_proportions_strata.png"), map.stratum.all,
         width = map.width*2.6, height = map.height*1.5)
}

include_graphics(here("Figs/fig_nasc_acoustic_proportions_strata.png"))
```  

```{r map-biomass-density}
# Convert nasc.density to sf and project
nasc.density <- ungroup(nasc.density) %>% 
  project_df(to = crs.proj)

# Summarize positive clusters to filter clusters from removed strata
pos.cluster.summ <- pos.clusters %>% 
  group_by(scientificName, cluster) %>% 
  summarise(nIndiv = sum(num)) %>% 
  filter(nIndiv >= nIndiv.min)

if (save.figs) {
  # Create a list for saving biomass density plots
  biomass.dens.figs <- list()
  
  # Create data frame for saving nasc.density.plot for each species and stratum
  nasc.density.plot.all <- data.frame()
  
  # Plot anchovy biomass density
  for (i in unique(strata.primary$scientificName)) {
    for (j in unique(filter(strata.primary, scientificName == i)$stock)) {
      # Filter biomass density
      nasc.density.plot <- nasc.density %>%
        left_join(filter(nasc.stock, scientificName == i, stock == j)) %>% 
        filter(density != 0, scientificName == i, 
               stock == j, transect %in% strata.final$transect[strata.final$scientificName == i])
      
      # Combine biomass density from each species and stratum
      nasc.density.plot.all <- bind_rows(nasc.density.plot.all,
                                         nasc.density.plot)
      
      # Filter positive clusters
      pos.cluster.txt <- pos.clusters %>% 
        filter(scientificName == i, stock == j, !duplicated(cluster)) %>%
        ungroup()
      
      # pos.cluster.txt <- pos.clusters %>% 
      #   filter(scientificName == i, stock == j, !duplicated(cluster), 
      #          cluster %in% pos.cluster.summ$cluster[pos.cluster.summ$scientificName == i]) %>%
      #   ungroup()
      
      # Map biomass density, strata polygons, and positive trawl clusters
      biomass.dens <- base.map +
        geom_sf(data = filter(strata.primary, scientificName == i, stock == j),
                aes(colour = factor(stratum)), fill = NA, size = 1) +
        scale_colour_discrete('Stratum') + 
        # Plot vessel track
        geom_sf(data = nav.paths.sf, colour = 'gray50', size = 0.25, alpha = 0.5) +
        # Plot zero nasc data
        geom_point(data = filter(nasc, cps.nasc == 0), aes(X, Y),
                   colour = 'gray50',size = 0.15, alpha = 0.5) +
        # Plot NASC data
        geom_point(data = nasc.density.plot, aes(X, Y, size = bin, fill = bin),
                   shape = 21, alpha = 0.75) +
        # Configure size and colour scales
        scale_size_manual(name = bquote(atop(Biomass~density, ~'(t'~'nmi'^-2*')')),
                          values = dens.sizes.all, labels = dens.labels.all) +
        scale_fill_manual(name = bquote(atop(Biomass~density, ~'(t'~'nmi'^-2*')')),
                          values = dens.colors.all, labels = dens.labels.all) +
        # Plot positive cluster midpoints
        geom_shadowtext(data = pos.cluster.txt,
                        aes(X, Y, label = cluster), 
                        colour = "blue", bg.colour = "white", size = 2, fontface = "bold") +
        # Configure legend guides
        guides(colour = guide_legend(order = 1),
               fill   = guide_legend(order = 2), 
               size   = guide_legend(order = 2)) +
        coord_sf(crs = crs.proj, 
                 xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
                 ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
      
      # Save figures
      ggsave(biomass.dens, 
             filename = paste0(here("Figs/fig_biomass_dens_"), i, "-", j, ".png"),
             width  = map.width, height = map.height)
      
      # Save plot to list
      biomass.dens.figs[[i]][[j]] <- biomass.dens
    }
  }
  
  # Save map objects
  save(biomass.dens.figs, file = here("Output/biomass_dens_maps_all.Rdata")) 
  save(nasc.density.plot.all, file = here("Output/nasc_density_plot_all.Rdata"))
  
} else {
  load(here("Output/biomass_dens_maps_all.Rdata"))
  load(here("Output/nasc_density_plot_all.Rdata"))
}

# Create blank plots for missing species
for (i in unique(strata.primary$scientificName)) {
  for (j in unique(filter(strata.primary, scientificName == i)$stock)) {
    if (is.null(biomass.dens.figs[[i]][[j]])) {
      biomass.dens.temp <- base.map + 
        annotate('text', 5, 5, label = 'No Data', size = 6, fontface = 'bold') +
        theme_bw()  
      ggsave(biomass.dens.temp, 
             filename = paste0(here("Figs/fig_biomass_dens_"), i, "-", j, ".png"))
    }
  }
}
```

# Process CTD and UCTD data
## Get CTD nav data  
Assemble together latitude and longitude data from NASC and ERDDAP for matching with CTD and UCTD casts based on time.  

```{r get-ctd-nav}
# Assemble lat/long data from nav
ctd.nav <- select(nav, time, long, lat, SOG, leg) %>% 
  # bind_rows(select(nasc, datetime, long, lat)) %>% 
  arrange(time)

# Add nav data from Shimada
if (survey.name %in% c("2307RL")) {
  if (exists("nav.sh")) {
    ctd.nav <- ctd.nav %>% 
      bind_rows(select(nav.sh, time, long, lat, SOG, leg)) 
  }
}
```  

## Process UCTD cast files  

Read header and ASCII files from underway CTD (UCTD) casts and plot results. The location of each cast is determined by matching the date/time of the cast (extracted from the header; assumes probe was synchronized to the ship's time server) to the navigation data extracted from ERDDAP.  

```{r process-uctd-casts}
if (process.ctd) {
  # Process UCTD header files #####
  # List raw UCTD ASCII files
  uctd.hdr <- dir_ls(here("Data/UCTD"), regexp = uctd.hdr.pattern) %>% 
    path_filter(regexp = "_processed", invert = TRUE)
  
  # Plot UCTD casts
  if (length(uctd.hdr) == 0) {
    # Create empty figure if no UCTD casts present
    df <- data.frame()
    
    uctd.empty <- ggplot(df) + geom_point() + 
      xlim(0,10) + ylim(0,10) + 
      annotate('text', 5, 5, label = 'No UCTD Casts', size = 6, fontface = 'bold') +
      theme_bw()  
    
    # Save blank figure
    ggsave(uctd.empty, filename = here("Figs/fig_uctd_missing.png"))
    
  } else {
    if (process.ctd) {
      # Create a data frame for header info  
      all.uctd.hdr <- data.frame()
      
      for (i in uctd.hdr) {
        # Extract header information
        all.uctd.hdr <- bind_rows(all.uctd.hdr,
                                  extract_ctd_header(i, type = "UCTD"))
      }
      
      # Process UCTD cast files --------------------------------------------------
      # List processed UCTD cast files
      uctd.proc <- dir_ls(here("Data/UCTD"), pattern = uctd.cast.pattern) %>% 
        path_filter(regexp = "_processed")
      
      # create a data frame for storing results
      all.uctd.casts <- data.frame()
      
      # Process all UCTD casts
      for (i in uctd.proc) {
        all.uctd.casts <- bind_rows(all.uctd.casts, 
                                    extract_ctd_cast(i, type = "UCTD"))
      }
      
      # Arrange and filter results
      all.uctd.casts <- arrange(all.uctd.casts, cast, scan) %>% 
        filter(between(S, min.S, max.S)) # Remove bad salinity data
      
      # Save results
      save(all.uctd.casts, all.uctd.hdr, uctd.hdr, uctd.proc,
           file = here("Data/UCTD/uctd_data.Rdata"))
    } else {
      # Load results
      load(here("Data/UCTD/uctd_data.Rdata"))
    }
    
    # Match UCTD headers to nav data
    nav.match.uctd <- data.frame()
    
    for (i in seq_along(all.uctd.hdr$cast)) {
      min.diff       <- which.min(abs(difftime(all.uctd.hdr$cast.date[i], ctd.nav$time)))
      nav.match.uctd <- bind_rows(nav.match.uctd, ctd.nav[min.diff, ])
    }
    
    # Combine header and nav data
    all.uctd.hdr <- all.uctd.hdr %>% 
      bind_cols(nav.match.uctd) %>% 
      mutate(lag = difftime(cast.date, time)) %>% 
      arrange(cast.date)
    
    # Summarize uctd casts for water classification
    uctd.class <- 
      group_by(all.uctd.casts, cast) %>% 
      summarise(
        min.T = min(T),
        min.S = min(S),
        max.T = max(T),
        max.S = max(S)) %>% 
      # Assign classes based on salinity
      mutate(class = case_when(
        min.S <= 31.4 ~ "Type 1",
        min.S >= 33.4 ~ "Type 2",
        TRUE ~ "Type 3"))
    
    # Add water mass to the summary table and cast data for plotting
    all.uctd.casts <- all.uctd.casts %>% 
      left_join(select(uctd.class, cast, class))
    
    # Summarize UCTD cast results
    uctd.summ <- all.uctd.casts %>% 
      group_by(cast) %>% 
      summarise(
        time = round(sum(dt),0),
        max.depth = round(min(Z),0),
        type = "UCTD") %>%
      left_join(select(all.uctd.hdr, cast, cast.date, datetime = time, lat, long, SOG, leg, lag)) %>%
      left_join(select(uctd.class, cast, class)) %>% 
      arrange(cast.date) %>%
      mutate(cast.num = seq(1, n()))
    
    # Add SOG to all.uctd
    all.uctd.casts <- all.uctd.casts %>% 
      left_join(select(uctd.summ, cast, SOG)) %>% 
      mutate(survey = as.factor(survey.name))
    
    # Write table to CSV
    write.csv(uctd.summ, file = here("Output/cast_summary_uctd.csv"), 
              quote = FALSE, row.names = FALSE)
    
    # Remove unprocessed casts from the summary
    uctd.missing <- all.uctd.hdr %>% 
      filter(!cast %in% unique(all.uctd.casts$cast))
    
    # Write table to CSV
    write.csv(uctd.missing, file = here("Output/unprocessed_uctd.csv"), 
              quote = FALSE, row.names = FALSE)
    
    # Exclude bad casts
    all.uctd.casts <- all.uctd.casts %>%
      filter(!cast %in% exclude.ctd)
    
    # Save results
    save(all.uctd.casts, all.uctd.hdr, uctd.hdr, uctd.proc, uctd.summ,
         file = here("Data/UCTD/uctd_data.Rdata"))
  }  
} else {
  if (file.exists(here("Data/UCTD/uctd_data.Rdata"))) {
    load(here("Data/UCTD/uctd_data.Rdata"))
  }
}
```  

### UCTD cast summary  

Summary of underway CTD (UCTD) casts conducted during the `r survey.name` aboard _`r survey.vessel`_.   

```{r summarize-uctd-casts}
if (exists("uctd.summ")) {
  # Make a copy of uctd.summ
  uctd.table <- uctd.summ %>% 
    select("Cast" = cast.num, "Filename" = cast, "Date" = cast.date, 
           "Lat" = lat, "Long" = long, "Duration" = time, "Depth" = max.depth,
           "Class" = class, "Lag" = lag) %>% 
    mutate(Date = format(Date, "%m/%d/%Y %H:%M:%S"))
  
  # Print table
  uctd.table %>% 
    filter(!is.na(Lag)) %>% 
    mutate(Lag = cell_spec(Lag, knitr.format, color = "black",
                           background = ifelse(abs(Lag) <= 30,"white","orange"))) %>% 
    kable(format = knitr.format,booktabs = TRUE, escape = FALSE,
          digits = c(0,0,0,4,4,0,0,0,0),
          align = c("c","l","c","r","r","r","r","c","r")) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"),
                  full_width = FALSE) %>%
    row_spec(0, align = c("c")) %>% 
    scroll_box(height = "500px")
} else {
  print("No UCTD casts present.")
}
```

### UCTD cast plots  

Profiles of a) temperature, b) salinity, and c) sound speed versus depth for all UCTD casts.

```{r plot-uctd-casts}
if (exists("all.uctd.casts")) {
  # Plot temperature data
  uctd.T <- ggplot(data = all.uctd.casts,
                   aes(T, Z, group = cast, colour = factor(cast))) +
    geom_path(alpha = 0.75) +
    xlab("\nTemperature (C)") + 
    ylab("Depth (m)\n") +
    # Configure x- and y-axis scales
    scale_x_continuous(limits = c(round(min(all.uctd.casts$T),0) - 1,
                                  round(max(all.uctd.casts$T),0) + 1),
                       breaks = seq(round(min(all.uctd.casts$T),0) - 1, 
                                    round(max(all.uctd.casts$T),0) + 1, 2),
                       expand = c(0,0)) + 
    scale_y_continuous(limits = c(round(min(all.uctd.casts$Z), digits = -1), 0),
                       breaks = seq(round(min(all.uctd.casts$Z), digits = -1), 0, 25),
                       expand = c(0,0)) +
    theme_bw() +
    theme(panel.grid.major = element_line(size = 0.75),
          legend.position  = "none") +
    ggtitle("Temperature")
  
  # Plot salinity data
  uctd.S <- ggplot(data = all.uctd.casts,
                   aes(S, Z, group = cast, colour = factor(cast))) +
    geom_path(alpha = 0.75) +
    xlab("\nSalinity") + 
    ylab("Depth (m)\n") +
    # Configure x- and y-axis scales
    scale_x_continuous(limits = c(round(min(all.uctd.casts$S),2) - 0.1,
                                  round(max(all.uctd.casts$S),2) + 0.1),
                       breaks = seq(round(min(all.uctd.casts$S),2) - 0.1, 
                                    round(max(all.uctd.casts$S),2) + 0.1, 1),
                       expand = c(0,0)) +  
    scale_y_continuous(limits = c(round(min(all.uctd.casts$Z),digits = -1),0),
                       breaks = seq(round(min(all.uctd.casts$Z),digits = -1),0,25),
                       expand = c(0,0)) + 
    theme_bw() +
    theme(panel.grid.major = element_line(size = 0.75),
          legend.position  = "none") +
    ggtitle("Salinity")
  
  # Plot salinity data
  uctd.Sv <- ggplot(data = all.uctd.casts,
                    aes(Sv, Z, group = cast, colour = factor(cast))) + 
    geom_path(alpha = 0.75) +
    xlab("\nSound speed (m/s)") + 
    ylab("Depth (m)\n") +
    # Configure x- and y-axis scales
    scale_x_continuous(limits = c(round(min(all.uctd.casts$Sv),0) - 1,
                                  round(max(all.uctd.casts$Sv),0) + 1),
                       breaks = seq(round(min(all.uctd.casts$Sv),0) - 1, 
                                    round(max(all.uctd.casts$Sv),0) + 1, 10),
                       expand = c(0,0)) +  
    scale_y_continuous(limits = c(round(min(all.uctd.casts$Z),digits = -1),0),
                       breaks = seq(round(min(all.uctd.casts$Z),digits = -1),0,25),
                       expand = c(0,0)) + 
    theme_bw() +
    theme(panel.grid.major = element_line(size = 0.75),
          legend.position  = "none") +
    ggtitle("Sound speed")
  
  if (save.figs) {
    # Arrange and save temperature, salinity, and sound speed plots
    all.uctd.plots <- plot_grid(uctd.T, uctd.S, uctd.Sv, 
                                nrow = 1, labels = c("a)","b)","c)"))
    ggsave(here("Figs/fig_uctd_cast_plots.png"), all.uctd.plots, 
           height = 5, width = 9)
  }
  include_graphics(here("Figs/fig_uctd_cast_plots.png"))
} else {
  print("No UCTD casts present.")
}
```  

## Process CTD cast files  

Read header and ASCII files from traditional CTD casts and plot results. The location of each cast is determined by matching the date/time of the cast (extracted from the header; assumes probe was synchronized to the ship's time server) to the navigation data extracted from ERDDAP.  

```{r process-ctd-casts}
# List raw CTD ASCII files
ctd.hdr <- dir_ls(here("Data/CTD"), regexp = ctd.hdr.pattern) %>% 
  path_filter(regexp = "_processed", invert = TRUE)

# Create empty figure if no CTD casts present
if (length(ctd.hdr) == 0) {
  df <- data.frame()
  
  ctd.empty <- ggplot(df) + geom_point() + 
    xlim(0,10) + ylim(0,10) + 
    annotate('text', 5, 5, label = 'No CTD Casts', size = 6, fontface = 'bold') +
    theme_bw()  
  
  ggsave(ctd.empty, filename = here("Figs/fig_ctd_missing.png"))
  
  # Create empty data frame for missing CTD casts
  ctd.missing <- data.frame()
  
} else {
  if (process.ctd) {
    # Extract header info
    all.ctd.hdr <- data.frame()
    
    for (i in ctd.hdr) {
      all.ctd.hdr <- bind_rows(all.ctd.hdr,
                               extract_ctd_header(i, type = "CTD"))
    }
    
    # Process CTD cast files --------------------------------------------------
    # List processed CTD cast files
    ctd.proc <- dir_ls(here("Data/CTD"), regexp = ctd.cast.pattern) %>% 
      path_filter(regexp = "_processed")
    
    # Create a data frame for storing results
    all.ctd.casts <- data.frame()
    
    if (length(ctd.proc) > 0) {
      for (i in ctd.proc) {
        all.ctd.casts <- bind_rows(all.ctd.casts, 
                                   extract_ctd_cast(i, type = "CTD"))
      }
      
      # Save results
      save(all.ctd.casts, all.ctd.hdr, ctd.hdr, ctd.proc, 
           file = here("Data/CTD/ctd_data.Rdata"))
      
    } else {
      load(here("Data/CTD/ctd_data.Rdata"))
    }
    
    # Match UCTD headers to nav data
    nav.match.ctd <- data.frame()
    
    for (i in 1:nrow(all.ctd.hdr)) {
      min.diff      <- which.min(abs(difftime(all.ctd.hdr$cast.date[i], nav$time)))
      nav.match.ctd <- bind_rows(nav.match.ctd, nav[min.diff, ])
    }
    
    # combine header and nav data
    all.ctd.hdr <- all.ctd.hdr %>% 
      bind_cols(nav.match.ctd) %>% 
      mutate(
        cast.num = seq(1, n()),
        type = "CTD",
        lag = difftime(cast.date, time, units = "secs"))
    
    if (nrow(all.ctd.casts) > 0) {
      # reorder all.ctd by cast and depth
      all.ctd.casts <- arrange(all.ctd.casts, cast, desc(Z)) %>% 
        # filter all.ctd to remove bad temperature and salinity 
        filter(between(T, min.T, max.T)) %>% 
        filter(between(S, min.S, max.S)) 
      
      # calculate max depth of each cast
      ctd.depth <- all.ctd.casts %>% 
        group_by(cast) %>% 
        summarise(max.depth = min(Z))
      
      # extract cast number from filename
      all.ctd.hdr <- all.ctd.hdr %>% 
        left_join(ctd.depth)
      
      # summarize uctd casts for water classification
      ctd.class <- all.ctd.casts %>% 
        group_by(cast) %>% 
        summarise(
          min.T = min(T),
          min.S = min(S),
          max.T = max(T),
          max.S = max(S)) %>% 
        # assign classes based on salinity
        mutate(class = case_when(
          min.S <= 31.4 ~ "Type 1",
          min.S >= 33.4 ~ "Type 2",
          TRUE ~ "Type 3"))
      
      all.ctd.hdr <- all.ctd.hdr %>% 
        left_join(select(ctd.class, cast, class)) %>% 
        select(cast.num, cast, cast.date, lat, long, max.depth, class, leg, lag)
      
      # add water mass to the summary table and cast data for plotting
      all.ctd.casts <- all.ctd.casts %>% 
        left_join(select(ctd.class, cast, class)) %>% 
        left_join(select(all.ctd.hdr, cast, leg))  
      
      # write table to CSV
      write.csv(all.ctd.hdr, file = here("Output/cast_summary_ctd.csv"), 
                quote = FALSE, row.names = FALSE)
      
      # Remove unprocessed casts from the summary
      ctd.missing <- all.ctd.hdr %>% 
        filter(!cast %in% all.ctd.casts$cast)
      
      # Exclude bad casts
      all.ctd.casts <- all.ctd.casts %>%
        filter(!cast %in% exclude.ctd)
    } else {
      ctd.missing <- all.ctd.hdr
      
      # Create column for depth if no casts are present
      all.ctd.hdr <- all.ctd.hdr %>% 
        mutate(max.depth = NA_real_,
               class     = NA_character_,
               lag       = NA_real_)
    }
  }
  
  # write table to CSV
  if (exists("ctd.missing")) {
    write.csv(ctd.missing, file = here("Output/unprocessed_ctd.csv"), 
              quote = FALSE, row.names = FALSE)  
  }
}
```  

### CTD cast summary  

Summary of traditional CTD casts conducted during the `r survey.name` aboard _`r survey.vessel`_. 

```{r summarize-ctd-casts}
if (exists("all.ctd.hdr")) {
  # make a copy of all.ctd.hdr
  ctd.table <- all.ctd.hdr %>% 
    select("Cast" = cast.num,  "Filename" = cast, "Date" = cast.date, 
           "Lat" = lat, "Long" = long, "Depth" = max.depth, "Class" = class, 
           "Lag" = lag) %>% 
    mutate(Date = format(Date, "%m/%d/%Y %H:%M:%S")) 
  
  # Print table
  ctd.table %>%
    mutate(Lag = ifelse(is.na(Lag), 0, Lag)) %>%
    mutate(Lag = cell_spec(Lag, knitr.format, color = "black",
                           background = ifelse(Lag <= 30, "white", "orange"))) %>% 
    kable(format = knitr.format,booktabs = TRUE, escape = FALSE,
          digits = c(0,0,0,2,2,0,0,0,0),
          align = c("c","l","c","r","r","r","c","r")) %>% 
    kable_styling(bootstrap_options = c("striped", "hover", "condensed"), 
                  full_width = FALSE) %>%
    row_spec(0, align = c("c")) %>% 
    scroll_box(height = "500px") 
} else {
  print("No CTD casts present.")
}
```  

### CTD cast plots  

Profiles of a) temperature, b) salinity, and c) sound speed versus depth for all CTD casts.

```{r plot-ctd-casts,eval=FALSE}
if (exists("all.ctd.casts")) {
  if (nrow(all.ctd.casts) > 0) {
    # Plot temperature data
    ctd.T <- ggplot(data = all.ctd.casts, 
                    aes(T, Z, group = cast, colour = factor(cast))) + 
      geom_path(alpha = 0.75) +
      xlab("\nTemperature (C)") + 
      ylab("Depth (m)\n") +
      # Configure x- and y-axis scales
      scale_x_continuous(limits = c(round(min(all.ctd.casts$T),0) - 1, 
                                    round(max(all.ctd.casts$T),0) + 1),
                         breaks = seq(round(min(all.ctd.casts$T),0) - 1, 
                                      round(max(all.ctd.casts$T),0) + 1, 2),
                         expand = c(0,0)) + 
      scale_y_continuous(limits = c(round(min(all.ctd.casts$Z),digits = -1), 0),
                         breaks = seq(round(min(all.ctd.casts$Z),digits = -1), 0, 25),
                         expand = c(0,0)) +
      theme_bw() +
      theme(panel.grid.major = element_line(size = 0.75),
            legend.position  = "none") +
      ggtitle("Temperature")
    
    # Plot salinity data
    ctd.S <- ggplot(data = all.ctd.casts,
                    aes(S,Z,group = cast, colour = factor(cast))) + 
      geom_path(alpha = 0.75) +
      xlab("\nSalinity") + 
      ylab("Depth (m)\n") +
      # Configure x- and y-axis scales
      scale_x_continuous(limits = c(round(min(all.ctd.casts$S),2) - 0.1, 
                                    round(max(all.ctd.casts$S),2) + 0.1),
                         breaks = seq(round(min(all.ctd.casts$S),2) - 0.1, 
                                      round(max(all.ctd.casts$S),2) + 0.1, 1),
                         expand = c(0,0)) +  
      scale_y_continuous(limits = c(round(min(all.ctd.casts$Z),digits = -1), 0),
                         breaks = seq(round(min(all.ctd.casts$Z),digits = -1), 0, 25),
                         expand = c(0,0)) + 
      theme_bw() +
      theme(panel.grid.major = element_line(size = 0.75),
            legend.position  = "none") +
      ggtitle("Salinity")
    
    # Plot salinity data
    ctd.Sv <- ggplot(data = all.ctd.casts, 
                     aes(Sv, Z, group = cast, colour = factor(cast))) + 
      geom_path(alpha = 0.75) +
      xlab("\nSound speed (m/s)") + 
      ylab("Depth (m)\n") +
      # Configure x- and y-axis scales
      scale_x_continuous(limits = c(round(min(all.ctd.casts$Sv),0) - 1,
                                    round(max(all.ctd.casts$Sv),0) + 1),
                         breaks = seq(round(min(all.ctd.casts$Sv),0) - 1, 
                                      round(max(all.ctd.casts$Sv),0) + 1, 10),
                         expand = c(0,0)) +  
      scale_y_continuous(limits = c(round(min(all.ctd.casts$Z),digits = -1),0),
                         breaks = seq(round(min(all.ctd.casts$Z),digits = -1),0,25),
                         expand = c(0,0)) + 
      theme_bw() +
      theme(panel.grid.major = element_line(size = 0.75),
            legend.position  = "none") +
      ggtitle("Sound speed")
    
    if (save.figs) {
      # Arrange and save temperature, salinity, and sound speed plots
      all.ctd.plots <- plot_grid(ctd.T, ctd.S,ctd.Sv, 
                                 nrow = 1, labels = c("a)","b)","c)"))
      
      ggsave(here("Figs/fig_ctd_cast_plots.png"),all.ctd.plots,
             height = 5,width = 9)
    }
    
    include_graphics(here("Figs/fig_ctd_cast_plots.png")) 
  }
} else {
  print("No CTD casts present.")
}
```  

## Combine CTD/UCTD cast data

```{r combine-cast-data}
if (exists("all.ctd.hdr") & exists("uctd.summ")) {
  # Combine all CTD and UCTD cast info in one data frame
  ctd.info.all <- all.ctd.hdr %>% 
    bind_rows(select(uctd.summ, cast.num, cast, cast.date, lat, long, max.depth, class, leg, lag)) %>% 
    mutate(type = case_when(
      str_detect(cast, "UCTD") ~ "UCTD",
      TRUE ~ "CTD")) %>% 
    filter(!is.na(lat), !is.na(long))
  
  # Combine all CTD and UCTD cast data in one data frame
  ctd.data.all <- bind_rows(all.ctd.casts, all.uctd.casts) %>%
    left_join(select(ctd.info.all, cast, lat, long)) %>% 
    filter(cast %in% ctd.info.all$cast)
  
  # Save to CSV file
  write.csv(ctd.data.all, file = here("Output/all_ctd_data.csv"), 
            quote = FALSE, row.names = FALSE)
  
  write.csv(ctd.info.all, file = here("Output/all_ctd_info.csv"), 
            quote = FALSE, row.names = FALSE) 
} else {
  print("No CTD/UCTD casts present.")
}
```

## Assign CTD casts to acoustic transects  

UCTD and CTD casts are assigned to acoustic transects so that they may be later used to determine the integration depth for estimating CPS abundance and biomass.  

```{r assign-ctd-transects}
if (exists("ctd.info.all")) {
  if (process.ctd) {
    # Assign nearest acoustic transect to CTD/UCTD cast
    # Create varialble for nearest cluster
    ctd.info.all$transect.name <- NA_character_
    ctd.info.all$transect      <- NA_real_
    
    # Configure progress bar
    pb <- tkProgressBar("CTD Transect Assignment", "CTD Transect", 0, 100, 50)
    
    # Match CTD casts to transects
    for (i in 1:nrow(ctd.info.all)) {
      # Calculate distance between each CTD/UCTD and all NASC data
      transect.distance <- distance(ctd.info.all$lat[i], ctd.info.all$long[i], 
                                    nasc$lat, nasc$long, units = "nm")
      # Assign trawl name and number with minimum distance to the CTD/UCTD cast
      ctd.info.all$transect.name[i] <- nasc$transect.name[which.min(transect.distance)]
      ctd.info.all$transect[i]      <- nasc$transect[which.min(transect.distance)]
      # Update the progress bar
      pb.prog <- round(i/nrow(ctd.info.all)*100)
      info <- sprintf("%d%% done", pb.prog)
      setTkProgressBar(pb, pb.prog, 
                       sprintf("CTD Transect Assignment (%s)", info), info)
    }
    # Close progress bar
    close(pb)
    
    # Save results
    save(ctd.info.all, file = here("Output/all_ctd_info.Rdata"))
    
  } else {
    if (file.exists(here("Output/all_ctd_info.Rdata"))) {
      # Load ctd.info.all
      load(here("Output/all_ctd_info.Rdata"))
    }
  }
  
  # Project CTD info table
  ctd.info.all <- project_df(ctd.info.all, to = 3310)
  
  # Convert CTD dataframe so sf for mapping
  ctd.info.sf <- st_as_sf(ctd.info.all, coords = c("long","lat"), crs = crs.geog) %>% 
    mutate(cast.type = type)
} else {
  print("No CTD/UCTD casts.")
}
```

## Map CTD/UCTD cast locations  

Maps of CTD (blue) and UCTD (purple) cast locations, labeled by a) cast number and b) sequential acoustic transect number (not transect names from Echoview templates). Panel b) is used to check whether CTD casts are being assigned to the appropriate acoustic transects.

```{r map-ctd-casts,eval=FALSE}
if (exists("ctd.info.all")) {
  if (save.figs) {
    # Plot all CTDs and UCTDs, labeled by cast number
    map.ctd.uctd <- base.map + 
      # Plot vessel track
      geom_sf(data = nav.paths.sf, colour = 'gray50', size = 0.25, alpha = 0.5) +
      # Plot CTD cast locations
      geom_shadowtext(data = ctd.info.all, aes(X, Y, label = cast.num, colour = type),
                      size = 2, bg.colour = "white", fontface = "bold") + 
      scale_colour_manual(name = "Type", values = c(CTD = "blue", UCTD = "purple")) +
      coord_sf(crs = crs.proj,
               xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
               ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
    
    # Plot all CTDs and UCTDs, labeled by transect assignment
    map.ctd.tx <- base.map + 
      # Plot vessel track
      geom_sf(data = nav.paths.sf, colour = 'gray50', size = 0.25, alpha = 0.5) +
      # Plot CTD cast locations
      geom_shadowtext(data = ctd.info.all, aes(X, Y, label = transect, colour = type),
                      size = 2, bg.colour = "white", fontface = "bold") + 
      scale_colour_manual(name = "Type", values = c(CTD = "blue", UCTD = "purple")) +
      coord_sf(crs = crs.proj,
               xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
               ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
    
    # Combine plots into two panels
    map.ctd.all <- plot_grid(map.ctd.uctd, map.ctd.tx, 
                             nrow = 1, labels = c("a)","b)"))
    
    # Save maps
    ggsave(here("Figs/fig_ctd_uctd_map.png"), map.ctd.uctd, 
           width = map.width, height = map.height)
    
    ggsave(here("Figs/fig_ctd_tx_map.png"),   map.ctd.tx,   
           width = map.width, height = map.height)
    
    ggsave(here("Figs/fig_ctd_map_all.png"),  map.ctd.all,  
           width = map.width*2, height = map.height)
  }
  
  include_graphics(here("Figs/fig_ctd_map_all.png"))
} else {
  print("No CTD casts present.")
}

```  

(ref:all-casts-mapview) An interactive map of CTD (purple) and UCTD (yellow) cast locations. Click points for more information about each cast.

```{r map-ctd-casts-interactive,fig.cap='(ref:all-casts-mapview)',eval=FALSE}
if (exists("ctd.info.sf")) {
  # Create interactive map of CTD locations
  mapview(nav.paths.sf, color = "black", alpha = 0.5, 
          layer.name = "Vessel track", col.regions = "black",
          legend = FALSE) +
    mapview(ctd.info.sf, cex = 4, zcol = "leg",
            layer.name = "CTD Casts", legend = TRUE)  
} else {
  print("No CTD casts present.")
}
```

## Calculate mixed-layer depth for each CTD cast  

Consider estimating thermocline depth using the method described by Alvera-Azcarate et al. [-@Alvera-Azcarate2011]. Some preliminary code has been developed in `Code/estimateThermocline.R`.  

## Calculate distance from shore for all NASC data and CTD/UCTD casts  

Juan does this as a precursor to defining the integration depth by temperature.  

## Estimate the lower limit of CPS distribution using the CTD casts and echo-integration files  

This is currently being done by hand using Juan's CTD "app" and added to the `nasc` data frame as `cps.nasc`, if available. If not, `NASC.50` is used until those data are available, or until the process is automated by this script. The source of the `cps.nasc` data is defined in the `survey_info_*.R` file in the `Code` directory.  

# Interactively explore acoustic, trawl, and CUFES data  

```{r create-imap-objects, include=FALSE}
# Convert backscatter data to sf -----------------------------------
big.nasc.sf <- big.nasc %>% 
  top_n(20, cps.nasc) %>%
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

# Convert CTD and UCTD cast data to sf -----------------------------------
if (exists("ctd.info.all")) {
  ctd.sf <- ctd.info.all %>%
    # bind_rows(all.uctd.hdr) %>% 
    mutate(name = paste(type, cast.num),
           label = paste("Cast:", cast),
           popup = paste('<b>Cast:', cast, '</b><br/>',
                         'Transect name:', transect.name, '<br/>',
                         'Max. depth:', max.depth, 'm<br/>')) %>% 
    select(name, lat, long, max.depth, type, label, popup) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) 
}

# Convert haul catch to sf and create labels ----------------------------------
cluster.catch.sf <- cluster.pie %>%
  st_as_sf(coords = c("X","Y"), crs = crs.proj) %>%
  st_transform(crs = crs.geog) 

# Add cluster species composition labels and popups ---------------------------
nasc.super.clusters <- nasc.super.clusters %>% 
  left_join(select(cluster.pie, cluster, label, popup))

# Convert CUFES data to sf -----------------------------------
cufes.sf <- cufes %>% 
  filter(Density > 0, Species %in% cufes.plot.spp) %>%
  mutate(
    spp.label = case_when(
      Species == "SardineEggs" ~ "Sardine",
      Species == "AnchovyEggs" ~ "Anchovy",
      Species == "JackMackerelEggs"~ "Jack mackerel",
      TRUE ~ Species),
    label = paste(spp.label, " eggs: ", round(Density, 1), " /cubic m", sep = ""),
    popup = paste('<b>Species:', spp.label, '</b><br/>', round(Density, 1),"eggs m<sup>3</sup>")) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>%
  arrange(desc(Density))

cufes.squid.sf <- cufes %>% 
  filter(Density > 0, Species == "SquidEggs") %>%
  mutate(
    spp.label = case_when(
      Species == "SquidEggs" ~ "Squid",
      TRUE ~ Species),
    label = paste(spp.label, " eggs: ", round(Density, 1), " /cubic m", sep = ""),
    popup = paste('<b>Species:', spp.label, '</b><br/>', round(Density, 1),"eggs m<sup>3</sup>")) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog)

cufes.ofe.sf <- cufes %>% 
  filter(Density > 0, Species == "OtherFishEggs") %>%
  filter(str_detect(Comments, "Scomber japonicus")|
         str_detect(Comments, "scomber japonicus")|
         str_detect(Comments, "S. japonicus")) %>%
  mutate(
    spp.label = case_when(
      Species == "OtherFishEggs" ~ "Other fish",
      TRUE ~ Species),
    label = paste(spp.label, " eggs: ", round(Density, 1), " /cubic m", sep = ""),
    popup = paste('<b>Species:', spp.label, '</b><br/>', round(Density, 1),"eggs m<sup>3</sup><br/>", 
                  '</b>Comment:</b>', Comments)) %>%
  st_as_sf(coords = c("long","lat"), crs = crs.geog)

# Convert negative CUFES samples to sf; CRS - 4326
cufes.neg.sf <- cufes %>% 
  filter(Density == 0, Species %in% cufes.plot.spp) %>%
  mutate(
    label = paste(round(Density, 1), " eggs/cubic m", sep = ""),
    popup = label) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog)

# Convert biomass density to sf ------------------------------
nasc.density.sf <- nasc.density.plot.all %>% 
  st_as_sf(coords = c("long", "lat"), crs = crs.geog) %>% 
  mutate(
    label = paste0('Species: ', scientificName, "; ", 
                   'Transect: ', transect, "; ",
                   'Density: ', signif(density, 2), ' t/sq.nmi'),
    popup = paste0('<b>Species: </b>', scientificName,  '<br/>',
                   '<b>Transect: </b>', transect, '<br/>',
                   '<b>Density: </b>', signif(density, 2), ' t nmi<sup>-2</sup>')
  )

# Read State Waters shapefiles -------------------------------
ca_waters <- st_read(here("Data/GIS/ca_state_waters.shp")) %>% 
  st_transform(crs.geog)

or_waters <- st_read(here("Data/GIS/or_state_waters.shp")) %>% 
  st_transform(crs.geog)

# Read CA MPAs shapefile --------------------------------------
ca_mpas <- st_read(here("Data/GIS/ca_mpas.shp")) %>% 
  st_transform(crs.geog) %>% 
  mutate(MPA = paste(NAME, Type))

or_mpas <- st_read(here("Data/GIS/or_mpas.shp")) %>% 
  st_transform(crs.geog) 

# Read CA MPAs shapefile --------------------------------------
nms <- st_read(here("Data/GIS/national_marine_sanctuaries.shp")) %>% 
  filter(REGION == "West Coast") %>% 
  st_transform(crs.geog)

# Read Channel Islands shapefile
channel_is <- st_read(here("Data/GIS/channel_islands.shp")) %>% 
  st_transform(crs.geog)

# Read EEZ shapefiles -----------------------------------------
eez_usa <- st_read(here("Data/GIS/eez_us.shp")) %>% 
  st_transform(crs.geog)
eez_can <- st_read(here("Data/GIS/eez_canada.shp")) %>% 
  st_transform(crs.geog)
eez_mex <- st_read(here("Data/GIS/eez_mex.shp")) %>% 
  st_transform(crs.geog)
```

(ref:interactive-data-explorer) Interactively explore acoustic backscatter (_s_~A~, m^2^ nmi^-2^) and trawl data. Base maps may be changed and other layers may be toggled on/off using the layer controls below the map inset. Blue markers ("big NASC") are potential outliers; hover over the markers to identify the transect-interval for further exploration.

```{r interactive-data-explorer}
# | fig.align: 'left'
# | fig.cap: '(ref:interactive-data-explorer)'
# | fig.height: '10in'
# | out.width: '100%'

# Leaflet options
# https://rstudio.github.io/leaflet/

# Info on tile caching
# https://bhaskarvk.github.io/leaflet.extras/reference/TileCaching.html

# Set padding around data  
imap.bounds <- map_bounds(nasc$lat, nasc$long, 0.1) 

# Create color palette for MPAs
all.mpa.types <- as.factor(c(unique(as.character(ca_mpas$Type)), 
                             unique(as.character(or_mpas$Label))))

mpaPal  <- colorFactor(topo.colors(10), all.mpa.types)

# Create color pallette for CUFES
cufesPal <- colorFactor(cufes.colors, cufes.sf$Species)

# Create color pallette for CPS species
cpsPal <- colorFactor(
  c(jacksmelt.color, pac.herring.color, anchovy.color, 
    rnd.herring.color, sardine.color, pac.mack.color, 
    jack.mack.color),
  c("Atherinopsis californiensis", "Clupea pallasii", "Engraulis mordax", 
    "Etrumeus acuminatus", "Sardinops sagax", "Scomber japonicus", 
    "Trachurus symmetricus"))

# Create color pallette for planned transects
txPal    <- colorFactor(wpt.colors, wpt.types)

# Create color palette for trawls casts (presently unused)
trawlPal <- c('#00CD66', '#0000FF', '#A020F0',
              '#F5DEB3', '#00FFFF', '#FF0000')

# Create color palette for CTD casts
ctdPal <- colorFactor(c("#FFA500", "#A020F0"), c("CTD", "UCTD"))

# Select plot levels for backscatter data
nasc.levels.all <- sort(unique(nasc.plot$bin.level))
nasc.labels.all <- nasc.labels[sort(nasc.levels.all)]
nasc.sizes.all  <- nasc.sizes[sort(nasc.levels.all)]
nasc.colors.all <- nasc.colors[sort(nasc.levels.all)]

# Create color palette for NASC
nascPal <- colorFactor(nasc.colors.all, nasc.levels.all)
densPal <- colorFactor(dens.colors.all, dens.levels.all)

# Remove GEOMETRYCOLLECTION sf strata for Leaflet map
strata.primary.sub <- strata.primary %>% 
  filter(!st_geometry_type(.) == "GEOMETRYCOLLECTION")

strata.nse.sub <- strata.nse %>% 
  filter(!st_geometry_type(.) == "GEOMETRYCOLLECTION")

if (do.imap) {
  i.map <- leaflet() %>% 
    # Enable tile caching
    enableTileCaching() %>% 
    # Add provider tiles; # http://leaflet-extras.github.io/leaflet-providers/preview/index.html
    addProviderTiles(providers$Esri.NatGeoWorldMap, 
                     group = "Esri.NatGeoWorldMap",
                     options = tileOptions(useCache = useCachedTile,
                                           crossOrigin = useCrossOrigin)) %>%
    # Add EEZs
    addPolylines(data = eez_usa, color = "#000414", weight = 3, 
                 label = "EEZ-U.S.", group = "Exclusive Economic Zones") %>% 
    addPolylines(data = eez_can, color = "#000414", weight = 3, 
                 label = "EEZ-Canada", group = "Exclusive Economic Zones") %>% 
    addPolylines(data = eez_mex, color = "#000414", weight = 3, 
                 label = "EEZ-Mexico", group = "Exclusive Economic Zones") %>% 
    # Add bathymetry contours
    addPolylines(data = bathy, color = "white", weight = 2, 
                 label = ~paste(Depth, "m"), group = "Bathymetry Contours") %>% 
    # Add State waters
    addPolygons(data = or_waters, weight = 2, fillColor = "transparent", 
                opacity = 0.75,
                label = ~htmlEscape("OR State Waters"),
                group = "State Waters") %>%
    addPolygons(data = ca_waters, weight = 2, fillColor = "transparent",
                opacity = 0.75,
                label = ~htmlEscape("CA State Waters"),
                group = "State Waters") %>%
    # Add CA MPAs
    addPolygons(data = ca_mpas, color = "#000414", weight = 2, fillColor = ~mpaPal(Type),
                fillOpacity = 0.3, label = ~htmlEscape(MPA), group = "MPAs") %>%
    # Add OR MPAs
    addPolygons(data = or_mpas, color = "#000414", weight = 2, fillColor =  ~mpaPal(Label),
                fillOpacity = 0.3, label = ~htmlEscape(Name), group = "MPAs") %>%
    # Add core planned transects
    addPolylines(data = filter(transects.sf, Type %in% c("Compulsory", "Adaptive")),
                 color = ~txPal(Type), weight = 3, opacity = 0.5,
                 label = ~htmlEscape(paste(Type, Transect)),
                 popup = ~popup,
                 group = "Planned Transects (Core)") %>%
    addCircleMarkers(data = filter(wpts.sf, Type %in% c("Compulsory", "Adaptive")),
                     radius = 3, color = "#000414", stroke = FALSE, opacity = 0.5,
                     fillOpacity = 0.5, fillColor =  ~txPal(Type),
                     label = ~htmlEscape(paste(Type, Waypoint)),
                     popup = ~popup,
                     group = "Planned Transects (Core)") %>%
    # Add scale bar
    addScaleBar(position = "bottomright") %>%
    # Add map coordinates
    addMouseCoordinates() %>% 
    # Add measurement tool
    addMeasure(primaryLengthUnit = "miles", secondaryLengthUnit = "km",
               primaryAreaUnit = "sqmiles", secondaryAreaUnit = "sqmeters",
               position = "topleft") %>% 
    # Add layer controls
    addLayersControl(
      overlayGroups = c("MPAs", "State Waters", "Exclusive Economic Zones", 
                        "Bathymetry Contours",
                        "Planned Transects (Core)", "Planned Transects (Ancillary)",
                        "Vessel Track", "Vessel Positions", "Trawls", 
                        "Trawl Cluster Polygons", "CTD Casts",
                        "Backscatter-CPS", "Backscatter-CPS (Small)",
                        "Backscatter-Krill", "Backscatter (Large)",
                        "CUFES Egg Density", "CUFES Egg Density-Other",
                        "CUFES Egg Density-Squid", "CUFES (Negative)",
                        "Biomass (Anchovy)", "Biomass (Sardine)",
                        "Biomass (J. mackerel)", "Biomass (P. mackerel)", 
                        "Biomass (Herring)", "Biomass (R. herring)"),
      options = layersControlOptions(collapsed = FALSE)) %>% 
    fitBounds(imap.bounds$range.lon[1], imap.bounds$range.lat[1],
              imap.bounds$range.lon[2], imap.bounds$range.lat[2])
  
  # Add nav data and vessel positions
  if (exists("nav.paths.sf"))
    i.map <- i.map %>% 
      # Add nav data
      addPolylines(data = nav.paths.sf, color = "#000414", weight = 1, 
                   label = ~leg, group = "Vessel Track") %>%
      addMarkers(data = nav.now, label = ~label, popup = ~popup, 
                 group = "Vessel Positions")
  
  # Add nearshore extrapolation polygons
  if(nrow(filter(strata.nse.sub, scientificName == "Clupea pallasii")) > 0)
    i.map <- i.map %>% 
      addPolygons(data = filter(strata.nse.sub, scientificName == "Clupea pallasii"), 
                  weight = 2, color = ~cpsPal(scientificName), fillColor = ~cpsPal(scientificName),
                  fillOpacity = 0.50, group = "Biomass (Herring)") 
  if(nrow(filter(strata.nse.sub, scientificName == "Engraulis mordax")) > 0)
    i.map <- i.map %>% 
      addPolygons(data = filter(strata.nse.sub, scientificName == "Engraulis mordax"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = ~cpsPal(scientificName),
                  fillOpacity = 0.50, group = "Biomass (Anchovy)")
  if(nrow(filter(strata.nse.sub, scientificName == "Sardinops sagax")) > 0)
    i.map <- i.map %>% 
      addPolygons(data = filter(strata.nse.sub, scientificName == "Sardinops sagax"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = ~cpsPal(scientificName),
                  fillOpacity = 0.50, group = "Biomass (Sardine)") 
  if(nrow(filter(strata.nse.sub, scientificName == "Scomber japonicus")) > 0)
    i.map <- i.map %>% 
      addPolygons(data = filter(strata.nse.sub, scientificName == "Scomber japonicus"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = ~cpsPal(scientificName),
                  fillOpacity = 0.50, group = "Biomass (P. mackerel)") 
  if(nrow(filter(strata.nse.sub, scientificName == "Trachurus symmetricus")) > 0)
    i.map <- i.map %>% 
      addPolygons(data = filter(strata.nse.sub, scientificName == "Trachurus symmetricus"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = ~cpsPal(scientificName),
                  fillOpacity = 0.50, group = "Biomass (J. mackerel)")
  
  # Add ancillary planned transects
  if(nrow(filter(transects.sf, Type == "Nearshore")) > 0)
    i.map <- i.map %>%
      addPolylines(data = filter(transects.sf, Type == "Nearshore"),
                   color = ~txPal(Type), weight = 3, opacity = 0.5,
                   label = ~htmlEscape(paste(Type, Transect)),
                   popup = ~popup,
                   group = "Planned Transects (Ancillary)")
  if(nrow(filter(transects.sf, Type == "Offshore")) > 0)
    i.map <- i.map %>%
      addPolylines(data = filter(transects.sf, Type == "Offshore"),
                   color = ~txPal(Type), weight = 3, opacity = 0.5,
                   label = ~htmlEscape(paste(Type, Transect)),
                   popup = ~popup,
                   group = "Planned Transects (Ancillary)")
  if(nrow(filter(transects.sf, Type == "Saildrone")) > 0)
    i.map <- i.map %>%
      addPolylines(data = filter(transects.sf, Type == "Saildrone"),
                   color = ~txPal(Type), weight = 3, opacity = 0.5,
                   label = ~htmlEscape(paste(Type, Transect)),
                   popup = ~popup,
                   group = "Planned Transects (Ancillary)")
  if(nrow(filter(transects.sf, Type == "Transit")) > 0)
    i.map <- i.map %>%
      addPolylines(data = filter(transects.sf, Type == "Transit"),
                   color = ~txPal(Type), weight = 3, opacity = 0.5,
                   label = ~htmlEscape(paste(Type, Transect)),
                   popup = ~popup,
                   group = "Planned Transects (Ancillary)")
  
  # Add primary stratum polygons and biomass densities
  if(nrow(filter(strata.primary.sub, scientificName == "Clupea pallasii")) > 0)
    i.map <- i.map %>%
      addPolygons(data = filter(strata.primary.sub, scientificName == "Clupea pallasii"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = "transparent",
                  group = "Biomass (Herring)") %>% 
      addCircleMarkers(data = filter(nasc.density.sf, scientificName == "Clupea pallasii"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~densPal(bin.level),
                       label = ~label, popup = ~popup, 
                       group = "Biomass (Herring)") %>% 
      addLegend("bottomleft", colors = dens.colors,
                values = sort(unique(nasc.density.sf$bin.level)),
                labels = dens.labels,
                title = "Biomass Density (Herring) <br/> (t nmi<sup>-2</sup>)",
                opacity = 1, group = "Biomass (Herring)") 
  
  if(nrow(filter(strata.primary.sub, scientificName == "Engraulis mordax")) > 0)
    i.map <- i.map %>%
      addPolygons(data = filter(strata.primary.sub, scientificName == "Engraulis mordax"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = "transparent", 
                  group = "Biomass (Anchovy)") %>% 
      addCircleMarkers(data = filter(nasc.density.sf, scientificName == "Engraulis mordax"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       label = ~label, popup = ~popup, 
                       fillOpacity = 0.75, fillColor =  ~densPal(bin.level),
                       group = "Biomass (Anchovy)") %>% 
      addLegend("bottomleft", colors = dens.colors,
                values = sort(unique(nasc.density.sf$bin.level)),
                labels = dens.labels,
                title = "Biomass Density (Anchovy) <br/> (t nmi<sup>-2</sup>)",
                opacity = 1, group = "Biomass (Anchovy)")
  
  if(nrow(filter(strata.primary.sub, scientificName == "Sardinops sagax")) > 0)
    i.map <- i.map %>%
      addPolygons(data = filter(strata.primary.sub, scientificName == "Sardinops sagax"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = "transparent",
                  group = "Biomass (Sardine)") %>% 
      addCircleMarkers(data = filter(nasc.density.sf, scientificName == "Sardinops sagax"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       label = ~label, popup = ~popup, 
                       fillOpacity = 0.75, fillColor =  ~densPal(bin.level),
                       group = "Biomass (Sardine)") %>% 
      addLegend("bottomleft", colors = dens.colors,
                values = sort(unique(nasc.density.sf$bin.level)),
                labels = dens.labels,
                title = "Biomass Density (Sardine) <br/> (t nmi<sup>-2</sup>)",
                opacity = 1, group = "Biomass (Sardine)")
  
  if(nrow(filter(strata.primary.sub, scientificName == "Scomber japonicus")) > 0)
    i.map <- i.map %>%
      addPolygons(data = filter(strata.primary.sub, scientificName == "Scomber japonicus"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = "transparent",
                  group = "Biomass (P. mackerel)") %>% 
      addCircleMarkers(data = filter(nasc.density.sf, scientificName == "Scomber japonicus"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       label = ~label, popup = ~popup, 
                       fillOpacity = 0.75, fillColor =  ~densPal(bin.level),
                       group = "Biomass (P. mackerel)") %>% 
      addLegend("bottomleft", colors = dens.colors,
                values = sort(unique(nasc.density.sf$bin.level)),
                labels = dens.labels,
                title = "Biomass Density (P. Mackerel) <br/> (t nmi<sup>-2</sup>)",
                opacity = 1, group = "Biomass (P. mackerel)")
  
  if(nrow(filter(strata.primary.sub, scientificName == "Trachurus symmetricus")) > 0)
    i.map <- i.map %>%
      addPolygons(data = filter(strata.primary.sub, scientificName == "Trachurus symmetricus"), 
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = "transparent",
                  group = "Biomass (J. mackerel)") %>% 
      addCircleMarkers(data = filter(nasc.density.sf, scientificName == "Trachurus symmetricus"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       label = ~label, popup = ~popup, 
                       fillOpacity = 0.75, fillColor =  ~densPal(bin.level),
                       group = "Biomass (J. mackerel)") %>% 
      addLegend("bottomleft", colors = dens.colors,
                values = sort(unique(nasc.density.sf$bin.level)),
                labels = dens.labels,
                title = "Biomass Density (Jack Mackerel) <br/> (t nmi<sup>-2</sup>)",
                opacity = 1, 
                group = "Biomass (J. mackerel)")
  
  if(nrow(filter(strata.primary.sub, scientificName == "Etrumeus acuminatus")) > 0)
    i.map <- i.map %>%
      addPolygons(data = filter(strata.primary.sub, scientificName == "Etrumeus acuminatus"),
                  weight = 2, color =  ~cpsPal(scientificName), fillColor = "transparent",
                  group = "Biomass (R. herring)") %>%
      addCircleMarkers(data = filter(nasc.density.sf, scientificName == "Etrumeus acuminatus"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       label = ~label, popup = ~popup,
                       fillOpacity = 0.75, fillColor =  ~densPal(bin.level),
                       group = "Biomass (R. herring)") %>%
      addLegend("bottomleft", colors = dens.colors,
                values = sort(unique(nasc.density.sf$bin.level)),
                labels = dens.labels,
                title = "Biomass Density (Round Herring) <br/> (t nmi<sup>-2</sup>)",
                opacity = 1,
                group = "Biomass (R. herring)")
  
  # Add CUFES data
  if (nrow(cufes.neg.sf) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = cufes.neg.sf, radius = ~bin.level*2, color = "#000414", stroke = FALSE, weight = 1,
                       fillOpacity = 0.50, fillColor =  "#000414", label = ~htmlEscape(SampleNumber),
                       group = "CUFES (Negative)")
  
  if (nrow(filter(cufes.sf, Species == "AnchovyEggs")) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = filter(cufes.sf, Species == "AnchovyEggs"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~cufesPal(Species), label = ~label,
                       popup = ~popup, group = "CUFES Egg Density")
  
  if (nrow(filter(cufes.sf, Species == "JackMackerelEggs")) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = filter(cufes.sf, Species == "JackMackerelEggs"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~cufesPal(Species), label = ~label,
                       popup = ~popup, group = "CUFES Egg Density")
  
  if (nrow(filter(cufes.sf, Species == "SardineEggs")) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = filter(cufes.sf, Species == "SardineEggs"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~cufesPal(Species), label = ~label,
                       popup = ~popup, group = "CUFES Egg Density")
  
  if (nrow(cufes.squid.sf) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = cufes.squid.sf,
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  "#FFFFFF", label = ~label,
                       popup = ~popup, group = "CUFES Egg Density-Squid")
  
  if (nrow(cufes.ofe.sf) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = cufes.ofe.sf,
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  pac.mack.color, label = ~label,
                       popup = ~popup, group = "CUFES Egg Density-Other") 
  
  # Add backscatter data
  if (nrow(filter(nasc.plot.sf, NASC < 200)) > 0)
    i.map <- i.map %>%  
      addCircleMarkers(data = filter(nasc.plot.sf, NASC < 200), 
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75,  fillColor = ~nascPal(bin.level), 
                       label = ~label, popup = ~popup, 
                       group = "Backscatter-CPS (Small)")
  
  if (nrow(filter(nasc.plot.sf, NASC >= 200)) > 0)
    i.map <- i.map %>%  
      addCircleMarkers(data = filter(nasc.plot.sf, NASC >= 200), 
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~nascPal(bin.level), 
                       label = ~label, popup = ~popup,
                       group = "Backscatter-CPS") %>%
      addLegend("bottomleft", colors = nasc.colors.all, 
                values = sort(unique(nasc.cps.sf$bin.level)),
                labels = nasc.labels.all, 
                title = "CPS Backscatter<br/> (s<sub>A</sub>; m<sup>2</sup> nmi<sup>-2</sup>)", 
                opacity = 1, group = "Backscatter-CPS")
  
  # Add trawl paths 
  if (nrow(haul.paths) > 0)
    i.map <- i.map %>%  
      addPolylines(data = haul.paths, color = c("#000000"), weight = 5, opacity = 0.8, 
                   popup = ~popup, label = ~label, 
                   group = "Trawls") 
  if (nrow(cluster.catch.sf) > 0)
    i.map <- i.map %>% 
      # Add trawl catch
      addCircleMarkers(data = cluster.catch.sf, radius = 5, color = "#000000", stroke = TRUE, weight = 2,
                       opacity = 0.8, fillOpacity = 1, fillColor =  "white",
                       popup = ~popup, label = ~label,
                       group =  "Trawls") 
  if (nrow(nasc.super.clusters) > 0)
    i.map <- i.map %>%
      # Add NASC super clusters
      addPolygons(data = nasc.super.clusters, 
                  weight = 2, fillColor = "#4046ED", color = "#000414", 
                  label = ~label, popup = ~popup,
                  group = "Trawl Cluster Polygons")
  
  # Add backscatter outliers
  if (nrow(big.nasc.sf) > 0)
    i.map <- i.map %>%
      addMarkers(data = big.nasc.sf, label = ~label, popup = ~popup,
                 group = "Backscatter (Large)")
  
  # Add CTD and UCTD data
  if (exists("ctd.sf"))
    i.map <- i.map %>% 
      addCircleMarkers(data = ctd.sf, radius = 8, color = "#000414", stroke = TRUE,
                       weight = 2, opacity = 1, fillOpacity = 0.75, fillColor =  ~ctdPal(type),
                       label = ~label, popup = ~popup, group =  "CTD Casts")
  
  # Hide groups
  i.map <- i.map %>% 
    hideGroup(c(
      "Exclusive Economic Zones",
      "Backscatter (Large)", "Backscatter-Krill", 
      "CUFES Egg Density", "CUFES (Negative)", "CUFES Egg Density-Other",
      "CUFES Egg Density-Squid", "Vessel Positions", "Saildrone Tracks", 
      "Trawl Cluster Polygons",
      "Biomass (Anchovy)", "Biomass (Sardine)",
      "Biomass (J. mackerel)", "Biomass (P. mackerel)", 
      "Biomass (Herring)", "Biomass (R. herring)", "CTD Casts"))
  
  # Display map
  i.map
  
} else {
  print("No interactive map created. Check \"do.imap\" if unexpected.")
}
```  

# Match intervals for comparing EK60 and EK80 data (optional)

```{r match-ping-intervals}
# Reduce intervals to matching values
if (match.intervals) {
  # Load interval key
  load(here("Output/int_key.Rdata"))
  
  # Filter NASC
  nasc <- nasc %>%
    mutate(key = paste(transect.name, date, time)) %>% 
    filter(key %in% int_key)
}
```  

# Calculate abundance and biomass estimates - Core Region  
For each species, point and bootstrap estimates of abundance and biomass are estimated.

## Calculate biomass - Point estimates
First, point estimates of biomass are estimated for each species and sampling stratum.  

Point estimates of biomass (tons, t) for each CPS species by sampling stratum and for the entire survey (Stratum = All). Stratum areas are nmi^2^.

### Primary strata

```{r biomass-point-estimates}
# Save final nasc data frame used for point and bootstrap estimates
save(nasc, file = here("Output/nasc_final.Rdata"))
write_csv(nasc, file = here("Output/nasc_final.csv"))

# Calculate point estimates for each species
for (i in unique(strata.final$scientificName)) {
  # Subset strata for species i
  strata.temp <- filter(strata.final, scientificName == i) %>% 
    select(transect, stratum)
  
  # Add stratum numbers to nasc
  nasc.temp <- nasc %>%
    left_join(strata.temp) %>% 
    filter(!is.na(stratum))
  
  # Summarise nasc by stratum
  nasc.temp.summ <- nasc.temp %>% 
    group_by(stratum) %>% 
    summarise(
      n_samples = n(),
      mean_nasc = mean(cps.nasc)) %>% 
    mutate(scientificName = i) %>% 
    select(scientificName, everything())
  
  # Combine nasc summaries
  if (exists("nasc.summ.strata")) {
    nasc.summ.strata <- bind_rows(nasc.summ.strata, 
                                  nasc.temp.summ)
  } else {
    nasc.summ.strata <- nasc.temp.summ
  }
  
  # Create data frame with stratum and area (m^2)  
  stratum.info <- strata.primary %>%
    filter(scientificName == i) %>%
    select(stratum, area) %>%
    mutate(area = as.numeric(area)) %>%
    st_set_geometry(NULL) 
  
  stratum.info.nse <- strata.nse %>% 
    filter(scientificName == i) %>% 
    select(stratum, area) %>%
    mutate(area = as.numeric(area)) %>% 
    st_set_geometry(NULL) 
  
  # Get nearshore nasc data
  nasc.nse <- estimate_inshore(nasc.temp, bathy_5m_df) %>% 
    mutate(scientificName = i,
           key            = paste(transect, int)) %>% 
    filter(stratum %in% stratum.info.nse$stratum)
  
  if (exists("nasc.nse.final")) {
    nasc.nse.final <- bind_rows(nasc.nse.final, nasc.nse)
  } else {
    nasc.nse.final <- nasc.nse
  }
  
  # Compute point estimates
  # Currently has na.rm = TRUE for calculating biomass
  if (exists("point.estimates")) {
    point.estimates <- bind_rows(point.estimates,
                                 data.frame(scientificName = i,
                                            estimate_point(nasc.temp, stratum.info, species = i)))
  } else {
    point.estimates <- data.frame(scientificName = i,
                                  estimate_point(nasc.temp, stratum.info, species = i))
  }
  
  if (exists("point.estimates.nse")) {
    point.estimates.nse <- bind_rows(point.estimates.nse,
                                     data.frame(scientificName = i,
                                                estimate_point(nasc.nse, stratum.info.nse, species = i)))
  } else {
    point.estimates.nse <- data.frame(scientificName = i,
                                      estimate_point(nasc.nse, stratum.info.nse, species = i))
  }
}

# Save results
save(point.estimates, 
     file = here("Output/biomass_point_estimates.Rdata")) 

save(point.estimates.nse, 
     file = here("Output/biomass_point_estimates_nse.Rdata"))

# Save strata nasc summaries to CSV
write_csv(nasc.summ.strata, here("Output/nasc_strata_summary.csv"))

# Add stock designations to point estimates
point.estimates     <- left_join(point.estimates, strata.summ.primary)
point.estimates.nse <- left_join(point.estimates.nse, strata.summ.nse)

# Summarize point estimates (by stocks)
pe <- point.estimates %>%
  group_by(scientificName, stock) %>%
  summarise(
    area          = sum(area),
    biomass.total = sum(biomass.total)) %>%
  bind_rows(point.estimates) %>%
  mutate(area = area * 2.915533e-07) %>%
  arrange(scientificName, stock, stratum) %>%
  mutate(stratum = case_when(
    is.na(stratum) ~ "All",
    TRUE ~  as.character(stratum))) %>% 
  select(scientificName, stock, stratum, area, biomass.total) %>%
  rename(
    Species            = scientificName,
    Stock              = stock,
    Stratum            = stratum,
    Area               = area,
    biomass.mean.point = biomass.total)

# Save point estimates
save(pe, file = here("Output/biomass_point_estimates_final.Rdata"))
write_csv(pe, here("Output/biomass_point_estimates_final.csv"))

# Get rows with estimates from all strata
pe.stratum.all <- which(pe$Stratum == "All")

# Format point estimates table
pe %>% 
  rename(Biomass = biomass.mean.point) %>% 
  kable(format = knitr.format,booktabs = TRUE, escape = FALSE,
        align = c("l","c","r","r","r"),
        digits = c(0),
        format.args = list(big.mark = ",")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"),full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>% 
  row_spec(0, align = c("c")) %>%
  collapse_rows(columns = c(1))

save(nasc.nse.final, file = here("Output/nasc_nse_final.Rdata"))
```

### Nearshore extrapolation

```{r biomass-point-estimates-inshore}
# Summarize point estimates (by stocks)
pe.nse <- point.estimates.nse %>%
  group_by(scientificName, stock) %>%
  summarise(
    area    = sum(area),
    biomass.total = sum(biomass.total)) %>%
  bind_rows(point.estimates.nse) %>%
  mutate(area = area * 2.915533e-07) %>%
  arrange(scientificName, stock, stratum) %>%
  mutate(stratum = case_when(
    is.na(stratum) ~ "All",
    TRUE ~  as.character(stratum))) %>% 
  select(scientificName, stock, stratum, area, biomass.total) %>%
  rename(
    Species            = scientificName,
    Stock              = stock,
    Stratum            = stratum,
    Area               = area,
    biomass.mean.point = biomass.total)

# Save point estimates
save(pe.nse, file = here("Output/biomass_point_estimates_nse_final.Rdata"))
write_csv(pe.nse, here("Output/biomass_point_estimates_nse_final.csv"))

# Format point estimates table
pe.nse %>%
  rename(Biomass = biomass.mean.point) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("l","c","r","r","r"),
        digits = c(0),
        format.args = list(big.mark = ",")) %>% 
  kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>% 
  row_spec(0, align = c("c")) %>%
  # row_spec(pe.stratum.all, bold = TRUE, color = c("#000000"),background = "#8B8C94") %>%
  collapse_rows(columns = c(1))
```

## Calculate biomass - Bootstrap estimates  
Next, mean biomass (tons, t), lower and upper confidence intervals, and CV is estimated for each species and stratum using non-parametric bootstrap sampling with replacement (n = `r boot.num` bootstrap samples).  

### Primary strata  

```{r biomass-bootstrap-estimates, include=FALSE}
# Generate multiple bootstrap biomass estimates
if (do.bootstrap) {
  # Create data frame for biomass estimates
  bootstrap.estimates <- data.frame()
  # Create data frame for abundance estimates by length
  abundance.estimates <- data.frame()
  # Create data frame for stratum summaries
  survey.summary <- data.frame()
  # Create data frame for catch summaries
  catch.summary <- data.frame()
  # Create data frame for stratum summaries
  stratum.summary <- data.frame()
  # Create data frame for comparing bootstrap estimates
  bootstrap.comp <- data.frame()
  
  # Configure progress bar
  pb1 <- tkProgressBar("R Progress Bar", 
                       "Multiple Bootstrap Estimation - Species", 0, 100, 0)
  spp.counter <- 1
  
  for (i in unique(strata.final$scientificName)) {
    # Get vector of lengths from clf.df column names
    L.cols  <- grep("L\\d",names(cluster.final[[i]]))
    L.vec   <- sort(as.numeric(str_extract(names(cluster.final[[i]][L.cols]),"\\d{1,2}")))
    
    # Create data frame with stratum and area (m^2)
    stratum.info <- strata.primary %>% 
      select(scientificName, stratum, area) %>%
      mutate(area = as.numeric(area)) %>% 
      st_set_geometry(NULL) 
    
    # Subset strata for species i
    strata.temp <- filter(strata.final, scientificName == i) %>% 
      select(transect, stratum) %>% 
      left_join(filter(strata.summ.primary, scientificName == i)) 
    
    # Add stratum numbers to nasc and remove transects outside of defined strata
    nasc.temp <- nasc %>%
      left_join(strata.temp) %>% 
      filter(!is.na(stratum))
    
    # Summarize nasc.temp to get strata to merge with pos.clusters below
    nasc.temp.summ <- nasc.temp %>% 
      group_by(stratum, cluster) %>% 
      summarise(n = n_distinct(cluster))
    
    # Summarize length data to get number of individuals
    lf.summ.cluster <- lf.final %>% 
      filter(scientificName == i) %>% 
      group_by(cluster) %>% 
      summarise(counts = sum(counts))
    
    # Summarize stratum clusters for all CPS
    stratum.cluster.cps <- nasc.temp %>% 
      group_by(cluster, stratum) %>% 
      summarise(nIntervals = n()) %>% 
      left_join(lf.summ.cluster)
    
    # Summarize positive clusters per species
    pos.cluster.spp <- pos.clusters %>%
      filter(cluster %in% nasc.temp$cluster & scientificName == i) %>% 
      inner_join(select(nasc.temp.summ,-n)) %>% 
      as.data.frame()
    
    # Summarize positive clusters per strata
    stratum.cluster.spp <- pos.cluster.spp %>% 
      group_by(scientificName, stratum) %>% 
      summarise(nClusters = n_distinct(cluster))
    
    # Summarize stratum statistics
    survey.summ.temp <- nasc.temp %>% 
      group_by(stratum, stock) %>% 
      summarise(
        nTransects     = n_distinct(transect),
        Distance       = length(Interval)*100/1852) %>% 
      mutate(Species = i) %>% 
      left_join(stratum.cluster.spp) %>% 
      rename(Stratum = stratum)
    
    # Summarize catch statistics by stratum
    catch.summ.temp <- n.summ.haul %>% 
      left_join(select(stratum.cluster.cps, cluster, stratum)) %>% 
      filter(scientificName == i, !is.na(stratum)) %>%
      group_by(scientificName, stratum) %>% 
      summarise(nIndiv = sum(num))
    
    # Configure progress bar
    pb2 <- tkProgressBar("R Progress Bar", "Multiple Bootstrap Estimation - Stratum", 0, 100, 0)
    # Initialize species counter
    stratum.counter <- 1
    # Estimate biomass for each stratum
    for (j in unique(nasc.temp$stratum)) {
      # Extract stratum area
      stratum.area <- stratum.info$area[stratum.info$scientificName == i & 
                                          stratum.info$stratum == j]
      # Calculate biomass using bootstrap function ----
      set.seed(1) # Set seed for repeatable results
      boot.df <- estimate_bootstrap(nasc.temp, cluster.final[[i]], j, 
                                    stratum.area = stratum.area, 
                                    species = i, do.lf = do.lf, 
                                    boot.number = boot.num)$data.frame
      
      # Extract biomass estimates; remove first (point) estimate
      boot.temp <- data.frame(Species = i, Stratum = j, Area = stratum.area,
                              Sample = seq(1,boot.num), boot.df[2:nrow(boot.df), ])
      # Combine results
      bootstrap.estimates <- bind_rows(bootstrap.estimates, boot.temp)
      
      # Calculate abundance by length class using bootstrap function ----
      abund.vec <- estimate_bootstrap(nasc.temp, cluster.final[[i]], j, 
                                      stratum.area = stratum.area, 
                                      species = i, do.lf = do.lf, 
                                      boot.number = 0)$abundance.vector
      # Extract abundance estimates
      abundance.temp <- data.frame(Species = i, Stratum = j,
                                   SL = L.vec, freq = abund.vec)
      # Combine results
      abundance.estimates <- bind_rows(abundance.estimates, abundance.temp)
      
      # Calculate abundance and biomass all ways ----
      boot.comp.temp <- estimate_bootstrap(nasc.temp, cluster.final[[i]], j, 
                                           stratum.area = stratum.area, 
                                           species = i, do.lf = do.lf, 
                                           boot.number = 0)$data.frame
      
      # Extract abundance estimates
      boot.comp <- data.frame(Species = i, Stratum = j, 
                              select(boot.comp.temp, abundance, everything()))
      
      bootstrap.comp <- bind_rows(bootstrap.comp, boot.comp) %>% 
        arrange(Species, Stratum)
      
      # Update the progress bar
      pb.prog2 <- round(stratum.counter/n_distinct(nasc.temp$stratum)*100)
      info2 <- sprintf("%d%% done", pb.prog2)
      setTkProgressBar(pb2, pb.prog2, sprintf("Bootstrap - Stratum (%s)", info2), info2)
      # Update stratum counter
      stratum.counter <- stratum.counter + 1      
    }
    # Close the stratum counter
    close(pb2)
    # Update the progress bar
    pb.prog1 <- round(spp.counter/length(bootstrap.est.spp)*100)
    info1    <- sprintf("%d%% done", pb.prog1)
    setTkProgressBar(pb1, pb.prog1, sprintf("Bootstrap - Species (%s)", info1), info1)
    
    # Update the species counter
    spp.counter     <- spp.counter + 1
    
    # Combine survey summary by species
    survey.summary  <- bind_rows(survey.summary, survey.summ.temp)
    # Combine survey summary by species
    catch.summary   <- bind_rows(catch.summary, catch.summ.temp)
    # Combine stratum summary
    stratum.summary <- bind_rows(stratum.summary, pos.cluster.spp)
  }
  # Close the species counter
  close(pb1)
  
  
  # Save bootstrap results
  save(bootstrap.estimates, abundance.estimates, survey.summary, 
       catch.summary, stratum.summary, bootstrap.comp,
       file = (here("Output/biomass_bootstrap_est.Rdata")))
  
  # Write bootstrap comparison to CSV
  write_csv(bootstrap.comp, here("Output/bootstrap_comparison.csv"))
} else{
  # Save bootstrap results
  load(here("Output/biomass_bootstrap_est.Rdata"))
}

# Rename scientificName column
catch.summary <- catch.summary %>% 
  left_join(strata.summ.primary) %>%
  rename(Stock = stock)

# Summarise abundance across strata
abund.summ <- abundance.estimates %>%
  left_join(strata.summ.primary, by = c("Species" = "scientificName",
                                        "Stratum" = "stratum")) %>%
  group_by(Species,Stock = stock,SL) %>% 
  summarise(abundance = sum(freq)) %>% 
  mutate(TL = SL)  

# Calculate estimated biomass from from TL and estimated.wg
# CURRENTLY USING ESTIMATED.WG ESTIMATED FROM TOTAL LENGTH
# MUST UPDATE TO USE ESTIMATED.WG FROM STANDARD LENGTH
abund.summ <- abund.summ %>% 
  mutate(estimated.wg = estimate_ts(Species, TL, units = "cm")$estimated.wg,
         biomass = abundance * estimated.wg)

# Add stock designations to bootstrap estimates
bootstrap.estimates <- bootstrap.estimates %>% 
  left_join(strata.summ.primary, by = c("Species" = "scientificName",
                                        "Stratum" = "stratum")) %>% 
  rename(Stock = stock)

# Summarize results from bootstrap per species and stratum
be.stratum <- bootstrap.estimates %>% 
  group_by(Species, Stock, Stratum) %>% 
  summarise(
    n.samples         = n(),
    Area              = Area[1]*2.915533e-07, # Convert m^2 to nmi^2
    biomass.mean.boot = mean(biomass)*10^3,
    biomass.sd        = sd(biomass)*10^3,
    biomass.se        = biomass.sd/sqrt(n.samples),
    abund.mean.boot   = mean(abundance),
    abund.sd          = sd(abundance),
    abund.se          = abund.sd/sqrt(n.samples),
    lower.ci.B        = quantile(biomass,probs = 0.025)*10^3,
    upper.ci.B        = quantile(biomass,probs = 0.975)*10^3) %>% 
  mutate(pct.tot.B    = biomass.mean.boot/sum(biomass.mean.boot)*100) %>%
  left_join(survey.summary, by = c("Species","Stratum")) %>%
  left_join(catch.summary,  by = c("Species" = "scientificName",
                                   "Stratum" = "stratum", "Stock")) %>% 
  arrange(Species, Stratum) %>%
  select(
    Species, Stock, Stratum, Area, nTransects, Distance, nClusters, nIndiv, 
    biomass.mean.boot, lower.ci.B, upper.ci.B, biomass.sd, pct.tot.B)

# Save results
save(be.stratum, 
     file = here("Output/biomass_bootstrap_estimates_stratum.Rdata"))

# Add stock designations to stratum summary
stratum.summary <- stratum.summary %>% 
  left_join(strata.summ.primary) %>% 
  rename(Stock = stock)

# Summarize clusters for each species for entire survey
cluster.summary.total <- stratum.summary %>%
  group_by(scientificName, Stock) %>% 
  summarise(nClusters = n_distinct(cluster)) %>% 
  rename(Species = scientificName)

# Summarize sampling for entire survey
survey.summary.total <- survey.summary %>% 
  group_by(Species, Stock = stock) %>% 
  summarise(
    Strata     = n(),
    nTransects = sum(nTransects),
    Distance   = sum(Distance)) %>% 
  left_join(cluster.summary.total)

# Summarise catch for entire survey
catch.summary.total <- catch.summary %>% 
  group_by(Species = scientificName,Stock) %>% 
  summarise(nIndiv = sum(nIndiv))

# Summarize results from bootstrap per species across all samples
be.sample <- bootstrap.estimates %>% 
  group_by(Species, Stock, Sample) %>% 
  summarise(area    = sum(Area)*2.915533e-07,
            biomass = sum(biomass))

# Summarize results from bootstrap per species across all strata
be.survey <- be.sample %>%
  group_by(Species, Stock) %>%
  summarise(
    Area = area[1],
    biomass.mean.boot = mean(biomass) * 10^3,
    biomass.sd = sd(biomass) * 10^3,
    lower.ci.B = quantile(biomass, probs = 0.025) * 10^3,
    upper.ci.B = quantile(biomass, probs = 0.975) * 10^3) %>%
  left_join(survey.summary.total) %>%
  left_join(catch.summary.total) %>%
  arrange(Species) %>%
  select(
    Species, Stock, Area, nTransects, Distance, nClusters, nIndiv, 
    biomass.mean.boot, lower.ci.B, upper.ci.B, biomass.sd
  )

# Save results
write.csv(be.survey, 
          file  = here("Output/biomass_bootstrap_estimates_survey.csv"),
          quote = FALSE,row.names = FALSE)

save(be.survey, file = here("Output/biomass_bootstrap_estimates_survey.Rdata"))
```  

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for all CPS by stratum and within the entire survey area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `r nrow(nasc)` acoustic intervals were included in this analysis.  

```{r biomass-bootstrap-estimates-final}
# Combine stratum and survey estimates
be <- be.stratum %>% 
  bind_rows(be.survey) %>% 
  arrange(Species, Stock, Stratum) %>% 
  replace_na(list(pct.tot.B = 100)) %>% 
  mutate(Stratum = case_when(
    is.na(Stratum) ~ "All",
    TRUE ~  as.character(Stratum))) %>% 
  left_join(select(pe, -Area)) %>%
  rename(Biomass = biomass.mean.point) %>% 
  mutate(biomass.cv = (biomass.sd / Biomass)*100) %>% 
  select(Species, Stock, Stratum, Area, nTransects, Distance, nClusters, nIndiv,
         Biomass, lower.ci.B, upper.ci.B, biomass.sd, biomass.cv)

# Save results
write.csv(be,
          file = here("Output/biomass_bootstrap_estimates_final.csv"),
          quote = FALSE, row.names = FALSE)
save(be,  file = here("Output/biomass_bootstrap_estimates_final.Rdata"))

# Create data frame for database export
be.db.export <- be %>% 
  mutate(region = "Core")

# Get rows with estimates from all strata
be.stratum.all <- which(be$Stratum == "All")

# Print bootstrap estimate table
be %>% 
  rename(Number               = Stratum,
         Transects            = nTransects,
         Clusters             = nClusters,
         Individuals          = nIndiv,
         "Point estimate"     = Biomass,
         SD                   = biomass.sd,
         CV                   = biomass.cv,
         "Lower CI$_{95\\%}$" = lower.ci.B,
         "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("l","c",rep("r",ncol(be) - 2)),
        digits = c(0),
        format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>%
  row_spec(0, align = c("c")) %>%
  # row_spec(be.stratum.all, bold = TRUE, color = "black", background = "#c1c2cc") %>% 
  collapse_rows(columns = c(1:2)) %>%
  add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
```

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for each CPS stock within the entire survey area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `r nrow(nasc)` acoustic intervals were included in this analysis.  

```{r biomass-bootstrap-estimates-totals-only}
# Print bootstrap estimate table
be %>% 
  filter(Stratum == "All") %>% 
  rename(Number               = Stratum,
         Transects            = nTransects,
         Clusters             = nClusters,
         Individuals          = nIndiv,
         "Point estimate"     = Biomass,
         SD                   = biomass.sd,
         CV                   = biomass.cv,
         "Lower CI$_{95\\%}$" = lower.ci.B,
         "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
  kable(format = knitr.format, booktabs = TRUE,escape = FALSE,
        align = c("l","c",rep("r",ncol(be) - 2)),
        digits = c(0),
        format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"),full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>%
  row_spec(0, align = c("c")) %>%
  collapse_rows(columns = c(1)) %>%
  add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
``` 

```{r biomass-bootstrap-histograms-stratum}
# Bootstrap estimates of biomass by species and stratum
biomass.histogram.stratum <- ggplot(bootstrap.estimates, 
                                    aes(biomass*1e3, group = factor(Stratum), 
                                        fill = factor(Stratum))) + 
  geom_histogram(position = 'identity', alpha = 0.75) + 
  facet_wrap(~Species, scales = 'free_x') + 
  ylab("Count") + xlab(expression(Biomass~(t))) +
  scale_fill_discrete("Stratum") +
  scale_y_continuous(expand = c(0,0)) +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "italic"))

# Save plot
ggsave(biomass.histogram.stratum, 
       filename = here("Figs/fig_biomass_histogram_stratum.png"),
       height = 8, width = 14)

include_graphics(here("Figs/fig_biomass_histogram_stratum.png"))
```  

Distribution of biomass estimates (t; n = `r boot.num` bootstrap samples) by species and stratum (**Note: differences in x-axis limits**).  

```{r biomass-bootstrap-estimates-survey}
# Bootstrap estimates of biomass by species
biomass.histogram.survey <- ggplot(be.sample, aes(biomass*1e3, fill = Stock)) + 
  geom_histogram(alpha = 0.75) + 
  facet_wrap(Species ~ Stock, scales = "free") + 
  geom_vline(data = filter(pe, Stratum == "All"), aes(xintercept = biomass.mean.point)) +
  geom_vline(data = be.survey, aes(xintercept = lower.ci.B), linetype = 'dashed') +
  geom_vline(data = be.survey, aes(xintercept = upper.ci.B), linetype = 'dashed') +
  scale_y_continuous(expand = c(0,0)) +
  scale_fill_manual(values = c(All = "gray50", Central = "orange", 
                               Northern = "navyblue", Southern = "firebrick")) +
  ylab("Count") + xlab(expression(Biomass~(t))) +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x       = element_text(face = "bold.italic"))

# Save figure
ggsave(biomass.histogram.survey,
       filename = here("Figs/fig_biomass_histogram_survey.png"),
       height = 8, width = 14)

include_graphics(here("Figs/fig_biomass_histogram_survey.png"))
```  

Distribution of biomass estimates (t; n = `r boot.num` bootstrap samples) by species throughout the entire survey area, the mean (solid vertical line), and 95% confidence intervals (dashed vertical lines) (**Note: differences in x- and y-axis limits**).

```{r biomass-bootstrap-estimates-nse, include=FALSE}
# Generate multiple bootstrap biomass estimates
if (do.bootstrap) {
  # Create data frame for biomass estimates
  bootstrap.estimates.nse <- data.frame()
  # Create data frame for abundance estimates by length
  abundance.estimates.nse <- data.frame()
  # Create data frame for stratum summaries
  survey.summary.nse <- data.frame()
  # Create data frame for catch summaries
  catch.summary.nse <- data.frame()
  # Create data frame for stratum summaries
  stratum.summary.nse <- data.frame()
  # Configure progress bar
  pb1 <- tkProgressBar("R Progress Bar", 
                       "Multiple Bootstrap Estimation (Nearshore) - Species", 0, 100, 0)
  spp.counter <- 1
  
  for (i in unique(strata.nse$scientificName)) {
    # Get vector of lengths from clf.df column names
    L.cols  <- grep("L\\d", names(cluster.final[[i]]))
    L.vec   <- sort(as.numeric(str_extract(names(cluster.final[[i]][L.cols]),"\\d{1,2}")))
    
    # Create data frame with stratum and area (m^2)
    stratum.info.nse <- strata.nse %>% 
      filter(scientificName == i) %>% 
      select(stratum, area) %>%
      mutate(area = as.numeric(area)) %>% 
      st_set_geometry(NULL)
    
    # Subset strata for species i
    strata.temp <- filter(strata.final, scientificName == i) %>% 
      select(transect, stratum) %>% 
      left_join(filter(strata.summ.nse, scientificName == i)) %>% 
      filter(!is.na(area))
    
    # Add stratum numbers to nasc and remove transects outside of defined strata
    nasc.temp <- nasc %>%
      left_join(strata.temp) %>% 
      filter(!is.na(stratum))
    
    # Get nearshore nasc data
    nasc.nse <- estimate_inshore(nasc.temp, bathy_5m_df) 
    
    # Summarize nasc.temp to get strata to merge with pos.clusters below
    nasc.temp.summ <- nasc.nse %>% 
      group_by(stratum, cluster) %>% 
      summarise(n = n_distinct(cluster))
    
    # Summarize length data to get number of individuals
    lf.summ.cluster <- lf.final %>% 
      filter(scientificName == i) %>% 
      group_by(cluster) %>% 
      summarise(counts = sum(counts))
    
    # Summarize stratum clusters for all CPS
    stratum.cluster.cps <- nasc.nse %>% 
      group_by(cluster, stratum) %>% 
      summarise(nIntervals = n()) %>% 
      left_join(lf.summ.cluster)
    
    # Summarize positive clusters per species
    pos.cluster.spp <- pos.clusters %>%
      filter(cluster %in% nasc.temp$cluster & scientificName == i) %>% 
      inner_join(select(nasc.temp.summ,-n)) %>% 
      as.data.frame()
    
    # Summarize positive clusters per strata
    stratum.cluster.spp <- pos.cluster.spp %>% 
      group_by(scientificName, stratum) %>% 
      summarise(nClusters = n_distinct(cluster))
    
    # Summarize stratum statistics
    survey.summ.temp <- nasc.nse %>% 
      group_by(stratum, stock) %>% 
      summarise(
        nTransects     = n_distinct(transect),
        Distance       = length(Interval)*100/1852) %>% 
      mutate(Species = i) %>% 
      left_join(stratum.cluster.spp) %>% 
      rename(Stratum = stratum)
    
    # Summarize catch statistics by stratum
    catch.summ.temp <- n.summ.haul %>% 
      left_join(select(stratum.cluster.cps, cluster, stratum)) %>% 
      filter(scientificName == i, !is.na(stratum)) %>%
      group_by(scientificName, stratum) %>% 
      summarise(nIndiv = sum(num)) %>% 
      as.data.frame()
    
    # Configure progress bar
    pb2 <- tkProgressBar("R Progress Bar", "Multiple Bootstrap Estimation - Stratum", 0, 100, 0)
    # Initialize species counter
    stratum.counter <- 1
    # Estimate biomass for each stratum
    for (j in unique(nasc.nse$stratum)) {
      # Extract stratum area
      stratum.area <- as.numeric(strata.nse$area[strata.nse$scientificName == i & 
                                                   strata.nse$stratum == j])
      # Calculate biomass using bootstrap function ----
      set.seed(1) # Set seed for repeatable results
      boot.df <- estimate_bootstrap(nasc.nse, cluster.final[[i]], j, 
                                    stratum.area = stratum.area, 
                                    species = i, do.lf = do.lf, 
                                    boot.number = boot.num)$data.frame
      # Extract biomass estimates; remove first (point) estimate
      boot.temp <- data.frame(Species = i, Stratum = j, Area = stratum.area,
                              Sample = seq(1,boot.num), boot.df[2:nrow(boot.df), ])
      # Combine results
      bootstrap.estimates.nse <- bind_rows(bootstrap.estimates.nse, boot.temp)
      
      # Calculate abundance by length class using bootstrap function ----
      abund.vec <- estimate_bootstrap(nasc.nse, cluster.final[[i]], j, 
                                      stratum.area = stratum.area, 
                                      species = i, do.lf = do.lf, 
                                      boot.number = 0)$abundance.vector
      # Extract abundance estimates
      abundance.temp <- data.frame(Species = i, Stratum = j,
                                   SL = L.vec, freq = abund.vec)
      # Combine results
      abundance.estimates.nse <- bind_rows(abundance.estimates.nse, abundance.temp)
      
      # Update the progress bar
      pb.prog2 <- round(stratum.counter/n_distinct(nasc.nse$stratum)*100)
      info2 <- sprintf("%d%% done", pb.prog2)
      setTkProgressBar(pb2, pb.prog2, sprintf("Bootstrap - Stratum (%s)", info2), info2)
      
      # Update stratum counter
      stratum.counter <- stratum.counter + 1      
    }
    
    # Close the stratum counter
    close(pb2)
    
    # Update the progress bar
    pb.prog1 <- round(spp.counter/length(bootstrap.est.spp)*100)
    info1    <- sprintf("%d%% done", pb.prog1)
    setTkProgressBar(pb1, pb.prog1, sprintf("Bootstrap - Species (%s)", info1), info1)
    
    # Update the species counter
    spp.counter     <- spp.counter + 1
    # Combine survey summary by species
    survey.summary.nse  <- bind_rows(survey.summary.nse, survey.summ.temp)
    # Combine survey summary by species
    catch.summary.nse   <- bind_rows(catch.summary.nse, catch.summ.temp)
    # Combine stratum summary
    stratum.summary.nse <- bind_rows(stratum.summary.nse, pos.cluster.spp)
  }
  
  # Close the species counter
  close(pb1)
  
  # # Replace NaNs in abundance summaries with zeros
  # abundance.estimates.nse[atm:::is.nan.df(abundance.estimates.nse)] <- 0
  # abundance.estimates.nse[is.nan(abundance.estimates.nse)] <- 0
  
  # Save bootstrap results
  save(bootstrap.estimates.nse, abundance.estimates.nse, survey.summary.nse, 
       catch.summary.nse, stratum.summary.nse,
       file = (here("Output/biomass_bootstrap_est_nearshore.Rdata")))
} else{
  # Save bootstrap results
  load(here("Output/biomass_bootstrap_est_nearshore.Rdata"))
}

# Rename scientificName column
catch.summary.nse <- catch.summary.nse %>% 
  left_join(strata.summ.nse) %>%
  rename(Stock = stock)

# Summarise abundance across strata
abund.summ.nse <- abundance.estimates.nse %>%
  left_join(strata.summ.nse, by = c("Species" = "scientificName",
                                    "Stratum" = "stratum")) %>%
  group_by(Species, Stock = stock, SL) %>% 
  summarise(abundance = sum(freq)) %>% 
  mutate(TL = SL)  

# Calculate estimated biomass from from TL and estimated.wg --------------------
# CURRENTLY USING ESTIMATED.WG ESTIMATED FROM TOTAL LENGTH
# MUST UPDATE TO USE ESTIMATED.WG FROM STANDARD LENGTH
abund.summ.nse <- abund.summ.nse %>% 
  mutate(estimated.wg = estimate_ts(Species, TL, units = "cm")$estimated.wg,
         biomass      = abundance * estimated.wg)

# Add stock designations to bootstrap estimates
bootstrap.estimates.nse <- bootstrap.estimates.nse %>% 
  left_join(strata.summ.nse, by = c("Species" = "scientificName",
                                    "Stratum" = "stratum")) %>% 
  rename(Stock = stock)

# Summarize results from bootstrap per species and stratum
be.stratum.nse <- bootstrap.estimates.nse %>% 
  group_by(Species, Stock, Stratum) %>% 
  summarise(
    n.samples         = n(),
    Area              = Area[1]*2.915533e-07, # Convert m^2 to nmi^2
    biomass.mean.boot = mean(biomass)*10^3,
    biomass.sd        = sd(biomass)*10^3,
    biomass.se        = biomass.sd/sqrt(n.samples),
    abund.mean.boot   = mean(abundance),
    abund.sd          = sd(abundance),
    abund.se          = abund.sd/sqrt(n.samples),
    lower.ci.B        = quantile(biomass,probs = 0.025)*10^3,
    upper.ci.B        = quantile(biomass,probs = 0.975)*10^3) %>% 
  mutate(pct.tot.B    = biomass.mean.boot/sum(biomass.mean.boot)*100) %>%
  left_join(survey.summary.nse, by = c("Species","Stratum")) %>%
  left_join(catch.summary.nse,  by = c("Species" = "scientificName",
                                       "Stratum" = "stratum", "Stock")) %>% 
  arrange(Species, Stratum) %>%
  select(
    Species, Stock, Stratum, Area, nTransects, Distance, nClusters, nIndiv, 
    biomass.mean.boot, lower.ci.B, upper.ci.B, biomass.sd, pct.tot.B)

# Save results
save(be.stratum.nse, 
     file = here("Output/biomass_bootstrap_estimates_stratum_nearshore.Rdata"))

# Add stock designations to stratum summary
stratum.summary.nse <- stratum.summary.nse %>% 
  left_join(strata.summ.nse) %>% 
  rename(Stock = stock)

# Summarize clusters for each species for entire survey
cluster.summary.total.nse <- stratum.summary.nse %>%
  group_by(scientificName, Stock) %>% 
  summarise(nClusters = n_distinct(cluster)) %>% 
  rename(Species = scientificName)

# Summarize sampling for entire survey
survey.summary.total.nse <- survey.summary.nse %>% 
  group_by(Species, Stock = stock) %>% 
  summarise(
    Strata     = n(),
    nTransects = sum(nTransects),
    Distance   = sum(Distance)) %>% 
  left_join(cluster.summary.total.nse)

# Summarise catch for entire survey
catch.summary.total.nse <- catch.summary.nse %>% 
  group_by(Species = scientificName, Stock) %>% 
  summarise(nIndiv = sum(nIndiv))

# Summarize results from bootstrap per species across all samples
be.sample.nse <- bootstrap.estimates.nse %>% 
  group_by(Species, Stock, Sample) %>% 
  summarise(area    = sum(Area)*2.915533e-07,
            biomass = sum(biomass))

# Summarize results from bootstrap per species across all strata
be.survey.nse <- be.sample.nse %>%
  group_by(Species, Stock) %>%
  summarise(
    Area = area[1],
    biomass.mean.boot = mean(biomass) * 10^3,
    biomass.sd = sd(biomass) * 10^3,
    lower.ci.B = quantile(biomass, probs = 0.025) * 10^3,
    upper.ci.B = quantile(biomass, probs = 0.975) * 10^3) %>%
  left_join(survey.summary.total.nse) %>%
  left_join(catch.summary.total.nse) %>%
  arrange(Species) %>%
  select(
    Species, Stock, Area, nTransects, Distance, nClusters, nIndiv, 
    biomass.mean.boot, lower.ci.B, upper.ci.B, biomass.sd
  )

# Save results
write.csv(be.survey.nse, 
          file  = here("Output/biomass_bootstrap_estimates_survey_nearshore.csv"),
          quote = FALSE,row.names = FALSE)

save(be.survey.nse, file = here("Output/biomass_bootstrap_estimates_survey_nearshore.Rdata"))
```

### Nearshore Extrapolation  

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for all CPS by stratum extrapolated to the unsampled nearshore area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `r nrow(nasc)` acoustic intervals were included in this analysis.

```{r biomass-bootstrap-estimates-final-nse}
# Combine stratum and survey estimates
be.nse <- be.stratum.nse %>% 
  bind_rows(be.survey.nse) %>% 
  arrange(Species, Stock, Stratum) %>% 
  replace_na(list(pct.tot.B = 100)) %>% # Replace NAs with "All"
  mutate(Stratum = case_when(
    is.na(Stratum) ~ "All",
    TRUE ~  as.character(Stratum))) %>% 
  left_join(select(pe.nse, -Area)) %>%
  rename(Biomass = biomass.mean.point) %>% 
  mutate(biomass.cv = (biomass.sd / Biomass)*100) %>% 
  select(Species, Stock, Stratum, Area, nTransects, Distance, nClusters, nIndiv,
         Biomass, lower.ci.B, upper.ci.B, biomass.sd, biomass.cv)

be.nse[atm:::is.nan.df(be.nse)] <- NA

# Save results
write.csv(be.nse,
          file = here("Output/biomass_bootstrap_estimates_final_nse.csv"),
          quote = FALSE, row.names = FALSE)

save(be.nse, 
     file = here("Output/biomass_bootstrap_estimates_final_nse.Rdata"))

# Get rows with estimates from all strata
be.stratum.all.nse <- which(be.nse$Stratum == "All")

# Print bootstrap estimate table
be.nse %>% 
  rename(Number               = Stratum,
         Transects            = nTransects,
         Clusters             = nClusters,
         Individuals          = nIndiv,
         "Point esimate"      = Biomass,
         SD                   = biomass.sd,
         CV                   = biomass.cv,
         "Lower CI$_{95\\%}$" = lower.ci.B,
         "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("l","c",rep("r",ncol(be.nse) - 2)),
        digits = c(0),
        format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>%
  row_spec(0, align = c("c")) %>%
  # row_spec(be.stratum.all, bold = TRUE, color = "black", background = "#c1c2cc") %>% 
  collapse_rows(columns = c(1:2)) %>%
  add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
```

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for each CPS stock within the entire survey area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `r nrow(nasc)` acoustic intervals were included in this analysis.  

```{r biomass-bootstrap-estimates-totals-only-nse}
# Print bootstrap estimate table
be.nse %>% 
  filter(Stratum == "All") %>% 
  rename(Number               = Stratum,
         Transects            = nTransects,
         Clusters             = nClusters,
         Individuals          = nIndiv,
         "Point estimate"     = Biomass,
         SD                   = biomass.sd,
         CV                   = biomass.cv,
         "Lower CI$_{95\\%}$" = lower.ci.B,
         "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
        align = c("l","c",rep("r",ncol(be.nse) - 2)),
        digits = c(0),
        format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
  column_spec(1, italic = TRUE) %>%
  row_spec(0, align = c("c")) %>%
  collapse_rows(columns = c(1)) %>%
  add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
``` 

(ref:biomass-bootstrap-histograms-stratum-nse) Distribution of biomass estimates (t; n = `r boot.num` bootstrap samples) by species and stratum (**Note: differences in x-axis limits**).

```{r biomass-bootstrap-histograms-stratum-nse,fig.cap='(ref:biomass-bootstrap-histograms-stratum-nse)'}
# Bootstrap estimates of biomass by species and stratum
biomass.histogram.stratum.nse <- 
  ggplot(bootstrap.estimates.nse, aes(biomass*1e3, group = factor(Stratum), fill = factor(Stratum))) + 
  geom_histogram(position = 'identity', alpha = 0.75) + facet_wrap(~Species, scales = 'free_x') + 
  ylab("Count") + xlab(expression(Biomass~(t))) +
  scale_fill_discrete("Stratum") +
  scale_y_continuous(expand = c(0,0)) +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "italic"))

# Save plot
ggsave(biomass.histogram.stratum.nse, filename = here("Figs/fig_biomass_histogram_stratum_nse.png"),
       height = 8, width = 14)

include_graphics(here("Figs/fig_biomass_histogram_stratum_nse.png"))
```  

(ref:biomass-bootstrap-estimates-survey-nse) Distribution of biomass estimates (t; n = `r boot.num` bootstrap samples) by species and stratum (**Note: differences in x-axis limits**).

```{r biomass-bootstrap-estimates-survey-nse,fig.cap='(ref:biomass-bootstrap-estimates-survey-nse)'}
# Bootstrap estimates of biomass by species
biomass.histogram.survey.nse <- ggplot(be.sample.nse, aes(biomass*1e3, fill = Stock)) + 
  geom_histogram(alpha = 0.75) + facet_wrap(Species ~ Stock, scales = "free") + 
  geom_vline(data = filter(pe.nse, Stratum == "All"),aes(xintercept = biomass.mean.point)) +
  geom_vline(data = be.survey.nse, aes(xintercept = lower.ci.B), linetype = 'dashed') +
  geom_vline(data = be.survey.nse, aes(xintercept = upper.ci.B), linetype = 'dashed') +
  scale_y_continuous(expand = c(0,0)) +
  scale_fill_manual(values = c(All = "gray50", Central = "orange", 
                               Northern = "navyblue", Southern = "firebrick")) +
  ylab("Count") + xlab(expression(Biomass~(t))) +
  theme_bw() +
  theme(strip.background.x = element_blank(),
        strip.text.x = element_text(face = "bold.italic"))

# Save figure
ggsave(biomass.histogram.survey.nse,
       filename = here("Figs/fig_biomass_histogram_survey_nse.png"),
       height = 8, width = 14)

include_graphics(here("Figs/fig_biomass_histogram_survey_nse.png"))
```

## Calculate biomass - Other estimates
### Offshore Region  

If desired, estimate biomass in the offshore region. 

```{r estimate-offshore-biomass}
if (estimate.os) {
  source(here("Code/estimateOffshore.R"))
}
```  

#### Point estimates

Point estimates of biomass (tons, t) for each CPS species and stock by sampling stratum and for the offshore survey area (Stratum = All). Stratum areas are nmi^2^.

```{r biomass-point-estimates-final-offshore}
if (exists("pe.os")) {
  # Print point estimate table
  pe.os %>%
    rename(Biomass = biomass.mean.point) %>% 
    kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
          align = c("l","c","r","r","r"),
          digits = c(0),
          format.args = list(big.mark = ",")) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>% 
    row_spec(0, align = c("c")) %>%
    collapse_rows(columns = c(1))
} else {
  print("No offshore point estimates")
}
```

#### Bootstrap estimates

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for all CPS in the offshore survey area, by stratum and within the entire area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `nrow(nasc.offshore)` acoustic intervals were included in this analysis.  

```{r biomass-bootstrap-estimates-os-final}
if (exists("be.os")) {
  # Print bootstrap estimate table
  be.os %>% 
    rename(Number               = Stratum,
           Transects            = nTransects,
           Clusters             = nClusters,
           Individuals          = nIndiv,
           "Point estimate"     = Biomass,
           SD                   = biomass.sd,
           CV                   = biomass.cv,
           "Lower CI$_{95\\%}$" = lower.ci.B,
           "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
    kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
          align = c("l","c",rep("r",ncol(be.os) - 2)),
          digits = c(0),
          format.args = list(big.mark = ",")) %>%
    kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>%
    row_spec(0, align = c("c")) %>%
    # row_spec(be.stratum.all, bold = TRUE, color = "black", background = "#c1c2cc") %>% 
    collapse_rows(columns = c(1:2)) %>%
    add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
} else {
  print("No offshore bootstrap estimates present.")
}
```

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for each CPS stock within the entire offshore survey area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `nrow(nasc.offshore)` acoustic intervals were included in this analysis.  

```{r biomass-bootstrap-estimates-os-totals-only}
if (exists("be.os")) {
  # Print bootstrap estimate table
  be.os %>% 
    filter(Stratum == "All") %>% 
    rename(Number               = Stratum,
           Transects            = nTransects,
           Clusters             = nClusters,
           Individuals          = nIndiv,
           "Point estimate"     = Biomass,
           SD                   = biomass.sd,
           CV                   = biomass.cv,
           "Lower CI$_{95\\%}$" = lower.ci.B,
           "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
    kable(format = knitr.format, booktabs = TRUE,escape = FALSE,
          align = c("l","c",rep("r",ncol(be.os) - 2)),
          digits = c(0),
          format.args = list(big.mark = ",")) %>%
    kable_styling(bootstrap_options = c("striped","hover","condensed"),full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>%
    row_spec(0, align = c("c")) %>%
    collapse_rows(columns = c(1)) %>%
    add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
} else {
  print("No offshore bootstrap estimates present.")
}
``` 

### Nearshore Region

If desired, estimate biomass in the nearshore region.

```{r estimate-nearshore-biomass}
if (estimate.ns) {
  source(here("Code/estimateNearshore.R"))
}
```

#### Point estimates

Point estimates of biomass (tons, t) for each CPS species and stock by sampling stratum and for the nearshore survey area (Stratum = All). Stratum areas are nmi^2^.

```{r biomass-point-estimates-final-nearshore}
if (exists("pe.ns")) {
  # Print point estimate table
  pe.ns %>%
    rename(Biomass = biomass.mean.point) %>% 
    kable(format = knitr.format, booktabs = TRUE, escape = FALSE,
          align = c("l","c","r","r","r"),
          digits = c(0),
          format.args = list(big.mark = ",")) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>% 
    row_spec(0, align = c("c")) %>%
    collapse_rows(columns = c(1))
} else {
  print("No nearshore point estimates")
}
```

#### Bootstrap estimates  

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for all CPS in the nearshore survey area, by stratum and within the entire area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `r nrow(nasc.nse)` acoustic intervals were included in this analysis. 

```{r biomass-bootstrap-estimates-ns-final}
if (exists("be.ns")) {
  # Print bootstrap estimate table
  be.ns %>% 
    rename(Number               = Stratum,
           Transects            = nTransects,
           Clusters             = nClusters,
           Individuals          = nIndiv,
           "Point esimate"      = Biomass,
           SD                   = biomass.sd,
           CV                   = biomass.cv,
           "Lower CI$_{95\\%}$" = lower.ci.B,
           "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
    kable(format = knitr.format, booktabs = TRUE,escape = FALSE,
          align = c("l","c",rep("r",ncol(be.ns) - 2)),
          digits = c(0),
          format.args = list(big.mark = ",")) %>%
    kable_styling(bootstrap_options = c("striped","hover","condensed"), full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>%
    row_spec(0, align = c("c")) %>%
    collapse_rows(columns = c(1:2)) %>%
    add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
} else {
  print("No nearshore bootstrap estimates")
}
```

Estimates of biomass (metric tons (t); mean, lower and upper 95% confidence intervals, CV, and percent of total biomass; n = `r boot.num` bootstrap samples) for each CPS stock within the entire nearshore survey area (Stratum = "All"). Stratum distances are in nmi, and stratum areas are nmi^2^. A total of `nrow(nasc.nse)` acoustic intervals were included in this analysis.  

```{r biomass-bootstrap-estimates-ns-totals-only}
if (exists("be.ns")) {
  # Print bootstrap estimate table
  be.ns %>% 
    filter(Stratum == "All") %>% 
    rename(Number               = Stratum,
           Transects            = nTransects,
           Clusters             = nClusters,
           Individuals          = nIndiv,
           "Point estimate"     = Biomass,
           SD                   = biomass.sd,
           CV                   = biomass.cv,
           "Lower CI$_{95\\%}$" = lower.ci.B,
           "Upper CI$_{95\\%}$" = upper.ci.B) %>% 
    kable(format = knitr.format, booktabs = TRUE,escape = FALSE,
          align = c("l","c",rep("r",ncol(be.ns) - 2)),
          digits = c(0),
          format.args = list(big.mark = ",")) %>%
    kable_styling(bootstrap_options = c("striped","hover","condensed"),full_width = FALSE) %>%
    column_spec(1, italic = TRUE) %>%
    row_spec(0, align = c("c")) %>%
    collapse_rows(columns = c(1)) %>%
    add_header_above(c(" " = 2, "Stratum" = 4, "Trawl" = 2, "Biomass" = 5))
} else {
  print("No nearshore bootstrap estimates present.")
}
``` 

## Combine sampling regions  

If combining data from multiple survey regions (e.g., the core and nearshore/offshore sampling regions), biomass density and length-disaggregated abundance data should be combined for presentation in the biomass report.  

```{r combine-regions}
if (combine.regions) {
  # Combine backscatter data
  nasc.combo <- nasc
  
  if ("Nearshore" %in% estimate.regions) {
    # Combine nasc from all core area vessels
    nasc.combo <- bind_rows(nasc.combo, nasc.nearshore)
  }
  
  if ("Offshore" %in% estimate.regions) {
    # Combine nasc from all core area vessels
    nasc.combo <- bind_rows(nasc.combo, nasc.offshore)
  }
  
  # Save combined nasc
  save(nasc.combo, file = here("Output/nasc_combo.Rdata"))
  
  # Average cps.nasc over defined interval
  # Summarize by file name, not transect, so that renamed (i.e., strip.tx.chars == TRUE) transects get included.
  nasc.plot.combo <- nasc.combo %>%
    select(filename, vessel.name, transect.name, transect, int, dist_m, datetime, lat, long, cps.nasc) %>% 
    group_by(filename, vessel.name, transect.name, transect, int) %>% 
    summarise(
      lat  = lat[1],
      long = long[1],
      NASC = mean(cps.nasc),
      label = paste0('Transect: ', transect[1], "; ",
                     'Distance: ', round(min(dist_m)), "-", round(max(dist_m)), ' m'),
      popup = paste0('<b>Transect: </b>', transect[1], '<br/>',
                     '<b>Time: </b>', min(datetime), " - ", max(datetime), ' UTC<br/>',
                     '<b>Distance: </b>', round(min(dist_m)), "-", round(max(dist_m)), ' m<br/>',
                     '<b>NASC: </b>', round(mean(NASC)), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>% 
    # Create bins for defining point size in NASC plots
    mutate(bin       = cut(NASC, nasc.breaks, include.lowest = TRUE),
           bin.level =  as.numeric(bin)) %>% 
    # st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    ungroup() %>% 
    project_df(to = crs.proj)
  
  if (save.figs) {
    source(here("Code/combineFigures.R"))
    source(here("Code/combineLengthDisaggAbund.R"))
    source(here("Code/plot_sA_CPS_combo.R"))
    source(here("Code/plot_acoustic_proportion_indiv_combo.R"))
    
    # Update backscatter plot with data from nearshore and/or offshore regions
    nasc.cufes.prop.plot      <- plot_grid(nasc.map.cps, cufes.density.all, acoustic.prop.cluster.combo.final,
                                           nrow = 1, labels = c("a)", "b)", "c)"))
    
    nasc.cufes.prop.plot.long <- plot_grid(nasc.map.cps, cufes.density.all, acoustic.prop.cluster.combo.final,
                                           ncol = 1, labels = c("a)", "b)", "c)"))
    
    # Save maps
    ggsave(nasc.cufes.prop.plot, 
           filename = here("Figs/fig_nasc_cufes_acoustic_cluster.png"),
           width = map.width*3, height = map.height)
    
    ggsave(nasc.cufes.prop.plot.long, 
           filename = here("Figs/fig_nasc_cufes_acoustic_cluster_long.png"),
           width = map.width, height = map.height*3) 
  }
}
```

```{r export-database}
# Format data for import to SQL server database
be.db.export <- be.db.export %>% 
  mutate(survey = survey.name) %>% 
  select(survey, region, species = Species, stock = Stock, stratum = Stratum, area = Area,
         nTransects, distance = Distance, nClusters, nIndiv, biomass = Biomass, 
         biomass_ci_lower = lower.ci.B, biomass_ci_upper = upper.ci.B,
         biomass_sd = biomass.sd, biomass_cv = biomass.cv) %>% 
  mutate(include_ts = case_when(
    region %in% estimate.regions ~ TRUE,
    TRUE ~ FALSE))

save(be.db.export, file = here("Output/biomass_timeseries_export.Rdata"))
write_csv(be.db.export, file = here("Output/biomass_timeseries_export.csv"))
```

## Estimation QA/QC

Compare biomass estimates from bootstrap function used to calculate length-disaggregated biomass and abundance estimates based on acoustic density by number and weight in the primary survey area. 

```{r bootstrap-comparisons}
# Import comparisons
bootstrap.comp <- read_csv(here("Output/bootstrap_comparison.csv")) %>% 
  mutate(pct_diff_biom = (biomass - biomass2)/biomass*100,
         pct_diff_abun = (abundance - abundance2)/abundance*100,
         label = paste(Species, Stratum, sep = "-"))

# Graphically compare biomass and abundance estimates from the bootstrap function
boot.biom.comp <- ggplot(bootstrap.comp, aes(biomass, biomass3)) +
  geom_point(size = 3, colour = "blue") +
  geom_point(data = bootstrap.comp, aes(biomass, biomass2),
             size = 3, colour = "red") +
  geom_text_repel(data = filter(bootstrap.comp, pct_diff_biom > 5), 
                  aes(biomass, biomass2, label = label),
                  colour = "black", size = 3, fontface = "italic") +
  geom_text_repel(data = filter(bootstrap.comp, pct_diff_biom > 10), 
                  aes(biomass, biomass2, label = label),
                  colour = "red", size = 4, fontface = "bold.italic") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  ylab("biomass") +
  coord_equal() +
  theme_bw()

boot.abun.comp <- ggplot(bootstrap.comp, aes(abundance, abundance2)) + 
  geom_point(size = 3) + 
  geom_text_repel(data = filter(bootstrap.comp, pct_diff_abun > 5), 
                  aes(abundance, abundance2, label = label),
                  colour = "black", size = 3, fontface = "italic") +
  geom_text_repel(data = filter(bootstrap.comp, pct_diff_biom > 10), 
                  aes(abundance, abundance2, label = label),
                  colour = "red", size = 4, fontface = "bold.italic") +
  geom_abline(slope = 1, intercept = 0, linetype = 'dashed') +
  coord_equal() + 
  theme_bw()

# Combine plots
bootstrap.comp.plot <- plot_grid(boot.biom.comp, boot.abun.comp, nrow = 1)

# Save plot
ggsave(bootstrap.comp.plot, filename = here("Figs/fig_bootrap_function_comparison.png"),
       height = 4, width = 8)

# Include plot
include_graphics(here("Figs/fig_bootrap_function_comparison.png"))
```

# Create final Figures and Tables  
The remaining figures and tables are meant to reproduce those presented in [@Zwolinski2017].  

Maps of biomass density by species and strata are equivalent to **Figure 2** in [@Zwolinski2017]. Maps for each species are saved in `Figs`; e.g.,  `fig_biomass_dens_Engraulis mordax.png`.  

Plots of standard-length distributions of each species per stratum and nighttime trawl cluster (panel labels), the number of individuals caught, and their percentage contribution to the density-weighted length distribution in the respective stratum are equivalent to **Figure 3** in [@Zwolinski2017].  

Plots of the estimated length-disaggregated abundance (upper panel) and biomass (lower panel) of each species in the survey area are equivalent to **Figure 4** in [@Zwolinski2017]. Labels above each panel indicates the stock (i.e., sub-population) from which the abundance and biomass come (e.g., northern or central sub-population of anchovy; those species with no sub-population division are labeled as "All"). **Importantly, biomass in this plot is estimated using the `estimate_ts` function, which calculates `estimated.wg` from TL; must update to use SL.**  

Tables of abundance versus standard length are equivalent to Table 2 in [@Zwolinski2017].  

```{r length-frequency-distributions}
# Summarise lengths by species and length bin
lf.summ <- lf.final %>% 
  group_by(scientificName, cluster, lf.labels) %>% 
  summarise(count = sum(counts)) %>% 
  # Compute relative frequency per cluster
  group_by(scientificName, cluster) %>% 
  mutate(count.sum = sum(count),
         freq = count/count.sum) %>% 
  ungroup() %>% 
  # Create facet labels
  mutate(
    cluster.name = as.factor(paste("Cluster", cluster)),
    cluster.name = fct_reorder(cluster.name, cluster))

# Save length frequency summary
save(lf.summ, file = here("Output/length_frequency_summary.Rdata"))

# Create labels for plot
abund.summ.total <- lf.summ %>% 
  group_by(scientificName, cluster, cluster.name) %>% 
  summarise(count = round(sum(count))) %>% 
  filter(count > 0) %>% 
  ungroup()

# Create list for storing lf plots
lf.summ.plots <- list()

# # Export data for Juan to reproduce figures and correct percent contributions
# save(lf.summ, abund.summ.total, strata.final, nasc, abundance.estimates,
#      file = here("Output/lf_data_for_juan.Rdata"))

# Plot relative length frequency for each species
for (i in unique(strata.final$scientificName)) {
  # Calculate total density per strata --------------------------------------------------------------------
  # Subset strata for species i
  strata.temp <- filter(strata.final, scientificName == i) %>% 
    select(transect, stratum)
  
  # Add stratum numbers to nasc
  nasc.temp <- nasc %>%
    left_join(strata.temp) %>% 
    filter(!is.na(stratum))
  
  # Calculate numeric abundance for each interval
  if (i == "Clupea pallasii") {
    nasc.temp <- nasc.temp %>% 
      mutate(num.abund = (cps.nasc*prop.her)/(4*pi*sigmaindiv.her))
  } else if (i == "Engraulis mordax") {
    nasc.temp <- nasc.temp %>% 
      mutate(num.abund = (cps.nasc*prop.anch)/(4*pi*sigmaindiv.anch))
  } else if (i == "Sardinops sagax") {
    nasc.temp <- nasc.temp %>% 
      mutate(num.abund = (cps.nasc*prop.sar)/(4*pi*sigmaindiv.sar))
  } else if (i == "Scomber japonicus") {
    nasc.temp <- nasc.temp %>% 
      mutate(num.abund = (cps.nasc*prop.mack)/(4*pi*sigmaindiv.mack))
  } else if (i == "Trachurus symmetricus") {
    nasc.temp <- nasc.temp %>% 
      mutate(num.abund = (cps.nasc*prop.jack)/(4*pi*sigmaindiv.jack))
  } else if (i == "Etrumeus acuminatus") {
    nasc.temp <- nasc.temp %>% 
      mutate(num.abund = (cps.nasc*prop.rher)/(4*pi*sigmaindiv.rher))
  }
  
  # % contribution per stratum is the sum(numeric density/interval)/sum(numeric density/stratum)
  #  Numeric density is (nasc * proportion) / (4*pi*sigma.indiv) 
  
  abund.summ.spp <- filter(abund.summ.total, scientificName == i)
  
  # Summarize numeric abundance by stratum
  num.abund.stratum <- nasc.temp %>% 
    group_by(stratum) %>% 
    summarise(num.stratum = sum(num.abund))
  
  # Summarize numeric abundance by cluster and overall
  pct.summ.cluster <- nasc.temp %>% 
    # Remove nasc with no
    filter(cluster %in% unique(abund.summ.spp$cluster)) %>%
    group_by(stratum, cluster) %>% 
    summarise(num.cluster = sum(num.abund)) %>% 
    left_join(num.abund.stratum) %>% 
    mutate(pct.abund.stratum = num.cluster/num.stratum*100,
           pct.txt      = paste0("(", stratum, ") ", round(pct.abund.stratum, 1),"%"),
           cluster.name = paste("Cluster", cluster)) %>%
    filter(pct.abund.stratum > 0) %>% 
    group_by(cluster, cluster.name) %>%
    summarise(pct = glue_collapse(unique(pct.txt), sep = ", ")) %>%
    ungroup() %>% 
    mutate(pct = str_replace(pct," 0%"," <0.1%"),
           cluster.name = fct_reorder(as.factor(cluster.name), cluster)) %>% 
    droplevels()
  
  # Summarize numeric abundance by cluster and overall
  pct.summ.all <- nasc.temp %>%
    filter(cluster %in% unique(abund.summ.spp$cluster)) %>%
    group_by(cluster) %>% 
    summarise(num.cluster = sum(num.abund)) %>% 
    mutate(pct = num.cluster/sum(num.abund.stratum$num.stratum)*100,
           pct.txt      = paste(round(pct, 1),"%", sep = ''),
           cluster.name = paste("Cluster", cluster)) %>%
    filter(pct > 0) %>% # Remove rows with no data
    ungroup() %>% 
    mutate(pct = str_replace(pct.txt," 0%"," <0.1%"),
           cluster.name = fct_reorder(as.factor(cluster.name), cluster)) %>% 
    droplevels()
  
  # Filter catch per species
  lf.cluster <- filter(lf.summ, scientificName == i &
                         cluster %in% pct.summ.cluster$cluster) %>% droplevels()
  
  catch.summ.cluster <- filter(abund.summ.total, scientificName == i &
                                 cluster %in% pct.summ.cluster$cluster) %>% droplevels()
  
  lf.summ.plot <- ggplot(lf.cluster, aes(lf.labels, freq)) +
    # Plot relative density by cluster and length class 
    geom_bar(stat = 'identity', fill = 'gray50', colour = 'gray20') + 
    scale_y_continuous(limits = c(0,1.1), expand = c(0,0)) +
    # Label with total number of individuals per cluster
    geom_shadowtext(data = catch.summ.cluster,
                    aes(1, 1.0, label = paste('Individuals:', count)),
                    size = annotation.size, hjust = 0, vjust = 0,
                    colour = "black", bg.colour = "white") +
    # Label with % contribution to weight distribution by stratum
    geom_shadowtext(data = pct.summ.cluster,
                    aes(1, 0.9, label = paste('Stratum:', pct)),
                    size = annotation.size, hjust = 0, vjust = 0,
                    colour = "black", bg.colour = "white") +
    # # Label with % contribution to weight distribution for all strata
    # geom_shadowtext(data = pct.summ.all,
    #           aes(1, 0.8, label = paste('All strata:', pct)),
    #           size = annotation.size, hjust = 0, vjust = 0,
    #           colour = "black", bg.colour = "white") +
    # Facet by cluster
    facet_wrap(~cluster.name, ncol = lf.ncols) + theme_bw() +
    xlab("Length (cm)") + ylab("Relative frequency") +
    theme(strip.background.x = element_blank(),
          strip.text.x       = element_text(face = "bold"))
  
  # Determine number of panels for setting aspect ratio
  # n.facets <- filter(lf.summ, scientificName == i) %>% 
  #   group_by(cluster) %>% 
  #   summarise(n = n()) %>% 
  #   nrow()/lf.ncols 
  
  n.facets <- filter(lf.summ, scientificName == i) %>%
    group_by(scientificName) %>%
    summarise(n_facets = n_distinct(cluster)/lf.ncols) %>%
    pull()
  
  # Set aspect ratio for saved figures
  if (round(n.facets)/lf.ncols > 0.5) {
    a.ratio <- round(n.facets)/lf.ncols  
  } else {
    a.ratio <- 0.5
  }
  
  
  # Save plot
  # ggsave(lf.summ.plot, 
  #        filename = paste0(here("Figs/fig_cluster_relative_length_frequency_"), i, ".png"),
  #        height = 10*a.ratio, width = 10) 
  
  ggsave(lf.summ.plot, 
         filename = paste0(here("Figs/fig_cluster_relative_length_frequency_"), i, ".png"),
         height = 11, width = 8) 
  
  # Add new plot to list
  lf.summ.plots[[i]] <- lf.summ.plot
}

# Save plots
save(lf.summ.plots, file = here("Output/relative_length_frequencies_all.Rdata"))

# Create blank plots for missing species
for (i in cps.spp) {
  if (is.null(lf.summ.plots[[i]])) {
    df <- data.frame()
    rel.lf.temp <- ggplot(df) + geom_point() + 
      xlim(0,10) + ylim(0,10) + 
      annotate('text', 5, 5, label = 'No Data', size = 6, fontface = 'bold') +
      theme_bw()  
    ggsave(rel.lf.temp, 
           filename = paste(here("Figs/fig_cluster_relative_length_frequency_"), 
                            i, ".png", sep = ""))
  }
}
```  

```{r l-disagg-plots}
# Create plots of length-disaggregated abundance and biomass
# Create list for storing plots
L.disagg.plots <- list()

# Plot length-disaggregated abundance and biomass by length class for each species
for (i in unique(abund.summ$Species)) {
  for (j in unique(abund.summ$Stock[abund.summ$Species == i])) {
    # Get y-axis limits for abundance and biomass plots
    y.max.abund   <- max(abund.summ$abundance[abund.summ$Species == i & abund.summ$Stock == j]) * 1.1
    y.max.biomass <- max(abund.summ$biomass[abund.summ$Species == i & abund.summ$Stock == j]) * 1.1
    # Create x-axis breaks from TL vector
    max.x         <- max(abund.summ$TL[abund.summ$Species == i & abund.summ$Stock == j])
    x.breaks      <- seq(0, max.x, max.x/10)
    # Plot length-disaggregated abundance for each species
    L.abund <- ggplot(filter(abund.summ, Species == i, Stock == j), aes(TL,abundance)) + 
      geom_bar(stat = 'identity',fill = 'gray50',colour = 'gray20') + 
      scale_x_continuous("Length (cm)", breaks = x.breaks) + 
      scale_y_continuous('Abundance (n)', limits = c(0, y.max.abund),
                         expand = c(0,0), labels = fancy_sci) +
      # facet_wrap(~Stock, nrow = 1) +
      theme_bw() +
      theme(strip.background.x = element_blank(),
            strip.text.x = element_text(face = "bold"))
    
    # Plot length-disaggregated biomass for each species
    L.biomass <- ggplot(filter(abund.summ, Species == i, Stock == j), aes(TL, biomass)) + 
      geom_bar(stat = 'identity', fill = 'gray50', colour = 'gray20') + 
      scale_x_continuous("Length (cm)", breaks = x.breaks) + 
      scale_y_continuous('Biomass (t)', limits = c(0, y.max.biomass),
                         expand = c(0,0), labels = fancy_sci) +
      # facet_wrap(~Stock, nrow = 1) +
      theme_bw() + 
      theme(strip.background.x = element_blank(),
            strip.text.x = element_text(face = "bold"))
    
    # Arrange all plots
    L.disagg.all <- plot_grid(L.abund, L.biomass, ncol = 1, align = 'h')
    # Save plot
    ggsave(L.disagg.all, 
           filename = paste(here("Figs/fig_L_disagg_"), i, "-", j, ".png", sep = ""), 
           height = 6, width = 6)
    
    # Add plot to list
    L.disagg.plots[[i]][[j]] <- L.disagg.all
  }
}

# Create blank plots for missing species
for (i in cps.spp) {
  if (is.null(L.disagg.plots[[i]])) {
    df <- data.frame()
    L.disagg.temp <- ggplot(df) + geom_point() + 
      xlim(0,10) + ylim(0,10) + 
      annotate('text',5,5,label = 'No Data',size = 6,fontface = 'bold') +
      theme_bw() + ggtitle(i)  
    ggsave(L.disagg.temp, 
           filename = paste(here("Figs/fig_L_disagg_"),i,".png", sep = ""))
  }
}  
```  

```{r abundance-by-length}
# Create and format abundance vs. length table for all species
L.abund.table <- abund.summ %>%
  ungroup() %>% 
  select(Species, Stock, SL, Abundance = abundance) %>% 
  kable(format = knitr.format, booktabs = TRUE, escape = FALSE, longtable = TRUE,
        digits = c(0),
        format.args = list(big.mark = ",")) %>%
  kable_styling(bootstrap_options = c("striped","hover","condensed"), 
                full_width = FALSE) %>%
  row_spec(0, align = c("c")) %>% 
  collapse_rows(columns = c(1)) %>% 
  scroll_box(height = "500px")

# Save results
save(L.abund.table, abund.summ, file = here("Output/abundance_table_all.Rdata"))
write_csv(abund.summ, here("Output/abundance_table_all.csv"))
```

## Results for anchovy (_Engraulis mordax_)
### Northern stock

(ref:biom-dens-anch-n) Biomass densities of northern stock of Northern Anchovy (_Engraulis mordax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one anchovy. The gray line represents the vessel track.

```{r biom-dens-anch-n,fig.cap='(ref:biom-dens-anch-n)',out.height='100%',fig.pos='H'}
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Engraulis mordax-Northern.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Engraulis mordax-Northern.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Engraulis mordax-Northern.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Engraulis mordax-Northern.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-anch-n) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for the northern stock of Northern Anchovy (_Engraulis mordax_) in the survey area.

```{r l-disagg-anch-n,fig.cap='(ref:l-disagg-anch-n)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for anchovy
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Engraulis mordax-Northern.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Engraulis mordax-Northern.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Engraulis mordax-Northern.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Engraulis mordax-Northern.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-anch-n) Abundance versus standard length ($L_S$, cm) for the northern stock of Northern Anchovy (_Engraulis mordax_).

```{r l-freq-summ-anch-n}
# Print table for anchovy
if ("Engraulis mordax" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Engraulis mordax", Stock == "Northern") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-anch-n)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No anchovy present.")
}
```

### Central stock

(ref:biom-dens-anch-c) Biomass densities of central stock of Northern Anchovy (_Engraulis mordax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one anchovy. The gray line represents the vessel track.

```{r biom-dens-anch-c,fig.cap='(ref:biom-dens-anch-c)',out.height='100%',fig.pos='H'}
# Insert biomass density plot for anchovy
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Engraulis mordax-Central.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Engraulis mordax-Central.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Engraulis mordax-Central.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Engraulis mordax-Central.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-anch-c) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for the central stock of Northern Anchovy (_Engraulis mordax_) in the survey area.

```{r l-disagg-anch-c,fig.cap='(ref:l-disagg-anch-c)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for anchovy
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Engraulis mordax-Central.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Engraulis mordax-Central.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Engraulis mordax-Central.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Engraulis mordax-Central.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-anch-c) Abundance versus standard length ($L_S$, cm) for the central stock of Northern Anchovy (_Engraulis mordax_).

```{r l-freq-summ-anch-c}
# Print table for anchovy
if ("Engraulis mordax" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Engraulis mordax", Stock == "Central") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-anch-n)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No anchovy present.")
}
```

### All stocks

(ref:rlf-anchovy) Standard length ($L_S$) frequency distributions of Northern Anchovy (_Engraulis mordax_) per nighttime trawl cluster, annotated with the number of individuals caught and their percentage contributions to the abundance in each stratum and across all strata (i.e., for the entire survey).

```{r rlf-anchovy,out.height='100%',fig.pos='H'}
# Insert relative length frequency plot for anchovy
if (file.exists(here("Figs/fig_cluster_relative_length_frequency_Engraulis mordax.png"))) {
  include_graphics(here("Figs/fig_cluster_relative_length_frequency_Engraulis mordax.png"))  
} else {
  print("No data for this stock.")
}
```  

## Results for sardine (_Sardinops sagax_)
### Northern stock

(ref:biom-dens-sar-n) Biomass densities of northern stock of Pacific Sardine (_Sardinops sagax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one sardine. The gray line represents the vessel track.

```{r biom-dens-sar-n,fig.cap='(ref:biom-dens-sar-n)',out.height='100%',fig.pos='H'}
# Insert biomass density plot for sardine
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Sardinops sagax-Northern.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Sardinops sagax-Northern.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Sardinops sagax-Northern.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Sardinops sagax-Northern.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-sar-n) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for the northern stock of Pacific Sardine (_Sardinops sagax_) in the survey area.

```{r l-disagg-sar-n,fig.cap='(ref:l-disagg-sar-n)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for sardine
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Sardinops sagax-Northern.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Sardinops sagax-Northern.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Sardinops sagax-Northern.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Sardinops sagax-Northern.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-sar-n) Abundance versus standard length ($L_S$, cm) for the northern stock of Pacific Sardine (_Sardinops sagax_).

```{r l-freq-summ-sar-n}
# Print table for sardine
if ("Sardinops sagax" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Sardinops sagax", Stock == "Northern") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-sar-n)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No sardine present.")
}
```

### Southern stock

(ref:biom-dens-sar-s) Biomass densities of southern stock of Pacific Sardine (_Sardinops sagax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one sardine. The gray line represents the vessel track.

```{r biom-dens-sar-s,fig.cap='(ref:biom-dens-sar-s)',out.height='100%',fig.pos='H'}
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Sardinops sagax-Southern.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Sardinops sagax-Southern.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Sardinops sagax-Southern.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Sardinops sagax-Southern.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-sar-s) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for the southern stock of Pacific Sardine (_Sardinops sagax_) in the survey area.

```{r l-disagg-sar-s,fig.cap='(ref:l-disagg-sar-s)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for sardine
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Sardinops sagax-Southern.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Sardinops sagax-Southern.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Sardinops sagax-Southern.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Sardinops sagax-Southern.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-sar-s) Abundance versus standard length ($L_S$, cm) for the southern stock of Pacific Sardine (_Sardinops sagax_).

```{r l-freq-summ-sar-s}
# Print table for sardine
if ("Sardinops sagax" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Sardinops sagax", Stock == "Southern") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-sar-s)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No sardine present.")
}
```

### All stocks

(ref:rlf-sardine) Standard length ($L_S$) frequency distributions of Pacific Sardine (_Sardinops sagax_) per nighttime trawl cluster, annotated with the number of individuals caught and their percentage contributions to the abundance in each stratum and across all strata (i.e., for the entire survey).

```{r rlf-sardine,out.height='100%',fig.pos='H'}
# Insert relative length frequency plot for sardine
if (file.exists(here("Figs/fig_cluster_relative_length_frequency_Sardinops sagax.png"))) {
  include_graphics(here("Figs/fig_cluster_relative_length_frequency_Sardinops sagax.png"))  
} else {
  print("No data for this stock.")
}
``` 

## Results for Pacific mackerel (_Scomber japonicus_)  

(ref:biom-dens-mack) Biomass densities of Pacific mackerel (_Scomber japonicus_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one mackerel The gray line represents the vessel track.

```{r biom-dens-mack,fig.cap='(ref:biom-dens-mack)',out.height='100%',fig.pos='H'}
# Insert biomass density plot for P. mackerel
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Scomber japonicus-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Scomber japonicus-All.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Scomber japonicus-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Scomber japonicus-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-mack) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for Pacific mackerel (_Scomber japonicus_) in the survey area.

```{r l-disagg-mack,fig.cap='(ref:l-disagg-mack)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for P. mackerel
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Scomber japonicus-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Scomber japonicus-All.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Scomber japonicus-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Scomber japonicus-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-mack) Abundance versus standard length ($L_S$, cm) for for Pacific mackerel (_Scomber japonicus_).

```{r l-freq-summ-mack}
# Print table for mack mackerel
if ("Scomber japonicus" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Scomber japonicus", Stock == "All") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-mack)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No Pacific mackerel present.")
}
```

(ref:rlf-mack) Fork length ($L_F$) frequency distributions of Pacific Mackerel (_Scomber japonicus_) per nighttime trawl cluster, annotated with the number of individuals caught and their percentage contributions to the abundance in each stratum and across all strata (i.e., for the entire survey).

```{r rlf-mack,out.height='100%',fig.pos='H'}
# Insert relative length frequency plot for anchovy
if (file.exists(here("Figs/fig_cluster_relative_length_frequency_Scomber japonicus.png"))) {
  include_graphics(here("Figs/fig_cluster_relative_length_frequency_Scomber japonicus.png"))  
} else {
  print("No data for this stock.")
}
``` 

## Results for Jack Mackerel (_Trachurus symmetricus_)

(ref:biom-dens-jack) Biomass densities of Jack Mackerel (_Trachurus symmetricus_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one jack mackerel. The gray line represents the vessel track.

```{r biom-dens-jack,fig.cap='(ref:biom-dens-jack)',out.height='100%',fig.pos='H'}
# Insert biomass density plot for jack mackerel
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Trachurus symmetricus-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Trachurus symmetricus-All.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Trachurus symmetricus-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Trachurus symmetricus-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-jack) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for Jack Mackerel (_Trachurus symmetricus_) in the survey area.

```{r l-disagg-jack,fig.cap='(ref:l-disagg-jack)',out.height='100%',fig.pos='H'}
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Trachurus symmetricus-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Trachurus symmetricus-All.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Trachurus symmetricus-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Trachurus symmetricus-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-jack) Abundance versus standard length ($L_S$, cm) for for Jack Mackerel (_Trachurus symmetricus_).

```{r l-freq-summ-jack}
# Print table for jack mackerel
if ("Trachurus symmetricus" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Trachurus symmetricus", Stock == "All") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-jack)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No jack mackerel present.")
}
```

(ref:rlf-jack) Fork length ($L_F$) frequency distributions of Jack Mackerel (_Trachurus symmetricus_) per nighttime trawl cluster, annotated with the number of individuals caught and their percentage contributions to the abundance in each stratum and across all strata (i.e., for the entire survey).

```{r rlf-jack,out.height='100%',fig.pos='H'}
# Insert relative length frequency plot for jack mackerel
if (file.exists(here("Figs/fig_cluster_relative_length_frequency_Trachurus symmetricus.png"))) {
  include_graphics(here("Figs/fig_cluster_relative_length_frequency_Trachurus symmetricus.png"))  
} else {
  print("No data for this stock.")
}
``` 

## Results for Pacific herring (_Clupea pallasii_)

(ref:biom-dens-her) Biomass densities of Pacific herring (_Clupea pallasii_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one herring. The gray line represents the vessel track.

```{r biom-dens-her,fig.cap='(ref:biom-dens-her)',out.height='100%',fig.pos='H'}
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Clupea pallasii-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Clupea pallasii-All.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Clupea pallasii-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Clupea pallasii-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-her) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for Pacific herring (_Clupea pallasii_) in the survey area.

```{r l-disagg-her,fig.cap='(ref:l-disagg-her)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for herring
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Clupea pallasii-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Clupea pallasii-All.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Clupea pallasii-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Clupea pallasii-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-her) Abundance versus standard length ($L_S$, cm) for for Pacific herring (_Clupea pallasii_).

```{r l-freq-summ-her}
# Print table for jack mackerel
if ("Clupea pallasii" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Clupea pallasii", Stock == "All") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-her)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No herring present.")
}
```

(ref:rlf-her) Standard length ($L_S$) frequency distributions of Pacific herring (_Clupea pallasii_) per nighttime trawl cluster, annotated with the number of individuals caught and their percentage contributions to the abundance in each stratum and across all strata (i.e., for the entire survey).

```{r rlf-her,out.height='100%',fig.pos='H'}
# Insert relative length frequency plot for herring
if (file.exists(here("Figs/fig_cluster_relative_length_frequency_Clupea pallasii.png"))) {
  include_graphics(here("Figs/fig_cluster_relative_length_frequency_Clupea pallasii.png"))  
} else {
  print("No data for this stock.")
}
```

## Results for round herring (_Etrumeus acuminatus_)

(ref:biom-dens-rher) Biomass densities of round herring (_Etrumeus acuminatus_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one herring. The gray line represents the vessel track.

```{r biom-dens-rher,fig.cap='(ref:biom-dens-rher)',out.height='100%',fig.pos='H'}
if (combine.regions) {
  if (file.exists(here("Figs/fig_biomass_dens_combo_Etrumeus acuminatus-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_combo_Etrumeus acuminatus-All.png"))  
  } else {
    print("No data for this stock.")
  }
} else {
  if (file.exists(here("Figs/fig_biomass_dens_Etrumeus acuminatus-All.png"))) {
    include_graphics(here("Figs/fig_biomass_dens_Etrumeus acuminatus-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-disagg-rher) Abundance versus standard length ($L_S$, upper panel) and biomass (t) versus $L_S$ (lower panel) for round herring (_Etrumeus acuminatus_) in the survey area.

```{r l-disagg-rher,fig.cap='(ref:l-disagg-rher)',out.height='100%',fig.pos='H'}
# Insert disaggregated abundance plots for herring
if (combine.regions) {
  if (file.exists(here("Figs/fig_L_disagg_combo_Etrumeus acuminatus-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_combo_Etrumeus acuminatus-All.png"))  
  } else {
    print("No data for this stock.")
  } 
} else {
  if (file.exists(here("Figs/fig_L_disagg_Etrumeus acuminatus-All.png"))) {
    include_graphics(here("Figs/fig_L_disagg_Etrumeus acuminatus-All.png"))  
  } else {
    print("No data for this stock.")
  }
}
```

(ref:l-freq-summ-rher) Abundance versus standard length ($L_S$, cm) for for round herring (_Etrumeus acuminatus_).

```{r l-freq-summ-rher}
# Print table for round herring
if ("Etrumeus acuminatus" %in% unique(abund.summ$Species)) {
  abund.summ.table <- abund.summ %>% 
    filter(Species == "Etrumeus acuminatus", Stock == "All") %>% 
    select(Stock, SL, abundance) %>% 
    rename(Abundance = abundance,
           '$L_S$' = SL) %>%
    ungroup()
  
  if (nrow(abund.summ.table) != 0) {
    if (doc.type == "docx") {
      regulartable(abund.summ.table) %>% 
        align(align = "center",part = "header") %>% 
        # set_formatter(SL = function(x) sprintf("%.0f", x),
        #               Abundance = function(x) sprintf("%.0f", x)) %>% 
        autofit()
    } else {
      kable(abund.summ.table, booktabs = FALSE,escape = FALSE,longtable = T,
            digits = c(0),
            format.args = list(big.mark = ","),
            caption = '(ref:l-freq-summ-her)') %>%
        kable_styling(latex_options = c("striped","repeat_headers")) %>%
        column_spec(1, italic = T) %>% 
        collapse_rows(columns = c(1:2)) %>%
        row_spec(0, align = c("c"))    
    }
  }
} else {
  print("No round herring present.")
}
```

(ref:rlf-rher) Standard length ($L_S$) frequency distributions of round herring (_Etrumeus acuminatus_) per nighttime trawl cluster, annotated with the number of individuals caught and their percentage contributions to the abundance in each stratum and across all strata (i.e., for the entire survey).

```{r rlf-rher,out.height='100%',fig.pos='H'}
# Insert relative length frequency plot for round herring
if (file.exists(here("Figs/fig_cluster_relative_length_frequency_Etrumeus acuminatus.png"))) {
  include_graphics(here("Figs/fig_cluster_relative_length_frequency_Etrumeus acuminatus.png"))  
} else {
  print("No data for this stock.")
}
```

# Map nearshore extrapolation

```{r map-biomass-density-nearshore,out.height='100%'}
# Calculate nearshore biomass density for plotting
nasc.density.nse <- nasc.nse.final %>%
  select(lat, long, anch.dens, her.dens, jack.dens, mack.dens, 
         sar.dens, transect, int) %>% 
  group_by(transect, int) %>% 
  summarise(
    lat = lat[1],
    long = long[1],
    `Engraulis mordax`      = mean(anch.dens),
    `Clupea pallasii`       = mean(her.dens),
    `Trachurus symmetricus` = mean(jack.dens),
    `Scomber japonicus`     = mean(mack.dens),
    `Sardinops sagax`       = mean(sar.dens)) %>% 
  gather(scientificName, density, -transect, -int, -lat, -long) %>% 
  mutate(bin       = cut(density, dens.breaks, include.lowest = TRUE,
                         ordered_result = TRUE),
         bin.level = as.numeric(bin),
         key       = paste(transect, int)) %>% 
  ungroup() %>% 
  project_df(to = crs.proj)

# Create maps of nearshore biomass
if (save.figs) {
  source(here("Code", paste0("mapNearshoreExtrapolation_", survey.name, ".R")))
}
```

## Results for anchovy (_Engraulis mordax_)
### Northern stock

(ref:biom-dens-anch-n-nse) Extrapolated nearshore biomass densities of northern stock of Northern Anchovy (_Engraulis mordax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one anchovy. The gray line represents the vessel track.

```{r biom-dens-anch-n-nse,fig.cap='(ref:biom-dens-anch-n-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Engraulis mordax-Northern.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Engraulis mordax-Northern.png"))  
} else {
  print("No data for this stock.")
}
```

### Central stock

(ref:biom-dens-anch-c-nse) Extrapolated nearshore biomass densities of central stock of Northern Anchovy (_Engraulis mordax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one anchovy. The gray line represents the vessel track.

```{r biom-dens-anch-c-nse,fig.cap='(ref:biom-dens-anch-c-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Engraulis mordax-Central.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Engraulis mordax-Central.png"))  
} else {
  print("No data for this stock.")
}
```

## Results for sardine (_Sardinops sagax_)
### Northern stock

(ref:biom-dens-sar-n-nse) Extrapolated nearshore biomass densities of northern stock of Pacific Sardine (_Sardinops sagax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one sardine. The gray line represents the vessel track.

```{r biom-dens-sar-n-nse,fig.cap='(ref:biom-dens-sar-n-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Sardinops sagax-Northern.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Sardinops sagax-Northern.png"))  
} else {
  print("No data for this stock.")
}
```

### Southern stock

(ref:biom-dens-sar-s-nse) Extrapolated nearshore biomass densities of southern stock of Pacific Sardine (_Sardinops sagax_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one sardine. The gray line represents the vessel track.

```{r biom-dens-sar-s-nse,fig.cap='(ref:biom-dens-sar-s-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Sardinops sagax-Southern.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Sardinops sagax-Southern.png"))  
} else {
  print("No data for this stock.")
}
```

## Results for Pacific mackerel (_Scomber japonicus_)

(ref:biom-dens-mack-nse) Extrapolated nearshore biomass densities of Pacific mackerel (_Scomber japonicus_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one mackerel. The gray line represents the vessel track.

```{r biom-dens-mack-nse,fig.cap='(ref:biom-dens-mack-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Scomber japonicus-All.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Scomber japonicus-All.png"))  
} else {
  print("No data for this stock.")
}
```

## Results for jack mackerel (_Trachurus symmetricus_)

(ref:biom-dens-jack-nse) Extrapolated nearshore biomass densities of jack mackerel (_Trachurus symmetricus_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one jack mackerel. The gray line represents the vessel track.

```{r biom-dens-jack-nse,fig.cap='(ref:biom-dens-jack-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Trachurus symmetricus-All.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Trachurus symmetricus-All.png"))  
} else {
  print("No data for this stock.")
}
```

## Results for Pacific herring (_Clupea pallasii_)

(ref:biom-dens-her-nse) Extrapolated nearshore biomass densities of Pacific herring (_Clupea pallasii_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one herring. The gray line represents the vessel track.

```{r biom-dens-her-nse,fig.cap='(ref:biom-dens-her-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Clupea pallasii-All.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Clupea pallasii-All.png"))  
} else {
  print("No data for this stock.")
}
```

## Results for round herring (_Etrumeus acuminatus_)

(ref:biom-dens-rher-nse) Extrapolated nearshore biomass densities of round herring (_Etrumeus acuminatus_), per strata, throughout the survey region. The blue numbers represent the locations of trawl clusters with at least one herring. The gray line represents the vessel track.

```{r biom-dens-rher-nse,fig.cap='(ref:biom-dens-rher-nse)',out.height='100%',fig.pos='H'}
if (file.exists(here("Figs/fig_biomass_dens_nse_Etrumeus acuminatus-All.png"))) {
  include_graphics(here("Figs/fig_biomass_dens_nse_Etrumeus acuminatus-All.png"))  
} else {
  print("No data for this stock.")
}
```

# Appendices
## **Appendix A.** Acoustic calibration results.

```{r process-cal-all,eval=FALSE}
if (process.cal) {
  source(here("Code/extractCalAll.R"))
} else {
  load(here("Data/Calibration/cal_results_all.Rdata"))
}

if (save.figs) {
  source(here("Code/plot_CalTimeSeries.R"))
}
```  

```{r process-cal,eval=FALSE}
# Get results from current survey ---------------------------------------------
cal.res <- cal.res.all %>% 
  mutate(cal_date = mdy(cal_date)) %>% 
  filter(between(cal_date,
                 ymd(cal.plot.date) - days(cal.window),
                 ymd(cal.plot.date) + days(cal.window))) %>% 
  arrange(txdr_freq)


# create data frame for calibration parameters
cal.params <- cal.res %>% 
  select(txdr_freq,txdr_type,txdr_sn,gpt_power,gpt_pd,
         txdr_gain,txdr_sa_corr,gpt_rcr_bw,gpt_si,
         txdr_2way_ba,env_alpha,txdr_alon_ang_sens,
         txdr_athw_ang_sens,txdr_alon_ba,txdr_athw_ba,
         txdr_alon_oa,txdr_athw_oa,target_ts) 

# add noise estimates
# if noise isn't measured, enter -999 in the User Inputs, else use noise estimates
if (is.na(cal.noise[survey.vessel.primary])) { 
  cal.params$noise <- rep("N/A", nrow(cal.res))
}else{
  cal.params$noise <- unlist(cal.noise[cal.vessels])
}

# create data frame for beam model results
bm.res <- cal.res %>% 
  select(txdr_freq,bm_txdr_gain,bm_sa_corr,dev_bm_rms,
         bm_alon_ba,bm_athw_ba,bm_alon_oa,bm_athw_oa) 

# create a data frame for echosounder settings
echo.settings <- cal.res %>% 
  select(txdr_freq,gpt_pd,gpt_si,gpt_rcr_bw,gpt_power,txdr_z,env_alpha) 

# create names for cal parameters and beam model results
names(cal.params) <- c("Frequency","Model","Serial Number","Transmit Power ($p_\\mathrm{et}$)",
                       "Pulse Duration ($\\tau$)","On-axis Gain ($G_0$)",
                       "$S_\\mathrm{a}$ Correction ($S_\\mathrm{a}\\mathrm{corr}$)",
                       "Bandwidth ($W_\\mathrm{f}$)","Sample Interval",
                       "Eq. Two-way Beam Angle ($\\mathrm{\\Psi}$)",
                       "Absorption Coefficient ($\\alpha_\\mathrm{f}$)",
                       "Angle Sensitivity Along. ($\\mathrm{\\Lambda}_{\\alpha}$)",
                       "Angle Sensitivity Athw. ($\\mathrm{\\Lambda}_{\\beta}$)",
                       "3-dB Beamwidth Along. ($\\alpha_\\mathrm{-3dB}$)",
                       "3-dB Beamwidth Athw. ($\\beta_\\mathrm{-3dB}$)",
                       "Angle Offset Along. ($\\alpha_{0}$)","Angle Offset Athw. ($\\beta_{0}$)",
                       "Theoretical TS ($TS_\\mathrm{theory}$)",
                       "Ambient Noise")

names(bm.res) <- c("Frequency","On-axis Gain ($G_0$)",
                   "$S_\\mathrm{a}$ Correction ($S_\\mathrm{a}\\mathrm{corr}$)","RMS",
                   "3-dB Beamwidth Along. ($\\alpha_\\mathrm{-3dB}$)",
                   "3-dB Beamwidth Athw. ($\\beta_\\mathrm{-3dB}$)",
                   "Angle Offset Along. ($\\alpha_{0}$)",
                   "Angle Offset Athw. ($\\beta_{0}$)")

names(echo.settings) <- c("Frequency","Pulse Duration ($\\mu s$)","Sample Interval (m)",
                          "Bandwidth (Hz)","Transmit Power (W)",
                          "Transducer Depth (m)","Absorption Coefficient (dB km$\\^{-1}$)")

# cast output by frequency and transducer model number
param.output  <- suppressMessages(reshape2::dcast(melt(cal.params, id.vars = "Frequency"), variable~Frequency))
bm.output     <- suppressMessages(reshape2::dcast(melt(bm.res, id.vars = "Frequency"), variable~Frequency))

# add a column with parameter units
param.units <- as.data.frame(c(" "," ","W","ms","dB re 1","dB re 1","Hz","m","dB re 1 sr","dB km$^{-1}$",
                               "Elec.$^\\circ$/Geom.$^\\circ$","Elec.$^\\circ$/Geom.$^\\circ$",
                               "deg","deg","deg","deg","dB re 1 m$^{2}$","dB re 1 W"))

# add a column with beam model units
bm.units <- as.data.frame(c("dB re 1","dB re 1","dB","deg","deg","deg","deg"))

# add label for first column
names(param.units) <- "Units"
names(bm.units)    <- "Units"

# add units to output and arrange columns
param.output <- bind_cols(param.output, param.units) %>% 
  select(variable, Units, everything()) %>% 
  rename("Frequency ($f$, kHz)" = variable)

bm.output <- bind_cols(bm.output, bm.units) %>% 
  select(variable, Units, everything()) %>% 
  rename("Frequency ($f$, kHz)" = variable)

# combine results data frames
all.output <- rbind(param.output, bm.output) %>% 
  rename(" " = "Frequency ($f$, kHz)")

# save output to .Rdata and CSV
save(all.output,
     file = here("Output/cal_output_table.Rdata"))

write.csv(all.output,
          file = here("Output/cal_output_table.csv"), 
          quote = FALSE, row.names = FALSE)
```

(ref:cal-results) Simrad EK80 wideband transceiver (WBT) information, pre-calibration settings (above horizontal line), and beam model results following calibration (below horizontal line). Prior to the survey, on-axis gain ($G_0$), beam angles and angle offsets, and $S_a$ Correction ($S_\mathrm{a}\mathrm{corr}$) values from calibration results were entered into the WBT-control software (Simrad EK80).

```{r cal-results, results='asis',eval=FALSE}
if (doc.type == "docx") {
  # create kable object (for Word)
  pander(all.output)
} else {
  # print LaTeX table for HTML or PDF
  kable(all.output, format = knitr.format, align = c("l","l",rep("c",ncol(all.output) - 2)),
        booktabs = T, escape = FALSE,
        caption = '(ref:cal-results)') %>% 
    kable_styling(position = "center", latex_options = c("scale_down","hold_position")) %>% 
    row_spec(18, hline_after = T) %>% 
    add_header_above(c(" " = 2, "Frequency (kHz)" = ncol(all.output) - 2))
}
```  

```{r plot-cal-time-series}
# Include calibration time series plot
if (file.exists(here("Figs/fig_cal_time_series_combo.png"))) {
  include_graphics(here("Figs/fig_cal_time_series_combo.png"))  
} else {
  print("No calibration time series plots available.")
}
```


```{r work-complete,eval=FALSE}
beep(4)
```

# Literature cited  
