---
output: 
  bookdown::pdf_document2:
    number_sections: yes
    toc: no
    includes: 
      in_header: yaml/header.tex
  bookdown::word_document2:
    reference_docx: template/report_template_DRAFT_Rmarkdown.docx
csl: csl/ices-journal-of-marine-science.csl
bibliography: bib/ast_bib.bib
---
```{r load-libraries, echo=F, error=F, message=F, warning=F}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,swfscMisc,readr,pander,kableExtra,bookdown,rgeos,
               knitr,ggmap,maps,readxl,RSQLite,shadowtext,xml2,sf,odbc,ggspatial,
               maptools,png,grid,gridExtra,cowplot,flextable,fs,ftExtra,mapview,
               stringr,xtable,devtools,gdata,reshape2,lubridate,rworldmap,
               scatterpie,forcats,here,viridis,rnaturalearth,rworldxtra,tcltk)

# Install and load required packages from Github -------------------------------
# surveyR
pacman::p_load_gh("kstierhoff/surveyR")
# atm
pacman::p_load_gh("kstierhoff/atm")
# rnaturalearth data
pacman::p_load_gh("ropenscilabs/rnaturalearthdata")
pacman::p_load_gh("ropenscilabs/rnaturalearthhires")

# Define method of table generation (whether kable or xtable) for best formatting
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')
doc.name <- knitr::current_input()
if (is.null(doc.type)) {doc.type <- "html"}
if (is.null(doc.name)) {doc.name <- "reportSurvey.Rmd"}

# global knitr chunk options
knitr::opts_chunk$set(echo = F, warning = F, message = F,progress = T,
                      fig.align = 'center',dev = "png",
                      dev.args = list(type = "cairo"),dpi = 150)

# determine global knitr table format
if (doc.type == "latex") {
  knitr.format <- "latex"
} else {
  knitr.format <- "html" 
}

# set global knitr table format
options(knitr.table.format = knitr.format,knitr.kable.NA = '')

# global pander options
panderOptions('table.style','rmarkdown'); panderOptions('table.split.table', Inf); panderOptions('digits', 6);
panderOptions('round', 6); panderOptions('keep.trailing.zeros', T); panderOptions('missing', "")

# Register Google Maps API; remove 
if (exists("google_map_api")) register_google(key = google_map_api)

# Create data directories
dir_create(here(c("Figs","Output")))
```

```{r user-input,include=FALSE}
# Get project name from directory
prj.name <- dplyr::last(unlist(str_split(here(), "/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste0("settings_", prj.name, ".R"))]
source(here("Doc/settings", prj.settings))

# Define ggplot theme
theme_set(theme_bw())

# Overwrite any variables from the "settings" file here, e.g., to not interfere
# with variables that might also be used by reportBiomass
rm.offshore = c(RL  = TRUE,
                LM  = TRUE,
                LBC = TRUE,
                SD  = TRUE,
                JCF = FALSE) 
```

```{r controls, echo=F, error=F, message=F, warning=F}
# Processing instructions (T/F)
copy.files      <- T # copy Lasker trawl, CUFES, and NASC files from source (data from other vessels must be manually copied)
copy.bib        <- F # copy files from source; requires VPN (LEAVE AS F to use existing file from GitHub)
overwrite.csv   <- T # overwrite CSV files when copying
overwrite.files <- T # overwrite non-CSV files when copying
download.hab    <- F # download habitat map (F if using temporal aggregate map)
save.figs       <- T # draw plots and maps, or use existing
get.db          <- T # import trawl database data
process.scs     <- F # process SCS logs, or load processed data
get.nav         <- T # download nav data from ERDDAP
process.csv     <- T # process CSV files from Echoview
process.csv.all <- F # Process all CSV files (F = only new files)
process.cal.FM  <- T # Process FM calibration results
process.zmux    <- F # process impedance data
resize.map      <- F # Resize map during survey; if T, uses anticipated bounds of survey area

calc.raw.size   <- F # computer RAW file size, or use existing
```

```{r copy-bib,include=F}
if (copy.bib) {
  # Update bibliography and CSL
  file_copy("//swc-storage1/ast1/LITERATURE/Rmarkdown/csl/ices-journal-of-marine-science.csl",
            "csl", overwrite = T)
  file_copy("//swc-storage1/AST1/LITERATURE/Rmarkdown/bib/ast_bib.bib",
            "bib", overwrite = T)
}
```

```{r copy-files, include=F}
if (copy.files) {
  # Create data directories
  dir_create(here("Data", c("Backscatter","CUFES","Trawl")))
  dir_create(here("Data/Backscatter", nasc.vessels))
  
  # Copy trawl Access database
  haul.db <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/HAUL"),
                    regexp = trawl.db.access)
  file_copy(haul.db, here("Data/Trawl"), overwrite = overwrite.files)
  
  # Copy CUFES files
  cufes.file <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/CUFES"), 
                       regexp = cufes.db.sqlite)
  file_copy(cufes.file, here("Data/CUFES"), overwrite = overwrite.files)
  
  # Copy CSV files for CPS
  csv.files.cps <- dir_ls(file.path(survey.dir[survey.vessel.primary], 
                                    nasc.dir[survey.vessel.primary]), 
                          regexp = nasc.pattern.cps[survey.vessel.primary],
                          ignore.case = TRUE)
  file_copy(csv.files.cps, here("Data/Backscatter", survey.vessel.primary), 
            overwrite = overwrite.csv)
}
```

```{r process-nav, include=FALSE}
# Source code to get nav data from ERDDAP
source(here("Code/get_nav_erddap.R"))

# Read transect waypoints
wpts <- read_csv(here("Data/Nav", wpt.filename))

# Convert planned transects to sf; CRS = crs.geog
wpts.sf <- wpts %>% 
  filter(Type %in% wpt.types) %>% 
  st_as_sf(coords = c("Longitude","Latitude"), crs = crs.geog)

transects.sf <- wpts.sf %>% 
  group_by(Type, Transect, Region) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING")

# Create gps.csv file from nav to replace missing data in Echoview
nav.gps <- nav %>% 
  mutate(GPS_date = format(time, format = "%F"),
         GPS_time = format(time, format = "%T")) %>% 
  select(GPS_date, GPS_time, latitude = lat, longitude = long)

write_csv(nav.gps, here("Output/nav.gps.csv"))

# Get most recent vessel position for plotting
nav.now <- tail(nav.sf, 1) %>% 
  mutate(label = paste("Last position:", time, "UTC"))
```

```{r download-habitat-maps}
if (download.hab) {
  source(here("Code/plot_sardine_habitat_2107RL.R"))
  # source(here("Code/plot_sardine_habitat_all.R"))
}
```

```{r process-cal}
# Currently, the process-cal-all section must be run first to either extract all
# calibration results from a SQL database or load it from an RData file. This
# section then pulls out the results for the current survey then formats it into
# a dataframe for displaying the results. This is then done separately for each
# survey vessel. This should be updated so that it loops through each survey
# vessel, obtains the calibration info, then formats it for displaying in a
# table

# Cycle through each vessel
for (i in cal.vessels) {
  
  # Define directory with calibration files for current vessel
  cal.dir <- paste(here("Data/Calibration"), i, sep = '/')
  
  # Get list of calibration files for that vessel
  cal.files <- sort(c(list.files(cal.dir, pattern = ".txt", 
                                     full.names = TRUE),
                          list.files(cal.dir, pattern = ".xml", 
                                     full.names = TRUE)))
  
  # Initialize data frames for storing results
  cal.res   <- data.frame()
  cal.info  <- data.frame()
  cal.pings <- data.frame()
  
  # Cycle through each calibration file (frequency)
  for (j in cal.files) {
  
    # Extract calibration info for that frequency
    cal <- extract_cal(j)
    
    # Append to data frames
    cal.res <- bind_rows(cal.res,   cal$cal.res)
    cal.info <- bind_rows(cal.info,  cal$cal.info)
    cal.pings <- bind_rows(cal.pings, cal$cal.pings)
  }
  
  # create data frame of echosounder parameters
  cal.params <- cal.res %>% 
    select(txdr_freq,txdr_type,txdr_sn,gpt_power,gpt_pd,
           txdr_gain,txdr_sa_corr,gpt_rcr_bw,gpt_si,
           txdr_2way_ba,env_alpha,txdr_alon_ang_sens,
           txdr_athw_ang_sens,txdr_alon_ba,txdr_athw_ba,
           txdr_alon_oa,txdr_athw_oa,target_ts) 
  
  # Specify names for echosounder parameters 
  names(cal.params) <- c("Frequency","Model","Serial Number","Transmit Power ($p_\\mathrm{et}$)",
                         "Pulse Duration ($\\tau$)","On-axis Gain ($G_0$)",
                         "$S_\\mathrm{a}$ Correction ($S_\\mathrm{a}\\mathrm{corr}$)",
                         "Bandwidth ($W_\\mathrm{f}$)","Sample Interval",
                         "Eq. Two-way Beam Angle ($\\mathrm{\\Psi}$)",
                         "Absorption Coefficient ($\\alpha_\\mathrm{f}$)",
                         "Angle Sensitivity Along. ($\\mathrm{\\Lambda}_{\\alpha}$)",
                         "Angle Sensitivity Athw. ($\\mathrm{\\Lambda}_{\\beta}$)",
                         "3-dB Beamwidth Along. ($\\alpha_\\mathrm{-3dB}$)",
                         "3-dB Beamwidth Athw. ($\\beta_\\mathrm{-3dB}$)",
                         "Angle Offset Along. ($\\alpha_{0}$)","Angle Offset Athw. ($\\beta_{0}$)",
                         "Theoretical TS ($TS_\\mathrm{theory}$)")

  # create data frame of beam model results
  bm.res <- cal.res %>% 
    select(txdr_freq,bm_txdr_gain,bm_sa_corr,dev_bm_rms,
           bm_alon_ba,bm_athw_ba,bm_alon_oa,bm_athw_oa)
  
  # Specify number of significant digits for certain parameters
  bm.res$bm_sa_corr <- formatC(bm.res$bm_sa_corr, format="f", digits=2)
  bm.res$dev_bm_rms <- formatC(bm.res$dev_bm_rms, format="f", digits=2)

  # Specify names for beam model results
  names(bm.res) <- c("Frequency","On-axis Gain ($G_0$)",
                   "$S_\\mathrm{a}$ Correction ($S_\\mathrm{a}\\mathrm{corr}$)","RMS",
                   "3-dB Beamwidth Along. ($\\alpha_\\mathrm{-3dB}$)",
                   "3-dB Beamwidth Athw. ($\\beta_\\mathrm{-3dB}$)",
                   "Angle Offset Along. ($\\alpha_{0}$)",
                   "Angle Offset Athw. ($\\beta_{0}$)")

  # Sort data frames by frequency
  param.output  <- suppressMessages(dcast(melt(cal.params, id.vars = "Frequency"), variable~Frequency))
  bm.output     <- suppressMessages(dcast(melt(bm.res, id.vars = "Frequency"), variable~Frequency))

  # Create column defining parameter units
  param.units <- data.frame(Units = c(" "," ","W","ms","dB re 1","dB re 1","Hz","m","dB re 1 sr","dB km$^{-1}$",
                                      "Elec.$^\\circ$/Geom.$^\\circ$","Elec.$^\\circ$/Geom.$^\\circ$",
                                      "deg","deg","deg","deg","dB re 1 m$^{2}$"))#,"dB re 1 W"))

  # Create column defining beam model units
  bm.units <- data.frame(Units = c("dB re 1","dB re 1","dB","deg","deg","deg","deg"))

  # Add units column to parameter data frame
  param.output <- bind_cols(param.output, param.units) %>% 
    select(variable, Units, everything()) %>% 
    rename("Frequency ($f$, kHz)" = variable)

  # Add units column to beam model results data frame
  bm.output <- bind_cols(bm.output, bm.units) %>% 
    select(variable, Units, everything()) %>% 
    rename("Frequency ($f$, kHz)" = variable)

  # combine the parameters and results data frames
  all.output <- rbind(param.output, bm.output) %>% 
    rename(" " = "Frequency ($f$, kHz)")
  
  # Store in data frame specific to the current vessel
  assign(paste("all.output.", i, sep = ""), all.output)

  # save output to .Rdata and CSV
  save(all.output,
       file = here(paste("Output/cal_output_table_", i, ".Rdata", sep = '')))

  write.csv(all.output,
            file = here(paste("Output/cal_output_table_", i, ".csv", sep = '')),
            quote = F, row.names = F)

  # If saving figures, then plot and save calibration polar plots
  if (save.figs) {
  
    # Format ping data for plotting
    cal.pings <- cal.pings %>% 
      mutate(cal_date = date(date_time)) %>% 
      filter(between(cal_date,
                     ymd(cal.plot.date) - days(cal.window),
                     ymd(cal.plot.date) + days(cal.window))) %>% 
      arrange(txdr_freq, ping_num)
  
    # Set axis limits based on range of ping angles
    cal.lim.tmp <- round(max(max(cal.pings$along), max(cal.pings$athw))) 
  
    if (cal.lim.tmp %% 2) {
      # If range is odd, add 1 to make axis ticks look nice
      cal.axis.lims <- c(-(cal.lim.tmp + 1), cal.lim.tmp + 1)
    } else {
      cal.axis.lims <- c(-cal.lim.tmp, cal.lim.tmp)
    }
  
    # subset only outlier points
    outliers <- filter(cal.pings, outlier == 1)
  
    cal.pings <- cal.pings %>% 
      left_join(select(cal.res,txdr_freq,txdr_type,target_ts,
                       txdr_gain,bm_txdr_gain,
                       bm_alon_ba,bm_athw_ba,
                       bm_alon_oa,bm_athw_oa)) %>% 
      mutate(
        txdr_type      = fct_reorder(txdr_type, txdr_freq),
        TS_u_new       = TS_u + 2*(txdr_gain - bm_txdr_gain),
        alpha          = along - bm_alon_oa,
        beta           = athw - bm_athw_oa,
        x              = (2*alpha) / bm_alon_ba,
        y              = (2*beta) / bm_athw_ba,
        B              = 6.0206*(x^2 + y^2 - 0.18*x^2*y^2),
        TS_c_new       = TS_u_new + B,
        relTS_c        = TS_c_new - target_ts,
        relTS_c_scaled = case_when(
          relTS_c >= 1 ~ 1,
          relTS_c <= -1 ~-1,
          between(relTS_c,-1,1) ~ relTS_c))
    
    if (cal.scales == "fixed") {
      # Plot beam-uncompensated target strength data #####
      tsu.scatter <- ggplot(filter(cal.pings, outlier == 0), aes(athw, along)) +
        geom_point(aes(colour = TS_u)) + 
        geom_point(data = filter(cal.pings, outlier == 1), aes(athw, along), 
                   shape = "+", size = 1, alpha = 0.7) +
        facet_wrap(~txdr_type, scales = cal.scales) +
        scale_colour_viridis(name = expression(paste(italic(TS)[u]," (dB)",sep = "")),
                             option = "magma") +
        scale_x_continuous('\nAthwartship Beam Angle (deg)',limits = cal.axis.lims,
                           breaks = seq(min(cal.axis.lims), max(cal.axis.lims), 2)) +
        scale_y_continuous('Alongship Beam Angle (deg)\n',limits = cal.axis.lims,
                           breaks = seq(min(cal.axis.lims), max(cal.axis.lims), 2)) +
        guides(size =  "none") + theme_bw() + 
        theme(panel.spacing    = unit(1, "lines"),
              strip.background = element_rect(fill = "white"),
              strip.text.x     = element_text(face = "bold")) + 
        coord_equal()
      
      # Plot beam-compensated target strength data #####
      tsc.scatter <- ggplot(filter(cal.pings, outlier == 0), aes(athw, along)) +
        geom_point(aes(fill = relTS_c_scaled), shape = 21) + 
        geom_point(data = filter(cal.pings, outlier == 1), aes(athw, along),
                   shape = "+", size = 4) +
        facet_wrap(~txdr_type, scales = cal.scales) + 
        scale_fill_distiller(name = expression(italic(TS)[rel]),
                             type = "div", palette = "RdBu", limits = c(-1,1)) +
        scale_x_continuous('\nAthwartship Beam Angle (deg)', limits = cal.axis.lims,
                           breaks = seq(min(cal.axis.lims), max(cal.axis.lims), 2)) +
        scale_y_continuous('Alongship Beam Angle (deg)\n',limits = cal.axis.lims,
                           breaks = seq(min(cal.axis.lims), max(cal.axis.lims), 2)) +
        theme_bw() + 
        theme(panel.spacing = unit(1, "lines"),
              strip.background = element_rect(fill = "white"),
              strip.text.x = element_text(face = "bold")) +
        coord_equal()
      
    } else {
      # Plot beam-uncompensated target strength data #####
      tsu.scatter <- ggplot(filter(cal.pings, outlier == 0), aes(athw, along)) +
        geom_point(aes(colour = TS_u)) + 
        geom_point(data = filter(cal.pings, outlier == 1), aes(athw, along), 
                   shape = "+", size = 1, alpha = 0.7) +
        facet_wrap(~txdr_type, scales = cal.scales) +
        scale_colour_viridis(name = expression(paste(italic(TS)[u]," (dB)",sep = "")),
                             option = "magma") +
        scale_x_continuous('\nAthwartship Beam Angle (deg)') +
        scale_y_continuous('Alongship Beam Angle (deg)\n') +
        guides(size =  "none") + theme_bw() + 
        theme(panel.spacing    = unit(1, "lines"),
              strip.background = element_rect(fill = "white"),
              strip.text.x     = element_text(face = "bold")) 
      
      # Plot beam-compensated target strength data #####
      tsc.scatter <- ggplot(filter(cal.pings, outlier == 0), aes(athw, along)) +
        geom_point(aes(fill = relTS_c_scaled), shape = 21, colour = "gray70") + 
        geom_point(data = filter(cal.pings, outlier == 1), aes(athw, along),
                   shape = "+", size = 4) +
        facet_wrap(~txdr_type, scales = cal.scales) + 
        scale_fill_distiller(name = expression(italic(TS)[rel]),
                             type = "div", palette = "RdBu", limits = c(-1,1)) +
        scale_x_continuous('\nAthwartship Beam Angle (deg)') +
        scale_y_continuous('Alongship Beam Angle (deg)\n') +
        theme_bw() + 
        theme(panel.spacing = unit(1, "lines"),
              strip.background = element_rect(fill = "white"),
              strip.text.x = element_text(face = "bold")) 
    }
    
    # Define figure widths based on vessel so that plots are relatively square
    fig.width <- switch(i,
                        "RL" = 10,
                        "LM" = 11.5,
                        "LBC" = 7)
    
    # Save TS_c plot 
    ggsave(tsu.scatter, filename = here(paste("Figs/fig_cal_TSu_scatter_", i, ".png", sep = '')),  
           width = fig.width, height = 6)
    
    # Save TS_c plot 
    ggsave(here(paste("Figs/fig_cal_TSrel_scatter_", i, ".png", sep = '')), tsc.scatter,
           width = fig.width, height = 6)
  }
}
```

```{r plot-cal-fm}
if (process.cal.FM) {
  if (save.figs) {
    # Plot FM calibration results
    source(here("Code/plot_CalFM_2207RL.R"))
  }  
}
```

```{r create-basemap,include=F}
# Configure base map options -----------------
# Import landmarks
locations <- filter(read.csv(here("Data/Map/locations.csv")), name %in% label.list) %>%
  project_df(to = crs.proj)

# Get state data
states <- ne_states(country = 'United States of America', returnclass = 'sf')
ca     <- filter(states, name == "California")

# Get countries
countries <- ne_countries(scale = "large", returnclass = "sf") %>%
  filter(subregion %in% c("Northern America","Central America"))

# Read bathy contours shapefile 
bathy <- st_read(here("Data/GIS/bathy_contours.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = Contour)

# If resize.map = T, then set map boundaries based on current navigation progress
if (resize.map) {
  # Use nav data to resize map to survey progress
  map.bounds <- nav.sf %>% 
    st_transform(crs = crs.proj) %>%
    st_bbox() 
  
# Otherwise, set map boundaries to the entire planned transect area
} else {
  
  # If the survey contains multiple core-area vessels, such as in 2021 when
  # Lasker and Carranza split transects, then combine those vessels
  if (survey.name %in% c("2107RL")) {
    # Use combined planned transects
    map.bounds <- transects.jcf %>% 
      select(Type) %>% 
      bind_rows(transects.sf) %>% 
      st_transform(crs = crs.proj) %>%
      st_bbox()
    
  # Otherwise use the planned transects from just Lasker
  } else {
    # Use planned transects
    map.bounds <- transects.sf %>%
      st_transform(crs = crs.proj) %>%
      st_bbox()
  }
}

# Determine map aspect ratio and set height and width
map.aspect <- (map.bounds$xmax - map.bounds$xmin)/(map.bounds$ymax - map.bounds$ymin)
map.height <- 10
map.width  <- map.height*map.aspect

# Create base map
base.map <- atm::get_basemap(nav.paths.sf, states, countries, locations, bathy, map.bounds, crs = crs.proj) +
  # Add scalebar
  annotation_scale(style = "ticks", location = "br", height = unit(0.15, "cm"))

# Save the basemap
ggsave(base.map,file = here("Figs/fig_basemap.png"), 
       height = map.height, width = map.width)

save(base.map, file = here("Data/Map/basemap.Rdata"))
```

```{r process-scs}
if (process.scs) {
  if (scs.source == "CSV") {
    # Process bridge event data #####
    bridge.events <- list.files(here("Data/SCS"), pattern = scs.pattern,
                                full.names = T, recursive = T)  
    # Import from CSV
    bridge.snap <- fs::path(here("Data/SCS")) %>% 
      dir_ls(regexp = scs.pattern) %>% 
      map_df(read_csv) %>% 
      select(Date, Time, Button, Notes = all_of(notes.hdr), 
             Lat = all_of(gps.lat.hdr), Lon = all_of(gps.lon.hdr))
    
  } else if (scs.source == "ELG") {
    # Process bridge event data 
    bridge.events <- list.files(here("Data/SCS"), pattern = "MOA Snap.*elg",
                                full.names = T, recursive = T)
    # create temporary df
    bridge.snap <- data.frame()
    # read and rbind all files
    for (i in bridge.events) {
      bridge.snap.tmp <- read_csv(i) %>% 
        select(Date, Time, Button, Notes = all_of(notes.hdr), 
               Lat = all_of(gps.lat.hdr), Lon = all_of(gps.lon.hdr))
      
      bridge.snap <- bind_rows(bridge.snap, bridge.snap.tmp)
    }
  } else if (scs.source == "XLSX") {
    # Process bridge event data #####
    bridge.events <- dir_ls(here("Data/SCS"), regexp = scs.pattern)
    
    bridge.snap <- tibble()
    
    for (b in bridge.events) {
      moa.tmp <- read_xlsx(bridge.events[b]) %>% 
        mutate(Time = as.character(gsub(".* ", "", Time)),
               datetime = Date + hms(Time)) %>% 
        select(Date, Time, Button, Notes = all_of(notes.hdr), 
               Lat = all_of(gps.lat.hdr), Lon = all_of(gps.lon.hdr), datetime) 
      
      bridge.snap <- bind_rows(bridge.snap, moa.tmp)
    }
  }
  
  # Format data
  bridge.snap <- bridge.snap %>% 
    filter(Lon != "", Lat != "") %>% 
    mutate(Lat      = as.numeric(substr(Lat, 1, 2)) + 
             as.numeric(substr(Lat, 3, 7))/60,
           Lon      = -(as.numeric(substr(Lon, 1, 3)) +
                          as.numeric(substr(Lon, 4, 8))/60),
           Button = case_when(
             Button == cb.flush.button ~ "Retracted (5 m)",
             Button == cb.int.button ~  "Intermediate (7 m)",
             Button == cb.ext.button ~  "Extended (9 m)",
             TRUE ~ Button)) %>% 
    arrange(datetime) %>% 
    mutate(datetime =  format(datetime, format = "%m/%d/%Y %H:%M")) 
  
  # save processed SCS data
  save(bridge.snap, file = here("Data/SCS/processed_logs.Rdata"))
} else {
  # load processed SCS data
  load(here("Data/SCS/processed_logs.Rdata"))
}
```

```{r import-trawl-data}
if (get.db) {
  # An installation of Microsoft Access Database Engine Redistributable is required
  # for the Access version. It may be downloaded here: 
  # https://www.microsoft.com/en-us/download/details.aspx?id=54920
  
  if (trawl.source == "SQL") {
    # Configure ODBC connection to TRAWL database
    trawl.con  <- odbc::dbConnect(odbc::odbc(), 
                                  Driver = "SQL Server", 
                                  Server = "161.55.235.187", 
                                  Database = "TRAWL", 
                                  Trusted_Connection = "True")
  } else if (trawl.source == "Access") {
    trawl.con  <- odbc::dbConnect(odbc::odbc(), 
                                  Driver = "Microsoft Access Driver (*.mdb, *.accdb)", 
                                  DBQ = file.path(here("Data/Trawl"), trawl.db.access))
  }
  
  # Import trawl database tables
  catch.all	     <- tbl(trawl.con,"Catch") %>% collect()
  haul.all       <- tbl(trawl.con,"Haul") %>% collect()
  lengths.all    <- tbl(trawl.con,"Specimen") %>% collect()
  lengthFreq.all <- tbl(trawl.con,"LengthFrequency") %>% collect()
  spp.codes      <- tbl(trawl.con,"SpeciesCodes") %>% collect()
  
  # Close database channel
  dbDisconnect(trawl.con)
  
  # Save imported database data to .Rdata file
  save(catch.all, haul.all, lengths.all, spp.codes, lengthFreq.all, 
       file = here("Data/Trawl/trawl_data.Rdata"))
} else {
  load(here("Data/Trawl/trawl_data.Rdata"))
}
```

```{r process-trawl-haul-data}
# Create startLatitudeDecimal and startLongitudeDecimal for Access data
if (trawl.source == "Access") {
  # Reformat haul data to match SQL
  haul.all <- haul.all %>% 
    mutate(
      startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
      startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
      stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
      stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60)), 
      haulBackTime     = haulbackTime,
      equilibriumTime  = EquilibriumTime) %>% 
    mutate(haulbackTime = case_when(
      haulBackTime < equilibriumTime ~ haulBackTime + days(1),
      TRUE ~ haulBackTime)) %>%
    rename(cruise = Cruise, ship = Ship, haul = Haul, 
           collection = Collection, notes = Notes)
  
  # Identify hauls where date of equilibriumTime or haulBackTime is incorrect
  eq.fix <- which(c(0, diff(haul.all$equilibriumTime)) < 0)
  hb.fix <- which(c(0, diff(haul.all$haulBackTime)) < 0)
  
  # Correct equilibriumTime or haulBackTime
  haul.all$equilibriumTime[eq.fix] <- haul.all$equilibriumTime[eq.fix] + days(1)
  haul.all$haulBackTime[eq.fix]    <- haul.all$haulBackTime[eq.fix] + days(1)
  
  # Reformat length frequency data to match SQL
  lengths.all <- lengths.all %>% 
    rename(cruise = Cruise, ship = Ship, haul = Haul, 
           collection = Collection, species = Species)
  
  # Reformat length frequency data to match SQL
  lengthFreq.all <- lengthFreq.all %>% 
    rename(cruise = Cruise, ship = Ship, haul = Haul, collection = Collection, 
           species = Species, length = Length, lengthType = LengthType, 
           sexUnknown = NotDetermined, male = Male, activeFemale = ActiveFemale, 
           inactiveFemale = InactiveFemale, totalFemale = TotalFemale, 
           subSampleNumber = SubSampleNumber)
} else if (trawl.source == "SQL") {
  haul.all <- haul.all %>% 
    mutate(
      equilibriumTime = ymd_hms(equilibriumTime),
      haulBackTime    = ymd_hms(haulBackTime))
}

# Classify hauls by season (spring or summer)
haul.all <- haul.all %>% 
  mutate(season = case_when(
    month(equilibriumTime) < 6 ~ "spring",
    TRUE ~ "summer"))

# Filter haul data for current survey
haul <- haul.all %>% 
  select(cruise, ship, haul, collection, startLatDecimal, startLongDecimal, 
         stopLatDecimal, stopLongDecimal, equilibriumTime, haulBackTime, 
         trawlPerformance, season, notes) %>% 
  filter(cruise %in% cruise.name & ship %in% cruise.ship) %>%
  # Calculate haul duration
  mutate(duration = difftime(haulBackTime, equilibriumTime, units = "mins")) %>% 
  # Remove bad trawls
  filter(!trawlPerformance %in% trawl.performance) %>% 
  # Assign cluster based on yearday
  mutate(cluster = cumsum(c(0, diff(equilibriumTime)) > 12) + 1) %>% 
  droplevels() # Remove unused factor levels

if (survey.name %in% c("2107RL")) {
  # Get max haul and cluster for Lasker to increment Carranza data
  max.cluster.rl <- max(haul$cluster)
  max.haul.rl <- max(haul$haul)
  
  # Get Carranza data during 
  haul.jcf <- read_csv(here("Data/Trawl/JCFINP2110_haul_bitacore.csv")) %>% 
    mutate(cruise = as.character(cruise.name),
           ship = "JCF",
           equilibriumTime = with_tz(dmy_hm(startDateLocalTime, tz = "America/Los_Angeles"), 
                                     tzone = "UTC"),
           haulBackTime = with_tz(dmy_hm(stopDateLocalTime, tz = "America/Los_Angeles"), 
                                  tzone = "UTC"),
           collection = haul,
           trawl.performance = NA,
           season = case_when(
             month(equilibriumTime) < 6 ~ "spring",
             TRUE ~ "summer"), 
           notes = NA,
           duration = difftime(haulBackTime, equilibriumTime, units = "mins"),
           cluster = cumsum(c(0, diff(equilibriumTime)) > 12) + 1) %>% 
    mutate(haul = haul + max.haul.rl,
           cluster = cluster + max.cluster.rl)  %>% 
    select(cruise, ship, haul, collection, startLatDecimal, startLongDecimal,
           stopLatDecimal, stopLongDecimal, equilibriumTime, haulBackTime,
           trawl.performance:cluster) 
  
  # ggplot(haul.jcf, aes(startLongDecimal, startLatDecimal)) + geom_point() + coord_map()
  
  haul <- bind_rows(haul, haul.jcf)
  
  # ggplot(haul, aes(startLongDecimal, startLatDecimal, colour = ship)) + 
  #   geom_point() + 
  #   coord_map()  
}

# # Get haul starts
# Find midpoint of each haul as the mean lat/lon
haul.mid <- haul %>% 
  group_by(cluster, haul) %>% 
  summarise(
    lat  = mean(c(startLatDecimal, stopLatDecimal)),
    long = mean(c(startLongDecimal, stopLongDecimal)))

# Convert haul paths and midpoints to sf; CRS = crs.geog
# Create haul paths from starts and ends
haul.paths <- select(haul, haul, lat = startLatDecimal, long = startLongDecimal) %>% 
  bind_rows(select(haul, haul, lat = stopLatDecimal, long = stopLongDecimal)) %>% 
  arrange(haul) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  group_by(haul) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING") 

haul.locs.sf <- haul.mid %>% 
  mutate(label = paste("Haul", haul)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

# Find midpoint of each haul cluster as the average of haul midpoints
cluster.mid <- haul.mid %>% 
  group_by(cluster) %>% 
  summarise(
    lat  = mean(lat),
    long = mean(long))  

# Save haul data
save(haul, file = here("Output/haul_info.Rdata"))
``` 

```{r process-catch-data}
# Filter catch data
catch <- catch.all %>% 
  left_join(dplyr::select(spp.codes, species, scientificName, commonName)) %>% 
  filter(cruise %in% cruise.name & ship %in% cruise.ship & 
           scientificName %in% cps.spp & netSampleType == 'codend') %>% 
  left_join(dplyr::select(haul, haul, cluster)) %>% 
  mutate(key = paste(haul, scientificName),
         totalWeight = subSampleWtkg + remainingSubSampleWtkg)

if (survey.name %in% c("2107RL")) {
  # Read and process catch data from Carranza
  catch.jcf <- read_csv(here("Data/Trawl/JCFINP2110_catch.csv")) %>% 
    mutate(
      cruise      = as.character(cruise.name),
      collection  = haul,
      haul        = haul + max.haul.rl,
      totalWeight = subSampleWtkg + remainingSubSampleWtkg,
      totalNum    = (subSampleCount/subSampleWtkg)*totalWeight,
      key         = paste(haul, scientificName)) %>% 
    left_join(select(spp.codes, scientificName, commonName, species)) %>% 
    left_join(select(haul, haul, cluster))
  
  # Combine catch data from each vessel
  catch <- bind_rows(catch, catch.jcf)
}

if (nrow(catch) > 0) {
  # Summarize trawl catch by species
  haul.summ.wt <- catch %>% 
    select(haul, cluster, scientificName, totalWeight) %>% 
    tidyr::spread(scientificName, totalWeight) 
  
  # Add species with zero total weight
  if (!has_name(haul.summ.wt, "Engraulis mordax"))      {haul.summ.wt$`Engraulis mordax`      <- 0}
  if (!has_name(haul.summ.wt, "Sardinops sagax"))       {haul.summ.wt$`Sardinops sagax`       <- 0}
  if (!has_name(haul.summ.wt, "Scomber japonicus"))     {haul.summ.wt$`Scomber japonicus`     <- 0}
  if (!has_name(haul.summ.wt, "Trachurus symmetricus")) {haul.summ.wt$`Trachurus symmetricus` <- 0}
  if (!has_name(haul.summ.wt, "Clupea pallasii"))       {haul.summ.wt$`Clupea pallasii`       <- 0}
  if (!has_name(haul.summ.wt, "Atherinopsis californiensis")) {haul.summ.wt$`Atherinopsis californiensis` <- 0}
  if (!has_name(haul.summ.wt, "Etrumeus acuminatus"))   {haul.summ.wt$`Etrumeus acuminatus` <- 0}
  
  # Calculate total weight of all CPS species
  haul.summ.wt <- haul.summ.wt %>%  
    replace(is.na(.), 0) %>% 
    mutate(AllCPS = rowSums(select(., -haul, -cluster))) %>%
    # mutate(AllCPS = rowSums(.[, 3:ncol(.)])) %>%
    rename("Jacksmelt"  = "Atherinopsis californiensis",
           "PacHerring" = "Clupea pallasii",
           "Anchovy"    = "Engraulis mordax",
           "Sardine"    = "Sardinops sagax",
           "PacMack"    = "Scomber japonicus",
           "JackMack"   = "Trachurus symmetricus",
           "RndHerring" = "Etrumeus acuminatus") 
  
  # Summarise catch by cluster
  cluster.summ.wt <- haul.summ.wt %>% 
    select(-haul, -AllCPS) %>% 
    group_by(cluster) %>% 
    summarise_all(list(sum)) %>% 
    mutate(AllCPS = rowSums(select(., -cluster))) %>% 
    right_join(cluster.mid) %>% 
    replace(is.na(.), 0)
  
  # Add lat/long to haul summary for plotting
  haul.summ.wt <- haul.summ.wt %>% 
    right_join(haul.mid) %>% 
    replace(is.na(.), 0)
  
} else {
  # Summarize trawl catch by species
  haul.summ.wt <- bind_cols(select(haul, haul, cluster),
                            data.frame(
                              "Jacksmelt"  = rep(0, nrow(haul)),
                              "PacHerring" = rep(0, nrow(haul)),
                              "Anchovy"    = rep(0, nrow(haul)),
                              "Sardine"    = rep(0, nrow(haul)),
                              "PacMack"    = rep(0, nrow(haul)),
                              "JackMack"   = rep(0, nrow(haul)),
                              "RndHerring" = rep(0, nrow(haul)),
                              "AllCPS"     = rep(0, nrow(haul)))) %>% 
    right_join(haul.mid)
  
  # Summarise catch by cluster
  cluster.summ.wt <- haul.summ.wt %>% 
    select(-haul, -AllCPS) %>% 
    group_by(cluster) %>% 
    summarise_all(list(sum)) %>% 
    mutate(AllCPS = rowSums(select(., -cluster))) %>%
    right_join(cluster.mid) %>% 
    replace(is.na(.), 0)
}

# Prepare catch data for plotting ----------------------------------------------
# Select and rename trawl data for pie charts
haul.pie <- haul.summ.wt %>% 
  select(haul, long, lat, Anchovy, JackMack, RndHerring,
         Jacksmelt, PacHerring, PacMack, Sardine, AllCPS) %>% 
  mutate(bin       = cut(AllCPS, trawl.breaks, include.lowest = TRUE),
         bin.level = as.numeric(bin)) %>% 
  project_df(to = crs.proj) %>% 
  mutate(
    label = paste("Haul", haul),
    popup = paste('<b>Cluster:', haul, '</b><br/>',
                  'Anchovy:', Anchovy, 'kg<br/>',
                  'Sardine:', Sardine, 'kg<br/>',
                  'Jack Mackerel:', JackMack, 'kg<br/>',
                  'P. herring:', PacHerring, 'kg<br/>',
                  'P. mackerel:', PacMack, 'kg<br/>',
                  'R. herring:', RndHerring, 'kg<br/>',
                  'All CPS:', AllCPS, 'kg'))

cluster.pie <- cluster.summ.wt %>% 
  select(cluster, long, lat, Anchovy, JackMack, RndHerring,
         Jacksmelt, PacHerring, PacMack, Sardine, AllCPS) %>% 
  mutate(bin       = cut(AllCPS, trawl.breaks, include.lowest = TRUE),
         bin.level = as.numeric(bin)) %>% 
  project_df(to = crs.proj) %>% 
  mutate(
    label = paste("Cluster", cluster),
    popup = paste('<b>Cluster:', cluster, '</b><br/>',
                  'Anchovy:', Anchovy, 'kg<br/>',
                  'Sardine:', Sardine, 'kg<br/>',
                  'Jack Mackerel:', JackMack, 'kg<br/>',
                  'P. herring:', PacHerring, 'kg<br/>',
                  'P. mackerel:', PacMack, 'kg<br/>',
                  'R. herring:', RndHerring, 'kg<br/>',
                  'All CPS:', AllCPS, 'kg'))

# Filter for empty trawls
haul.zero    <- filter(haul.pie, AllCPS == 0)

# Filter for empty trawls
haul.zero    <- filter(haul.pie, AllCPS == 0)

cluster.zero <- filter(cluster.pie, AllCPS == 0)

# Calculate pie radius based on latitude range
pie.radius <- as.numeric(abs(map.bounds$ymin - map.bounds$ymax)*pie.scale)

# Calculate pie radius of each pie, based on All CPS landings
# Calculate pie radius of each pie, based on All CPS landings
if (scale.pies) {
  haul.pie$r    <- pie.radius*log(haul.pie$bin.level+1)
  cluster.pie$r <- pie.radius*log(cluster.pie$bin.level+1)
} else {
  haul.pie$r    <- pie.radius
  cluster.pie$r <- pie.radius
}

# Filter for positive hauls and clusters
haul.pos <- filter(haul.pie, AllCPS > 0) %>% 
  arrange(X)

cluster.pos <- filter(cluster.pie, AllCPS > 0) %>% 
  arrange(X)

# Substitute very small value for species with zero catch, just for pie charts
if (nrow(haul.pos) > 0) {
  haul.pos <- haul.pos %>% 
    replace(. == 0, 0.0000001) 
  
  cluster.pos <- cluster.pos %>% 
    replace(. == 0, 0.0000001) 
}

# Convert haul data for plotting
haul.catch <- haul.summ.wt %>% 
  project_df(to = crs.proj)

# sum total weight of sardine, anchovy, and mackerel
haul.Anchovy.kg    <- sum(haul.catch$Anchovy, na.rm = T)
haul.Sardine.kg    <- sum(haul.catch$Sardine, na.rm = T)
haul.PacMack.kg    <- sum(haul.catch$PacMack, na.rm = T)
haul.JackMack.kg   <- sum(haul.catch$JackMack, na.rm = T)
haul.PacHerring.kg <- sum(haul.catch$PacHerring, na.rm = T)
haul.RndHerring.kg <- sum(haul.catch$RndHerring, na.rm = T)
haul.CPS.kg        <- sum(haul.Anchovy.kg, haul.Sardine.kg, haul.PacMack.kg,
                          haul.JackMack.kg, haul.PacHerring.kg, haul.RndHerring.kg, 
                          na.rm = T)

# summarize trawl haul data
trawl.summ <- haul.catch %>% 
  left_join(select(haul, haul, Date = equilibriumTime, Latitude = startLatDecimal,
                   Longitude = startLongDecimal)) %>% 
  select(Haul = haul, Date, Latitude, Longitude, "N. Anchovy" = Anchovy, "P. Sardine" = Sardine, 
         "P. Mackerel" = PacMack, "J. Mackerel" = JackMack, "P. Herring" = PacHerring, 
         "R. Herring" = RndHerring, 
         Jacksmelt, "All CPS" = AllCPS) %>% 
  mutate(Date = format(Date, "%m/%d/%Y %H:%M"))
```

```{r process-cufes}
# Read CUFES data
cufes.filename <- list.files(here("Data/CUFES"), pattern = "*.sqlite")
cufes.con      <- odbc::dbConnect(SQLite(), dbname = here("Data/CUFES", cufes.db.sqlite))
cufes.all      <- tbl(cufes.con, "cufessqlite") %>%
  collect() %>% 
  mutate(
    Start = case_when(
      cufes.date.format == "mdy" ~ mdy_hms(Start), #"06/01/2019-15:43:00"
      cufes.date.format == "ymd" ~ ymd_hms(Start)),#"1996-03-15 15:43:00 -08:00"
    Stop = case_when(
      cufes.date.format == "mdy" ~ mdy_hms(Stop), #"06/01/2019-15:43:00"
      cufes.date.format == "ymd" ~ ymd_hms(Stop)),#"1996-03-15 15:43:00 -08:00"
    Duration = as.numeric(difftime(Stop, Start, units = "mins")),
    Year = year(Start),
    AllEggs = SardineEggs + AnchovyEggs + JackMackerelEggs) %>% 
  rename(lat = StartLatitude, long = StartLongitude) %>% 
  filter(!is.na(lat), !is.na(long)) %>% 
  project_df(to = crs.proj)

# Close connection
dbDisconnect(cufes.con)

# save raw cufes table to CSV
write.csv(cufes.all, file = here("Output/cufes_raw.csv"), 
          quote = F, row.names = F)

# Process CUFES data
cufes <- cufes.all %>% 
  # Convert cufes to long format for plotting
  select(
    SampleNumber, Year, Ship, Cruise, lat, long, X, Y, Duration, 
    SardineEggs, AnchovyEggs, JackMackerelEggs, SquidEggs, HakeEggs, OtherFishEggs,
    Comments) %>%
  gather(Species, Counts, -SampleNumber, -Year, -Ship, -Cruise, 
         -lat, -long, -X, -Y, -Duration, -Comments) %>% 
  mutate(Density = Counts/Duration/0.64,
         # Create bins for defining point size in NASC plots
         bin = cut(Density, cufes.breaks, include.lowest = T),
         bin.level = as.numeric(bin)) %>% 
  left_join(select(cufes.all, SampleNumber, Start, Stop)) 


if (survey.name %in% c("2107RL")) {
  # Import and format CUFES data from Carranza
  cufes.jcf.all <- read_csv(here("Data/CUFES/cufes_jcfinp2110_rev.csv")) %>% 
    mutate(Start = with_tz(dmy_hms(paste(date, startLocalTime), tz = "America/Los_Angeles"), tzone = "UTC"),
           Stop  = with_tz(dmy_hms(paste(date, stopLocalTime), tz = "America/Los_Angeles"), tzone = "UTC"),
           Ship  = "JCF",
           Cruise = as.character(cruise.name),
           Duration = as.numeric(difftime(Stop, Start, units = "mins")),
           Year = year(Start),
           AllEggs = SardineEggs + AnchovyEggs + JackMackerelEggs) %>% 
    rename(lat = startLatDecimal,
           long = startLongDecimal) %>% 
    project_df(to = crs.proj) 
  
  # Convert to long form
  cufes.jcf <- cufes.jcf.all %>% 
    select(
      SampleNumber, Year, Ship, Cruise, lat, long, X, Y, Duration, 
      SardineEggs, AnchovyEggs, JackMackerelEggs, SquidEggs, HakeEggs, OtherFishEggs,
      Comments) %>% 
    gather(Species, Counts, -SampleNumber, -Year, -Ship, -Cruise, 
           -lat, -long, -X, -Y, -Duration, -Comments) %>% 
    mutate(Density = Counts/Duration/0.64,
           # Create bins for defining point size in NASC plots
           bin = cut(Density, cufes.breaks, include.lowest = T),
           bin.level = as.numeric(bin)) %>% 
    left_join(select(cufes.jcf.all, SampleNumber, Start, Stop))
  
  # Combine with CUFES data from Lasker
  cufes     <- bind_rows(cufes, cufes.jcf)
  cufes.all <- bind_rows(cufes.all, cufes.jcf.all)
  
  # ggplot(cufes, aes(long, lat, colour = Ship)) + geom_point() + coord_map()
}

# Save processed cufes to CSV
write.csv(cufes, file = here("Output/cufes_proc.csv"), 
          quote = F, row.names = F)

# Prepare CUFES data for plotting ----------------------------------------------
# Select CUFES sample with zero density for plotting
cufes.neg <- filter(cufes.all, AllEggs == 0) %>% 
  mutate(bin.level = 1) %>% 
  select(X, Y, SampleNumber)

# Identify bad CUFES samples
cufes.bad <- filter(cufes.all, Duration <= 0)

save(cufes.bad, file = here("Output/cufes_bad.Rdata"))

# Remove bad samples from CUFES
cufes <- cufes %>% 
  filter(!SampleNumber %in% cufes.bad$SampleNumber)

# Write CUFES data from current survey to CSV
write.csv(cufes, file = here("Output/cufes_data.csv"), quote = F)

# Create bins for defining point size in NASC plots
cufes <- cufes %>% 
  mutate(bin = cut(Density, cufes.breaks, include.lowest = T),
         bin.level = as.numeric(bin))

# Project CUFES data from CPS
cufes.plot <- cufes %>% 
  filter(Density > 0, Species %in% cufes.plot.spp) %>%
  arrange(desc(Density))

# Project CUFES data from squid
cufes.plot.squid <- cufes %>% 
  filter(Density > 0, Species == "SquidEggs") %>% 
  arrange(desc(Density))

# Project CUFES data from other fish eggs (mostly P. mackerel)
cufes.plot.ofe <- cufes %>% 
  filter(Density > 0, Species == "OtherFishEggs") %>%
  filter(str_detect(Comments, "japonicus")) %>% 
  arrange(desc(Density))
```  

```{r process-ctd-stations}
# Extract CTD and UCTD cast locations
events_sf <- st_as_sf(bridge.snap, coords = c("Lon","Lat"), crs = crs.geog)

ctd.sta         <- filter(events_sf, Button == ctd.button)
uctd.sta        <- filter(events_sf, Button == uctd.button)

# Append CTD cast locations from other survey vessels
if (survey.name %in% c("2107RL")) {
  
  # Read Carranza stations
  ctd.jcf <- read_csv(here("Data/CTD/ctd_stations_jcf.csv")) %>% 
    mutate(Button = "CTD") 
  
  ctd.jcf.sf <- ctd.jcf %>% 
    st_as_sf(coords = c("long", "lat"), crs = crs.geog)
  
  # Combine with Lasker casts
  if (nrow(ctd.sta) == 0) {
    ctd.sta <- ctd.jcf.sf  
  } else {
    ctd.sta <- bind_rows(ctd.sta, ctd.jcf.sf)  
  }  
  
  # Create datetime column
  ctd.jcf <- ctd.jcf %>%
    mutate(datetime = format(mdy_hms(paste(Date, Time)), format = "%m/%d/%Y %H:%M"))
  
}

# Extract bongo locations
bongo.sta       <- filter(events_sf, Button == bongo.button)

# Extract pairovet locations
pairovet.sta    <- filter(events_sf, Button == pairovet.button)

# Extract all CTD/UCTD stations
all.ctds        <- bind_rows(filter(bridge.snap, Button == ctd.button),
                             filter(bridge.snap, Button == uctd.button)) %>% 
  arrange(datetime) %>% 
  select(Date = datetime, Button, Latitude = Lat, Longitude = Lon) %>% 
  mutate(Button = case_when(
    Button == ctd.button ~ "CTD Cast",
    Button == uctd.button ~ "UCTD Cast", 
    TRUE ~ Button))

# Append CTD info from other survey vessels
if (survey.name %in% c("2107RL")) {
  all.ctds <- all.ctds %>% 
    bind_rows(select(ctd.jcf, Date = datetime, Button = Button, Latitude = lat, Longitude = long))
}
```  

```{r process-csv-cps}
# Process backscatter data (CSV files) for CPS
source(here("Code/process_NASC.R"))

# Get intervals with bad lat/long values
bad.nasc <- filter(nasc, lat == 999, long == 999)
write_csv(bad.nasc, here("Output/nasc_bad_cps.csv"))

# Summarize nasc for reporting effort
nasc.summ <- nasc %>% 
  group_by(transect.name, transect) %>% 
  summarise(
    distance = length(Interval)*100/1852,
    lat = lat[which.min(long)],
    lon = long[which.min(long)])

# average NASC.70 data over new intervals or number of intervals in a 2 km radius
nasc.summ.cps <- nasc %>%
  filter(lat != 999, long != 999) %>% 
  group_by(transect.name, transect, int) %>%
  summarise(
    bins    = length(int),
    bin.mid = as.integer(round(bins / 2)),
    lat     = lat[1],
    long    = long[1],
    NASC    = mean(cps.nasc)
  )

# Average cps.nasc over defined interval
# Summarize by filename, not transect, so that renamed (i.e., strip.tx.chars == T) transects get included.
nasc.sf <- nasc %>%
  filter(lat != 999, long != 999) %>%
  # arrange(filename, datetime) %>% 
  select(filename, transect.name, transect, int, dist_m, datetime, lat, long, cps.nasc) %>% 
  group_by(filename, transect.name, transect, int) %>% 
  summarise(
    lat   = lat[1],
    long  = long[1],
    NASC  = mean(cps.nasc),
    label = paste0('Transect: ', transect[1], "; ",
                   'Distance: ', round(min(dist_m)), "-", round(max(dist_m)), ' m'),
    popup = paste0('<b>Transect: </b>', transect[1], '<br/>',
                   '<b>Time: </b>', min(datetime), " - ", max(datetime), ' UTC<br/>',
                   '<b>Distance: </b>', round(min(dist_m)), "-", round(max(dist_m)), ' m<br/>',
                   '<b>NASC: </b>', round(mean(NASC)), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>%
  # Create bins for defining point size in NASC plots
  mutate(bin       = cut(NASC, nasc.breaks, include.lowest = T),
         bin.level =  as.numeric(bin)) %>% 
  filter(!is.na(bin)) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) 

nasc.plot.cps <- project_sf(nasc.sf, crs.proj)

# Convert acoustic transects to sf
nasc.tx.sf <- st_as_sf(nasc.sf, coords = c("long","lat"), crs = crs.geog) %>% 
  select(transect.name, transect) %>% 
  group_by(transect.name, transect) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING") %>% 
  filter(!transect %in% tx.rm)

# create acoustic transect labels
nasc.tx.labels.cps <- nasc %>%
  group_by(transect.name, transect) %>%
  summarise(
    lat = lat[which.max(long)],
    long = max(long)
  )

# List already processed CSV files and save
processed.cps <- unique(nasc$filename)
save(processed.cps, file =  here("Output/processed_cps.Rdata"))
```

```{r plot-maps, include=F}
if (save.figs) {
  # Map planned transects
  survey.plan <- base.map +    
    geom_sf(data = transects.sf, aes(colour = Type, linetype = Type), 
            show.legend = "line") +
    scale_colour_manual("Type", values = wpt.colors) +
    scale_linetype_manual(name = "Type", values = wpt.linetypes) +
    coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
             xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
             ylim = c(map.bounds["ymin"], map.bounds["ymax"]))
  
  # save survey plan map
  ggsave(here("Figs/fig_survey_plan.png"), survey.plan,
         height = map.height, width = map.width)
  
  if (survey.name %in% c("2107RL")) {
    # Map planned transects
    survey.plan.mx <- base.map +    
      geom_sf(data = transects.sf, aes(colour = Type, linetype = Type), 
              show.legend = "line") +
      geom_sf(data = transects.jcf, aes(colour = Type, linetype = Type), 
              show.legend = "line") +
      # geom_sf(data = nav.paths.sf, colour = "gray50", size = 1, alpha = 0.5) +
      # geom_sf(data = nav.paths.jcf.sf, colour = "gray50", size = 1, alpha = 0.5) +
      scale_colour_manual("Type", 
                          values = wpt.colors) +
      scale_linetype_manual("Type", 
                            values = wpt.linetypes) +
      coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
               xlim = unname(c(map.bounds["xmin"], map.bounds["xmax"])), 
               ylim = unname(c(map.bounds["ymin"], map.bounds["ymax"])))
    
    # save survey plan map
    ggsave(here("Figs/fig_survey_plan_mx.png"), survey.plan.mx,
           height = map.height, width = map.width)
  }

  # Plot Survey Track, Acoustic Transects, and Trawl Locations #####
  survey.track.map <- base.map +
    # Plot transects data
    geom_sf(data = transects.sf, aes(linetype = Type), colour = "gray70",
            show.legend = "line") +
    # Plot ship track data
    geom_sf(data = nav.paths.sf, colour = "gray50", size = 0.5, alpha = 0.5) +
    # Plot acoustic transects
    geom_sf(data = nasc.tx.sf, size = 1) +
    # Plot trawl transects
    geom_point(data = haul.catch, aes(X, Y),
               shape = 21, colour = "black", fill = "white", size = 1.5) +
    scale_linetype_manual("Type", 
                          values = c(Adaptive = "dashed", Compulsory = "solid",
                                     Offshore = "dashed", Nearshore = "dotted",
                                     transit = "dashed")) +
    coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
             xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
             ylim = c(map.bounds["ymin"], map.bounds["ymax"]))
  
  # save figure as PNG and PDF images
  ggsave(here("Figs/fig_vessel_track.png"), survey.track.map,
         height = map.height, width = map.width)
  
  # Plot Side Station Sampling Locations #####
  survey.station.map <- base.map +
    # Plot transects data
    geom_sf(data = transects.sf, aes(linetype = Type), colour = "gray70",
            show.legend = FALSE) +
    # Plot ship track data
    geom_sf(data = nav.paths.sf, colour = "gray70", size = 0.5, alpha = 0.5) +
    # Plot acoustic transects
    geom_sf(data = nasc.tx.sf, size = 1) +
    # scale_linetype_manual(name = "Type", values = wpt.linetypes) +
    # Plot trawl transects
    geom_point(data = haul.catch, aes(X, Y),
               shape = 21, colour = "black", fill = "white", size = 3) +
    geom_sf(data = bongo.sta, 
            shape = 24, size = 2, fill = "orange", colour = "black") +
    geom_sf(data = ctd.sta, 
            shape = 21, size = 2, fill = "red", colour = "black") +
    geom_sf(data = uctd.sta, 
            shape = 21, size = 2, fill = "red", colour = "black") +
    coord_sf(crs = crs.proj,
             xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
             ylim = c(map.bounds["ymin"], map.bounds["ymax"]))
  
  ggsave(here("Figs/fig_station_samples.png"), survey.station.map,
         height = map.height, width = map.width)
  
  # Create final backscatter summary map
  source(here("Code/plot_sA_CPS.R"))
  # Create final CUFES egg density map
  source(here("Code/plot_CUFES.R"))
  # Create trawl haul and cluster proportion figures
  source(here("Code/plot_haul_proportion_wt.R"))
  
  # Combine backscatter, CUFES, and trawl maps
  nasc.cufes.trawl.plot      <- plot_grid(nasc.map.cps, cufes.density.all, trawl.pie.haul.wt,
                                          nrow = 1, labels = c("a)", "b)", "c)"))
  
  # Save maps
  ggsave(nasc.cufes.trawl.plot, 
         filename = here("Figs/fig_nasc_cufes_haul_wt.png"),
         width = map.width*3, height = map.height)

  if (exists("google_map_api")) {
    # If the Google Map API key is present, map the calibration location
    source(here("Code/map_calibration_location.R"))
  }
} 
```  

```{r plot-maps-ns}
# Plot nearshore purse seine catch and acoustic backscatter
source(here("Code/plot_purseSeine_2107RL.R"))
```

\pagenumbering{gobble}

**Report on the `r survey.name.long` (`r survey.name`), `r survey.start` to `r survey.end` `r survey.year`, conducted aboard NOAA ship _`r survey.vessel.long`_, fishing vessels _Lisa Marie_ and _Long Beach Carnage_, and uncrewed surface vehicles**  

Josiah S. Renfree^1^, Alice Beittel^2^, Noelle M. Bowlin^1^, Brad E. Erisman^1^, Scott A. Mau^1^, David W. Murfin^1^, Brittany D. Schwartzkopf^1^, Thomas S. Sessions^1^, Kevin L. Stierhoff^1^, Lanora Vasquez^1^, William Watson^1^, Juan P. Zwolinski^1,4^, and David A. Demer^1^

^1^Fisheries Resources Division  
Southwest Fisheries Science Center (SWFSC)  
NOAA-National Marine Fisheries Service  
8901 La Jolla Shores Dr.  
La Jolla, CA 92037, USA  

^2^NOAA Commissioned Officer Corps, Assigned to SWFSC 

^3^University of California, Santa Cruz  
The Cooperative Institute for Marine, Earth and Atmospheric Systems (CIMEAS)  
1156 High St
Santa Cruz, CA 95064, USA

\newpage

<!-- \pagenumbering{gobble} -->

<!-- \listoftables -->

<!-- \listoffigures -->

<!-- \newpage -->

\pagenumbering{arabic}

# Introduction {#introduction}

The `r survey.name.long` (`r survey.name`) was conducted by the Fisheries Resources Division (FRD) of the Southwest Fisheries Science Center (SWFSC) aboard NOAA ship *`r survey.vessel.long`* (hereafter *`r survey.vessel`*) (**Fig.** \@ref(fig:vessel-pic)), `r survey.start` to `r survey.end` `r survey.year`, and augmented by data collected from the fishing vessels _Lisa Marie_ and _Long Beach Carnage_ and uncrewed surface vehicles (USVs; Saildrone, Inc.). The Acoustic-Trawl Method (ATM) is routinely used to assess coastal pelagic fish species (CPS) and krill within the California Current Ecosystem (CCE), typically between Vancouver Island, British Columbia and San Diego, CA. Starting in 2021, the survey has extended southward to include central Baja California, Mexico. Data were collected using multi-frequency echosounders, surface trawls, obliquely integrating net tows, a Continuous Underway Fish-Egg Sampler [CUFES; @Checkley1997], and conductivity-temperature-depth probes (CTDs).

The objectives for the survey were to: 1) acoustically map the distributions, measure the species compositions and size-frequency distributions, and estimate the abundances of CPS, e.g., Pacific Sardine *Sardinops sagax*, Northern Anchovy *Engraulis mordax*, Pacific Herring *Clupea pallasii*, Pacific Round Herring *Etrumeus acuminatus*, Pacific Mackerel *Scomber japonicus*, and Jack Mackerel *Trachurus symmetricus*; and krill (euphausiid spp.); 2) characterize and investigate linkages to their biotic and abiotic environments; 3) gather information regarding their life histories; and 4) use fishing vessels and USVs to sample transects and nearshore areas when and where sampling from NOAA ships was deemed inefficient, unsafe, or both (**Fig.** \@ref(fig:vessel-pic)).

The survey domain, from Cape Flattery, WA to Central Baja California, Mexico, was defined primarily by the modeled distribution of potential habitat for the northern subpopulation (stock) of Pacific Sardine [@Zwolinski2011], with a southern extension permitted by available sampling effort. This area was chosen to encompass the anticipated distributions of the northern stock of Pacific Sardine and the central and northern stocks of Northern Anchovy off the west coasts of the U.S., Canada, and Mexico, but it also spanned portions of the southern stock of Pacific Sardine, Pacific Mackerel, Jack Mackerel, Pacific Round Herring, and Pacific Herring.

This report provides an overview of the survey objectives and a summary of the survey equipment, sampling protocols, and data collections. This report does not include estimates of the animal distributions and biomasses, which are documented separately. 

(ref:vessel-pic) NOAA ship _`r survey.vessel`_ (top), F/V _Lisa Marie_ (bottom left), F/V _Long Beach Carnage_ (bottom middle), and an uncrewed surface vehicle (Saildrone USV, bottom right).

```{r vessel-pic, fig.cap='(ref:vessel-pic)', out.height='5.0in', fig.pos='H'}
include_graphics(here("Images/img_vessels_1907RL.png"))
```

\newpage  

## Scientific Personnel {#introduction-personnel}
The collection and analysis of the survey data were conducted by members of 1-NOAA, 2-UCSC/CIMEAS, 3-UCSD/SIO, 4-INAPESCA, and 5-volunteers. Asterisks denote Chief Scientists.

Leg 1 of the survey on _`r survey.vessel`_ was cancelled due to OMAO staffing issues.

**Project Lead:**

* D. Demer

**Acoustic Data Collection and Processing:**

* Leg II:  S. Mau^1^, S. Dolan^3^, and D. Palance^2^
* Leg III: J. Zwolinski^2\*^ and S. Sessions^1^
* Leg IV:  K. Stierhoff^1\*^ and A. Beittel^1^

**Trawl Sampling:**

* Leg II:  K. James^1^, E. Weber^1^, K. Walsh^3^, and R. Backman^5^
* Leg III: J. Walker^2^, N. Concha-Saiz^1^, M. Illman^5^, and J. Wood^5^
* Leg IV:  B. Schwartzkopf^1^, N. Concha-Saiz^1^, O. Snodgrass^1^, D. Lowry^1^ , and D. Hernandez-Cruz^4^

**CUFES Sampling:**

* Leg II:  W. Watson^1\*^ and E. Gardner^1^
* Leg III: A. Hays^1^
* Leg IV:  B. Overcash^1^ and S. Morales-Gutierrez^4^

**Purse-seine Sampling:**  

* _Lisa Marie_
  + K. Hinton and P. Biondo
* _Long Beach Carnage_
  + K. Kloos, T. Nguyen, J. van Noord, and T. Stocking

**Echosounder Calibrations:**  

* _Lasker_
  + D. Demer^1^, D. Murfin^1^, J. Renfree^1^, and S. Dolan^4^
* _Lisa Marie_
  + J. Renfree^1^
* _Long Beach Carnage_
  + D. Murfin^1^ and J. Renfree^1^
* _Saildrone_
  + Saildrone, Inc. and J. Renfree^1^
* _Carranza_
  + M. Vásquez-Ortiz^2^, L. Altamirano-López^2^, and S. Padilla-Galindo^2^

\newpage

# Methods {#methods}
## Survey region and design {#methods-survey-design}

The SWFSC’s ATM surveys of CPS in the CCE began in 2006 with a focus on the northern stock of Pacific Sardine. Since then, they have expanded in scope and objectives to include the larger forage-fish assemblage and krill. This evolution, and the migratory behavior of Pacific Sardine, serve to explain the present survey region and design.  

During spring, the northern stock of Pacific Sardine typically aggregates offshore of central and southern California to spawn [@Demer2012, and reference therein]. During summer, if the stock is large enough, adults migrate north, compress along the coast, and feed in the upwelled regions (**Fig. \@ref(fig:sardine-distribution)**). Since approximately 2012, however, the seasonal migration of the northern stock of Pacific Sardine diminished to the extent that it remains north of Cape Mendocino year-round.  

During `r tolower(survey.season)` `r survey.year`, the west coasts of the United States and Baja California were surveyed using _`r survey.vessel`_, _Carranza_, _Lisa Marie_, _Long Beach Carnage_, and USVs. Compulsory transects were nearly perpendicular to the coast and separated by 10 nmi. The survey began off `r survey.landmark.n` and the combination of survey platforms progressed southwards toward `r survey.landmark.s`.    

The planned transects (**Fig. \@ref(fig:survey-plan)**) spanned the latitudinal extent of the potential habitat of the northern stock of Pacific Sardine^[https://coastwatch.pfeg.noaa.gov/erddap/griddap/sardine_habitat_modis.html] at the time of the survey (**Fig. \@ref(fig:sardine-habitat)**). For _`r survey.vessel`_, the planned transects ranged from Vancouver Island, British Columbia to Punta Eugenia, MX. Due to time constraints, Vancouver Island was omitted, and _`r survey.vessel`_’s southernmost transect ended at Las Flores, MX. The offshore extent of the planned transects was adjusted during the survey according to the observed distribution of putative CPS backscatter in the echograms, CPS eggs in the CUFES samples, or CPS caught in trawls. To survey farther south into Baja California, _Carranza_ planned to sample from Punta Eugenia to `r survey.landmark.s`, but began the former at Las Flores, MX to begin sampling where _`r survey.vessel`_ concluded. To increase the spatial sampling resolution from _`r survey.vessel`_, acoustic sampling was conducted by USVs interstitial to _`r survey.vessel`_ transects from Cape Flattery, WA to Crescent City, CA (SD-1055 and SD-1059) and Point Arena to Point Conception, CA (SD-1036, SD-1055, and SD-1059). USVs (SD-1036 and SD-1059) were additionally used to sample the offshore extents of _`r survey.vessel`_ transects in the Southern California Bight. To estimate CPS biomass near shore, where it is too shallow to navigate NOAA ships safely, sampling from _`r survey.vessel`_ was augmented with echosounder and purse-seine sampling from _Lisa Marie_ between Cape Flattery, WA to Bodega Bay, CA; and _Long Beach Carnage_ from Bodega Bay, CA to the US/Mexico border, and around Santa Cruz and Santa Catalina Islands (**Fig. \@ref(fig:survey-plan)**).  

(ref:sardine-distribution) Conceptual spring (shaded region) and summer (hashed region) distributions of potential habitat for the northern stock of Pacific Sardine along the west coasts of Mexico, the United States, and Canada. The dashed and dotted lines represent, respectively, the approximate summer and spring positions of the 0.2 mg m^–3^ chlorophyll-a concentration isoline. This isoline appears to oscillate in synchrony with the transition zone chlorophyll front [TZCF, @Polovina2001] and the offshore limit of the northern stock Pacific Sardine potential habitat [@Zwolinski2011]. Mackerels are found within and on the edge of the same oceanographic  habitat [e.g., @Demer2012; @Zwolinski2012]. The TZCF may delineate the offshore and southern limit of both Pacific Sardine and Pacific Mackerel distributions, and juveniles may have nursery areas in the Southern California Bight, downstream of upwelling regions.

```{r sardine-distribution, fig.cap='(ref:sardine-distribution)',out.height='7in',fig.pos='H'}
include_graphics(here("Images/img_survey_region.png"))  
```  

\newpage  

(ref:survey-plan) Planned core-area (solid black lines) and adaptive (dashed red lines) transect lines sampled by _`r survey.vessel`_ and _Carranza_; optional offshore transect extensions for potential sampling by _`r survey.vessel`_ (dashed orange lines); interstitial transects sampled by USVs (solid cyan lines); and nearshore transect lines sampled by fishing vessels (solid magenta lines). Isobaths (light gray lines) are placed at 50, 200, 500, and 2,000 m (or approximately 25, 100, 250, and 1,000 fathoms).

```{r survey-plan, fig.cap='(ref:survey-plan)', out.height='8in',fig.align='center',fig.pos='H'}
include_graphics(here("Figs/fig_survey_plan.png"))
```  

\newpage  

(ref:sardine-habitat) Distribution of potential habitat for the northern stock of Pacific Sardine, temporally aggregated using an average of the habitat centered ±2° around _`r survey.vessel`_ positions throughout the survey. Areas in white correspond to no available data, e.g., cloud coverage preventing satellite-sensed observations.

```{r sardine-habitat,fig.cap='(ref:sardine-habitat)',out.height = '6in',fig.align='center',fig.pos='H'}
include_graphics(here("Figs/fig_summer2021_habitat.png"))
```  

\newpage

## Acoustic sampling {#methods-acoustic-sampling}
### Echosounders {#methods-echosounders}  

On _`r survey.vessel`_, multi-frequency Wideband Transceivers (18-, 38-, 70-, 120-, 200-, and 333-kHz Simrad EK80 WBTs) were configured with split-beam transducers (Simrad `r echo.models`). The transducers were mounted on the bottom of a retractable keel or "centerboard" (**Fig. \@ref(fig:cb-config)**). The keel was retracted (transducers ~`r cb.retracted`-m depth) during calibration, and extended to the intermediate position (transducers ~`r cb.intermediate`-m depth) during the survey. Exceptions were made during shallow water operations, when the keel was retracted; or during times of heavy weather, when the keel was extended (transducers ~`r cb.extended`-m depth) to provide extra stability and reduce the effect of weather-generated noise (**Appendix \@ref(appendix-cb-pos)**). Transducer position and motion were measured at 5 Hz using an inertial motion unit (POS-MV; Trimble/Applanix).  

(ref:cb-config) Transducer locations on the bottom of the centerboard aboard _`r survey.vessel`_.

```{r cb-config,fig.cap='(ref:cb-config)',out.width = '6.5in',fig.align='center',fig.pos='H'}
if (survey.vessel.primary == "RL") {
  include_graphics(here("Images/img_centerboard_config_RL.png"))
} else {
  include_graphics(here("Images/img_centerboard_config_SH.png"))
}
```  

On _Carranza_, multi-frequency General Purpose Transceivers (18-, 38-, 70-, 120-, and 200-kHz Simrad EK60 GPTs) were configured with split-beam transducers (Simrad ES18, ES38B, ES70-7C, ES120-7C, and ES200-7C) mounted on the bottom of a retractable keel, placing them approximately 4 m beneath the water surface.

On _Lisa Marie_, the SWFSC's General Purpose Transceiver (38-kHz Simrad EK60 GPT) was connected to the vessel's hull-mounted split-beam transducer (Simrad ES38B).

On _Long Beach Carnage_, the SWFSC's multi-frequency General Purpose Transceivers (38-, 70-, 120-, and 200-kHz Simrad EK60 GPTs) were configured with the SWFSC's split-beam transducers (Simrad ES38-12, ES70-7C, ES120-7C and ES200-7C) mounted in a multi-frequency transducer array (MTA4) on the bottom of a pole (**Fig. \@ref(fig:cb-config-lbc)**).  

On the three USVs (SD-1036, SD-1055, and SD-1059), miniature Wideband Transceivers (Simrad WBT Mini) were configured with gimbaled, keel-mounted, dual-frequency transducers (Simrad ES38-18|200-18C) containing a split-beam 38-kHz transducer and single-beam 200-kHz transducer with nominally 18$^\circ$ beamwidths.

(ref:cb-config-lbc) Transducer locations on the bottom of the pole-mounted multi-transducer array (MTA4) installed on the F/V _Long Beach Carnage_.

```{r cb-config-lbc,fig.cap='(ref:cb-config-lbc)',out.height = '5in',fig.align='center',fig.pos='H'}
include_graphics(here("Images/img_carnage_MTA4.jpg"))
```

### Calibrations {#methods-echosounder-calibration}  

The echosounder systems on each vessel were calibrated using the standard sphere technique [@Foote1987;@Demer2015]. On _`r survey.vessel`_, each WBT was calibrated in both CW (i.e., continuous wave or chirp mode) and FM modes (i.e., frequency modulation or broadband mode). For both modes, the reference target was a `r cal.sphere`; For FM mode, additional calibrations were conducted for the 120, 200, and 333-kHz echosounders using a smaller 25-mm WC sphere. On _Carranza_, the EK60 GPTs were calibrated using a WC38.1, except for the 18-kHz GPT that was calibrated using a 63-mm diameter copper sphere (Cu63). Calibrations for _Lisa Marie_, _Long Beach Carnage_, and the USVs were all conducted using a WC38.1. On each vessel, the GPTs or WBTs were configured using the calibration results via the control software (EK80 `r ek80.version`, Simrad; see **Section \@ref(results-echosounder-calibration)**).  

### Data collection {#methods-acoustic-data-collection}  

On _`r survey.vessel`_, the computer clocks were synchronized with the GPS clock (UTC) using synchronization software (NetTime^[http://timesynctool.com]). The 18-kHz WBT, operated by a separate PC from the other echosounders, was programmed to track the seabed and output the detected depth to the ship’s Scientific Computing System (SCS). The 38-, 70-, 120-, 200-, and 333-kHz echosounders were controlled by the EK80 Adaptive Logger [EAL^[https://www.fisheries.noaa.gov/west-coast/science-data/ek80-adaptive-logger/], @Renfree2016]. The EAL optimizes the pulse interval based on the seabed depth, while avoiding aliased seabed echoes, and was programmed such that once an hour the echosounders would record three pings in passive mode, for obtaining estimates of the background noise level. Acoustic sampling for CPS-density estimation along the pre-determined transects was limited to daylight hours (approximately between sunrise and sunset).

Measurements of volume backscattering strength ($S_v$; dB re 1 m^2^ m^-3^) and target strength ($TS$; dB re 1 m^2^), indexed by time and geographic positions provided by GPS receivers, were logged to 60 m beyond the detected seabed range or to a maximum range of 1000, 1000, 700, 300, and 150 m for 38, 70, 120, 200, and 333 kHz, respectively, and stored in Simrad .raw format with a `r raw.size`-GB maximum file size. During daytime and nighttime, the echosounders were set to operate in CW and FM modes, respectively. For each acoustic instrument, the prefix for each file name is a concatenation of the survey name (e.g.,  `r survey.name`), the operational mode (CW or FM), and the logging commencement date and time from the EK80 software. For example, a file generated by the Simrad EK80 software (`r ek80.version`) for a WBT operated in CW mode is named `2107RL-CW-D20210723-T125901.raw`.   

To minimize acoustic interference, transmit pulses from the EK80s, acoustic Doppler current profiler and echosounder (Simrad EC150-3C), multibeam echosounder (Simrad ME70), imaging sonar (Simrad MS70), scanning sonar (Simrad SX90), and a separate acoustic Doppler current profiler (Teledyne RD Instruments OS75 ADCP) were triggered using a synchronization system (Simrad K-Sync). The K-Sync trigger rate, and thus the echosounder ping interval, was modulated by the EAL using the 18-kHz seabed depth provided by _`r survey.vessel`_'s Scientific Computing System (SCS). During daytime, the EC150-3C, ME70, SX90, and ADCP were operated continuously, while the MS70 was only operated at times when CPS were present. At nighttime, only the EK80, EC150-3C, and ADCP were operated. All other instruments that can produce sound within the EK80's CW bandwidths were secured during daytime-survey operations. Exceptions were made during stations (e.g., plankton sampling and fish trawling) or in shallow water when the vessel's command occasionally operated the bridge's 50- and 200-kHz echosounders (Furuno), the Doppler velocity log (Model SRD-500A, Sperry Marine), or both.

On _Carranza_, the EK60 echosounders were triggered using a synchronization system (Simrad K-Sync). During daytime acoustic transects, no other acoustic sounders were operated. The ping interval and recording range were modulated based on the seabed depth, respectively: 0.25 s and 100 m for a depth of 0-50 m; 0.5 s and 150 m for a depth of 50-100 m; 0.75 s and 200 m for a depth of 100-150 m; 1 s and 300 m for a depth of 150-200 m; and 2 s and 500 m for a depth of 250-500 m.

On _Lisa Marie_ and _Long Beach Carnage_, the EAL was used to control the EK80 software to modulate the echosounder recording ranges and ping intervals to avoid aliased seabed echoes. When the EAL was not utilized, the EK80 software recorded to 200 and 500 m, respectively, and used the maximum ping rate. Transmit pulses from the EK60s and fishing sonars were not synchronized. Therefore, the latter was secured during daytime acoustic transects.

On the USVs, the echosounders were programmed to transmit CW pulses to a range dependent on the transect depth. For deeper seabed depths, the ping interval was 2 s and the 38 and 200-kHz echosounders recorded to 1000 and 400 m, respectively. For shallower depths, the ping interval was 1 s and both echosounders recorded to 250 m. Once an hour, the echosounders would operate in passive mode and record three pings to obtain estimates of the background noise level.

### Data processing {#methods-acoustic-data-processing}  

Echoes from schooling CPS and plankton (**Figs. \@ref(fig:ev-filtering-example)a, d**) were identified using a semi-automated data processing algorithm implemented using Echoview software (`r ev.version`; Echoview Software Pty Ltd). The filters and thresholds were based on a subsample of echoes from randomly selected CPS schools. The aim of the filter criteria is to retain at least 95% of the noise-free backscatter from CPS while rejecting at least 95% of the non-CPS backscatter (**Fig. \@ref(fig:ev-filtering-example)**). Data from _`r survey.vessel`_, _Carranza_, and _Long Beach Carnage_ were processed using the following steps:  

1. Match geometry of all $S_v$ variables to the 38-kHz $S_v$;
2. Remove passive-mode pings;
3. Estimate and subtract background noise using the background noise removal function [@DeRobertis2007] in Echoview (**Figs. \@ref(fig:ev-filtering-example)b, e**);
4. Average the noise-free $S_v$ echograms using non-overlapping 11-sample by 3-ping bins;
5. Expand the averaged, noise-reduced _S~v~_ echograms with a 7 pixel x 7 pixel dilation;
6. For each pixel, compute: $S_{v,\mathrm{200kHz}}-S_{v,\mathrm{38kHz}}$, $S_{v,\mathrm{120kHz}}-S_{v,\mathrm{38kHz}}$, and $S_{v,\mathrm{70kHz}}-S_{v,\mathrm{38kHz}}$;
7. Create a Boolean echogram for $S_v$ differences in the CPS range: $-13.85 < S_{v,\mathrm{70kHz}}-S_{v,\mathrm{38kHz}} < 9.89 \text{ and} -13.5 < S_{v,\mathrm{120kHz}}-S_{v,\mathrm{38kHz}} < 9.37 \text{ and} -13.51 < S_{v,\mathrm{200kHz}}-S_{v,\mathrm{38kHz}} < 12.53$;
8. Compute the 120- and 200-kHz Variance-to-Mean Ratios [$VMR_{\mathrm{120kHz}}$ and $VMR_{\mathrm{200kHz}}$, respectively, @Demer2009a] using the difference between noise-filtered $S_v$ (Step 3) and averaged $S_v$ (Step 4);
9. Expand the $VMR_{\mathrm{120kHz}}$ and $VMR_{\mathrm{200kHz}}$ echograms with a 7 pixel x 7 pixel dilation;
10. Create a Boolean echogram based on the $VMR$s in the CPS range: $VMR_{\mathrm{120kHz}}$ > -65 dB and $VMR_{\mathrm{200kHz}}$ > -65 dB. Diffuse backscattering layers have low $VMR$ [@Zwolinski2010] whereas fish schools have high $VMR$ [@Demer2009a];
11. Intersect the two Boolean echograms to create an echogram with "TRUE" samples for candidate CPS schools and "FALSE" elsewhere;
12. Mask the noise-reduced echograms using the CPS Boolean echogram (**Figs. \@ref(fig:ev-filtering-example)c, f**);
13. Create an integration-start line `r int.start` m below the transducer (~10 m depth);
14. Create an integration-stop line `r adz.range` m above the estimated seabed [@Demer2009a], or to the maximum logging range (e.g., `r int.stop` m), whichever is shallowest;
15. Set the minimum $S_v$ threshold to -60 dB (corresponding to a density of approximately three 20-cm-long Pacific Sardine per 100 m^3^);
16. Integrate the volume backscattering coefficients ($s_V$, m^2^ m^-3^) attributed to CPS over 5-m depths and averaged over 100-m distances;
17. Output the resulting nautical area scattering coefficients ($s_A$; m^2^ nmi^-2^) and associated information from each transect and frequency to comma-delimited text (.csv) files.  

Data from _Lisa Marie_ were processed using the following steps:  

1. Remove shorter-duration, transient noise (e.g., ship’s asynchronous sonar) using the Impulse Noise Removal operator;
2. Remove longer-duration, transient noise (e.g., wave-hull collisions) using the Transient Noise Removal operator;
3. Compensate attenuated signals (e.g., from air-bubble attenuation) using the Attenuated Signal Removal operator;
4. Average the noise-free 38-kHz $S_v$ echograms using non-overlapping 11-sample by 3-ping bins;
5. Compute the $VMR$ using the difference between noise-filtered $S_v$ (Step 3) and averaged $S_v$ (Step 4);
6. Create a Boolean echogram mask using $VMR$ > -48 dB;
7. Expand the Boolean mask with a 7 pixel x 7 pixel dilation;
8. Performs Steps 12-17 from _`r survey.vessel`_ processing.

Data from the USVs were processed using the following steps:

1. Match geometry of the $S_{v,\mathrm{200kHz}}$ to the $S_{v,\mathrm{38kHz}}$;
2. Remove passive-mode pings;
3. Perform Steps 3-5 from _`r survey.vessel`_ processing;
4. For each pixel, compute: $S_{v,\mathrm{200kHz}}-S_{v,\mathrm{38kHz}}$;
5. Create a Boolean echogram for $S_v$ differences in the CPS range: $-13.5 < S_{v,\mathrm{200kHz}}-S_{v,\mathrm{38kHz}} < 9.37$
6. Perform Steps 8-9 from _`r survey.vessel`_ processing;
7. Create a Boolean echogram mask using $VMR$ > -57 dB;
8. Performs Steps 11-17 from _`r survey.vessel`_ processing.  

When necessary, the start and stop integration lines were manually edited to exclude reverberation due to bubbles, to include the entirety of shallow CPS aggregations, or to exclude seabed echoes.  Echoes suspected to be from rockfish schools were further excluded.

(ref:ev-filtering-example) Echogram depicting CPS schools (red) and plankton aggregations (blue and green) at 38 kHz (top row) and 120 kHz (bottom row). Example data processing steps include the original echogram (left column), after noise subtraction and bin-averaging (middle column), and after filtering to retain only putative CPS echoes (right column).

```{r ev-filtering-example,fig.cap='(ref:ev-filtering-example)',out.width = '7in',fig.pos='H'}
include_graphics(here("Images/img_echoview_filtering_example-labeled.png"))
```  

## Trawl sampling {#methods-trawl-sampling}  

During the day, CPS form schools, typically in the upper mixed layer [e.g., from the surface to 70-m depth in the spring, @Kim2005], and generally shallower in summer. After sunset, CPS schools tend to ascend and disperse; at that time, with reduced visibility and no schooling behavior, they are less able to avoid a net [@Mais1974]. Therefore, trawl sampling for identifying the species composition and length distributions of acoustic targets was performed at night.  

On _`r survey.vessel`_, the net, a Nordic 264 rope trawl (NET Systems; Bainbridge Island, WA; **Figs. \@ref(fig:trawl-diagrams)a, b**), has a rectangular opening in the fishing portion of the net with an area of approximately 300 m^2^ (~15-m tall x 20-m wide), variable-sized mesh in the throat, an 8-mm square-mesh cod-end liner (to retain a large range of animal sizes), and a "marine mammal excluder device" to prevent the capture of larger animals, such as dolphins, turtles, or sharks [@Dotson2010]. The trawl doors are foam-filled and the trawl headrope is lined with floats so the trawl opening spans from the surface to about 15-m depth.

Up to three nighttime (i.e., 60 min after sunset to 30 min before sunrise) surface trawls, typically spaced 5-10 nmi-apart, were conducted in areas where echoes from putative CPS schools were observed in echograms or eggs were observed in the CUFES earlier that day. Each evening, trawl locations were selected based on the acoustic and CUFES data using the following criteria, in descending priority: CPS schools in echograms that day, CPS eggs in CUFES samples that day, and the trawl locations and catches during the previous night. If no CPS echoes or CPS eggs were observed along the transect(s) that day, trawls were alternatively placed nearshore one night and offshore the next night, with consideration given to the seabed depth and the modeled distribution of Pacific Sardine habitat.  

Trawls were towed at ~4 kn for 45 min. The total catch from each trawl was weighed and sorted by species or groups. From the catches with CPS, specimens were selected randomly for each of the target species (up to 75 for Pacific Sardine and Northern Anchovy and up to 50 for Pacific Mackerel, Jack Mackerel, and Pacific Herring). Those were weighed and measured to either their standard length ($L_S$; mm) for Pacific Sardine and Northern Anchovy, or fork length ($L_F$; mm) for Jack Mackerel, Pacific Mackerel, Pacific Round Herring, and Pacific Herring. In addition, sex and maturity were visually determined and recorded for up to 75 specimens from Pacific Sardine and Northern Anchovy and up to 25 for Pacific and Jack Mackerels. Ovaries were preserved of each CPS, except Pacific Herring, for subsequent histological processing to validate maturity. For each CPS, ovaries (either whole or partial) were preserved for up to 10 specimens from each maturity code (immature specimens: maturity code 1; mature specimens: maturity codes 2-4), enabling an evaluation of accuracy for personnel who assessed maturity. Fin clips were removed from 50 Pacific Sardine and Northern Anchovy specimens each from seven different geographic zones (designated by J. Hyde and M. Craig, SWFSC) and preserved in ethanol for genetic analysis. Otoliths were removed from up to 50 Pacific Sardine in the subsample; for other CPS species (except Pacific Herring), 25 otoliths were removed from fish representing the range of lengths present, for age determination as described in @Schwartzkopf2022 and @Dorval2022. The combined catches of CPS in up to three trawls per night (i.e., trawl cluster) were used to estimate the proportions of species contributing to the nearest samples of acoustic backscatter.  

(ref:trawl-diagrams) Schematic drawings of the Nordic 264 rope trawl net (a) and cod-end (b) on _`r survey.vessel`_.

```{r trawl-diagrams, fig.cap='(ref:trawl-diagrams)',out.height='7in',fig.align='center',fig.pos='H'}
include_graphics(here("Images/img_Nordic_264.png")) 
```  

On _Carranza_, up to three trawls were conducted each night. The net, a midwater Mesh Wing Trawl 25/25 (252MWT04i; NET Systems; **Figs. \@ref(fig:trawl-diagram-carranza)**), has equal top and bottom footrope lengths of 48.17 m. The mesh size decreases from 1600 to 50 mm, and is constructed of multifilament nylon cloth and ultra-high molecular weight polyethylene [@Carranza2021]. The cod-end is a 17-mm Raschel nylon cloth netting. Trawls were towed at 3.5 to 4 knots for 45 minutes. A sample volume of approximately 15 kg was obtained from each haul. When the biological sample of the target species was less than this volume, the entire sample was processed. Subsequently, the CPS were identified and processed, first by measuring the standard length of each individual in the sample. Then, a proportion of each size interval was obtained with respect to the total number of organisms analyzed, to obtain a subsample for biological sampling that reflects the size distribution observed in the overall sample. The subsample was then processed to obtain specimen length, weight, sex, sexual maturity, fat content, stomach content, and gonadal weight. Otoliths were extracted for future age analysis.

(ref:trawl-diagram-carranza) Schematic drawings of the Mesh Wing trawl net on _Carranza_.

```{r trawl-diagram-carranza, fig.cap='(ref:trawl-diagram-carranza)',out.height='2.8in',fig.align='center',fig.pos='H'}
include_graphics(here("Images/img_meshwing_25_25.png")) 
```  

## Purse seine sampling {#methods-seine-sampling}  

Purse seine nets were set to provide information about size, age, and species composition of fishes observed in the echosounders mounted on the fishing vessels that sampled the nearshore region. _Lisa Marie_ used an approximately 440-m-long and 40-m-deep net with 17-mm-wide mesh (A. Blair, pers. comm.). _Long Beach Carnage_ used an approximately 200-m-long and 27-m-deep net with 17-mm-wide mesh; a small section on the back end of the net had 25-mm-wide mesh (R. Ashley, pers. comm.). Specimens collected by _Lisa Marie_ and _Long Beach Carnage_ were processed by the Washington Department of Fish and Wildlife (WDFW) and California Department of Fish and Wildlife (CDFW), respectively.

On _Lisa Marie_, as many as three purse seine sets were planned each day. For each set, three dip net samples, spatially separated as much as possible, were collected. For each dip net sample, all specimens were sorted, weighed, and counted to provide a combined weight and count for each. Next, all three dip net samples were combined and up to 50 specimens of each CPS species were randomly sampled to provide a combined weight for each set. The length (mm; $L_S$ for Pacific Sardine and Northern Anchovy and $L_F$ for all others) and weight was measured for up to 50 randomly selected specimens of each species. Otoliths were extracted, macroscopic maturity stage was determined visually, and gonads were collected and preserved from female specimens.

On _Long Beach Carnage_, as many as three purse seine sets were planned each day, including evenings. The total weight (tons) of the school was estimated by the captain. For each set, three dip net samples, spatially separated as much as possible, were collected. For each dip net sample, all specimens were sorted, weighed, and counted to provide a combined weight and count for each. From each dip net sample, as many as 20 fish of each CPS species were chosen randomly throughout the sample, and combined for a random sample of 50 fish collected throughout the catch. The fish were then frozen for later analysis by CDFW biologists, yielding measures of total sample weight and individual fish weight, length (mm; $L_S$ for Pacific Sardine and Northern Anchovy and $L_F$ for all others), maturity, and otolith-derived ages. Because samples were frozen, no gonad samples from female specimens were analyzed.

## Ichthyoplankton and oceanographic sampling {#methods-other-sampling}
### Egg and larva sampling {#methods-egg-sampling}  

On _`r survey.vessel`_ and _Carranza_, fish eggs were collected during the day using a CUFES, which collects water and plankton at a rate of ~640 l min^-1^ from an intake on the hull of the ship at ~3-m depth. For each vessel, the particles in the sampled water were sieved by a 505- and 500-$\mu$m mesh, respectively. Pacific Sardine, Northern Anchovy, Jack Mackerel, and Pacific Hake (_Merluccius productus_) eggs were identified to species, counted, and logged. Eggs from other species (e.g., Pacific Mackerel and flatfishes) were also counted and logged as "other fish eggs". Typically, the duration of each CUFES sample was 30 min, corresponding to a distance of 5 nmi at a speed of 10 kn for _`r survey.vessel`_, and 4 nmi at a speed of 8 kn for _Carranza_. Because the durations of the initial egg stages is short for most CPS, the egg distributions inferred from CUFES samples indicate the nearby presence of actively spawning fish.

On _`r survey.vessel`_, a CalCOFI bongo oblique net [a bridleless pair of 71-cm diameter nets with 505-$\mu$m mesh, @Smith1977] was used opportunistically to sample ichthyoplankton and krill after sunset, to contribute to the CalCOFI ichthyoplankton time series. Where there was adequate depth, 300 m of wire was deployed at a rate of 50 m min^-1^ and then retrieved at 20 m min^-1^, at a nominal wire angle of 45$^\circ$. Bongo samples were stored in 5% buffered formalin.  

### Conductivity and temperature versus depth (CTD) sampling {#methods-ctd-sampling}  

On _`r survey.vessel`_ and _Carranza_, conductivity and temperature were measured versus depth to `r ctd.depth` and 500 m, respectively, using calibrated sensors on a probe cast from the vessel while on station (CTD), or a probe cast from the vessel while underway (UnderwayCTD, or UCTD; Teledyne Oceanscience). These data indicate the depth of the surface mixed layer, above which most epipelagic CPS reside during the day, which is later used to determine the integration-stop depth during acoustic data processing. For _`r survey.vessel`_, these data were also used to estimate the time-averaged sound speed [@Demer2004c], for estimating ranges to the sound scatterers, and frequency-specific sound absorption coefficients, for compensating signal attenuation of the sound pulse between the transducer and scatterers [@Simmonds2005]. For _Carranza_, the conductivity and temperature from the echosounder calibrations were used for the Echoview processing.

\newpage

# Results {#results}
## Echosounder calibrations {#results-echosounder-calibration}  

For _`r survey.vessel`_, the EK80s were calibrated on `r cal.datetime` while the vessel was alongside the pier near `r cal.loc` (`r cal.lat.dd` $^\circ$N, `r cal.lon.dd` $^\circ$W). Measurements of sea-surface temperature ($t_w$ = `r cal.temp` $^\circ$C) and salinity ($s_w$ = `r cal.sal` psu) were measured to a depth of 10 m using a handheld probe (Pro2030, YSI) and input to the WBT-control software (EK80 `r ek80.version`, Simrad), which derived estimates of sound speed ($c_w$ = `r cal.c` m s^-1^) and absorption coefficients (see **Table \@ref(tab:cal-results)**). The centerboard was placed in the Retracted position, which resulted in the seabed being approximately `r cal.min.z` to `r cal.max.z` m beneath the transducers, depending on the tide. The calibration spheres were positioned in the far-field of each transducer, at 3.5- to 7-m range. WBT information, settings, and calibration results are presented in **Table \@ref(tab:cal-results)**. Measurements of beam-compensated sphere target strength relative to the theoretical target strength ($TS_{rel}$, dB re 1 m^2^) are presented in **Fig. \@ref(fig:tsc-plot)**. Measurements of gains, beamwidths, and offset angles from WBTs operated in FM mode are presented in **Fig. \@ref(fig:cal-plot-fm)**.

\newpage

(ref:cal-results) Simrad EK80 wideband transceiver (WBT; 18, 38, 70, 120, 200, and 333 kHz) and transducer information aboard _`r survey.vessel`_; pre-calibration settings (above horizontal line); and beam model results following calibration (below horizontal line). Prior to the survey, on-axis gain ($G_0$), beam angles ($\alpha_{-3dB}$ and $\beta_{-3dB}$) and angle offsets ($\alpha_0$ and $\beta_0$), and $S_a$ Correction ($S_\mathrm{a}\mathrm{corr}$) values from calibration results were entered into the control software (EK80 `r ek80.version`, Simrad).

```{r cal-results,results='asis'}

# Specify which vessel to use for table
all.output <- all.output.RL

# If knitting a Word document
if (doc.type == "docx") {
  
  # create kable object (for Word)
  pander(all.output)
  
# Otherwise, if knitting HTML or PDF
} else {
  
  # print LaTeX table
  kable(all.output, format = knitr.format, align = c("l","l",rep("c", ncol(all.output) - 2)),
        booktabs = T, escape = F, linesep = "",
        caption = '(ref:cal-results)') %>% 
    kable_styling(position = "center", 
                  latex_options = c("scale_down","hold_position")) %>% 
    row_spec(17, hline_after = T) %>% 
    add_header_above(c(" " = 2, "Frequency (kHz)" = ncol(all.output) - 2))
}
```  

\newpage

(ref:tsc-plot) Relative beam-compensated target strength ($TS_{rel}$, dB re 1 m^2^) measurements of a WC38.1 sphere at `r echo.freqs` kHz for echosounders aboard _`r survey.vessel`_. $TS_{rel}$ is calculated as the difference between the beam-compensated target strength ($TS_c$) and the theoretical target strength ($TS_{theory}$, see **Table \@ref(tab:cal-results)**). Crosses indicate measurements marked as outliers after viewing the beam model results.

```{r tsc-plot,fig.cap='(ref:tsc-plot)',out.width='5in',fig.align='center',fig.pos='H'}
include_graphics(here("Figs/fig_cal_TSrel_scatter.png"))
``` 

(ref:cal-plot-fm) Measurements of on-axis gain ($G_0$, dB); alongship ($\alpha_\mathrm{-3dB}$, cyan) and athwartship ($\beta_\mathrm{-3dB}$, magenta) beamwidths (deg); and alongship ($\alpha_\mathrm{0}$, cyan) and athwartship ($\beta_\mathrm{0}$, magenta) offset angles (deg) measured during calibrations of EK80 wideband transceivers aboard _`r survey.vessel`_ (WBT; 38, 70, 120, 200, and 333 kHz) in frequency modulation (FM, or broadband) mode.

```{r cal-plot-fm,fig.cap='(ref:cal-plot-fm)',out.width='6in',fig.align='center',fig.pos='H'}  
# Plots generated using Code/plot_CalFM_[survey.name].R
include_graphics(here("Figs/fig_cal_FM_AllFreqs.png"))
```

\newpage

For _Carranza_, the 18, 38, and 70-kHz GPTs were calibrated on 29 and 30 January, 2022, using the standard sphere technique. Calibrations were unsuccessful for the 120 and 200-kHz GPTs, and therefore results from the most recent calibration, conducted in September 2020, were used. Beam model results were entered into the EK80 software and are presented in **Table \@ref(tab:cal-results-jcf)**.  

(ref:cal-results-jcf) General Purpose Transceiver (Simrad EK60 GPT) calibrated beam model results estimated from calibrations of the echosounders aboard _Carranza_ using either a Cu63 (for 18 kHz) or WC38.1 (for 38, 70, 120, and 200 kHz). Results for the 120 and 200-kHz GPTs are from a calibration conducted in September 2020. Prior to the survey, calibrated on-axis gain ($G_0$), beam angles and angle offsets, and $S_a$ Correction ($S_\mathrm{a}\mathrm{corr}$) values were entered into the GPT-control software (EK80, Simrad).

```{r cal-results-jcf,results='asis'}
if (doc.type == "docx") {
  # create kable object (for Word)
  pander(all.output.jcf)
} else {
  # print LaTeX table for HTML or PDF
  kable(all.output.jcf, format = knitr.format, 
        align = c("l","l", rep("c",ncol(all.output.jcf) - 2)),
        booktabs = TRUE, escape = FALSE, linesep = "",
        caption = '(ref:cal-results-jcf)') %>% 
    kable_styling(position = "center", 
                  latex_options = c("hold_position"),
                  font_size = 8) %>%  
    row_spec(17, hline_after = TRUE) %>% 
    add_header_above(c(" " = 2, "Frequency (kHz)" = ncol(all.output.jcf) - 2))
}
```  

\newpage

For _Lisa Marie_, the 38-kHz GPT was calibrated on 5 June, 2021 using the standard sphere technique with a WC38.1 while the vessel was anchored in Yaquina Bay near Newport, OR (44.6249, -124.0370). Calibration results for _Lisa Marie_ are presented in **Table \@ref(tab:cal-results-lm)**.  

(ref:cal-results-lm) General Purpose Transceiver (Simrad EK60 GPT) beam model results estimated from an in situ calibration of echosounders aboard _Lisa Marie_ using a WC38.1. Prior to the survey, calibrated on-axis gain ($G_0$), beam angles and angle offsets, and $S_a$ Correction ($S_\mathrm{a}\mathrm{corr}$) values were entered into the GPT-control software (EK80, Simrad).

```{r cal-results-lm,results='asis'}
if (doc.type == "docx") {
  # create kable object (for Word)
  pander(all.output.lm)
} else {
  # print LaTeX table for HTML or PDF
  kable(all.output.lm, format = knitr.format, 
        align = c("l","l", rep("c",ncol(all.output.lm) - 2)),
        booktabs = TRUE, escape = FALSE, linesep = "",
        caption = '(ref:cal-results-lm)') %>% 
    kable_styling(position = "center", 
                  latex_options = c("hold_position"),
                  font_size = 8) %>%  
    row_spec(17, hline_after = TRUE) %>% 
    add_header_above(c(" " = 2, "Frequency (kHz)" = ncol(all.output.lm) - 2))
}
```  

\newpage

For _Long Beach Carnage_, the echosounders were calibrated using the standard sphere technique with a WC38.1 on 13 October, 2021 in a tank at the SWFSC. Calibration results for _Long Beach Carnage_ are presented in **Table \@ref(tab:cal-results-lbc)**.  

(ref:cal-results-lbc) General Purpose Transceiver (Simrad EK60 GPT) beam model results estimated from a tank calibration of echosounders aboard _Long Beach Carnage_ using a WC38.1. Prior to the survey, calibrated on-axis gain ($G_0$), beam angles and angle offsets, and $S_a$ Correction ($S_\mathrm{a}\mathrm{corr}$) values were entered into the GPT-control software (EK80, Simrad).

```{r cal-results-lbc,results='asis'}
if (doc.type == "docx") {
  # create kable object (for Word)
  pander(all.output.lbc)
} else {
  # print LaTeX table for HTML or PDF
  kable(all.output.lbc, format = knitr.format, 
        align = c("l","l", rep("c",ncol(all.output.lbc) - 2)),
        booktabs = TRUE, escape = FALSE, linesep = "",
        caption = '(ref:cal-results-lbc)') %>% 
    kable_styling(position = "center", 
                  latex_options = c("hold_position"),
                  font_size = 8) %>%  
    row_spec(17, hline_after = TRUE) %>% 
    add_header_above(c(" " = 2, "Frequency (kHz)" = ncol(all.output.lbc) - 2))
}
```  

\newpage

For the three USVs, the echosounders were calibrated while dockside by Saildrone, Inc. using the standard sphere technique with a WC38.1. The results were processed and derived by the SWFSC [@Renfree2019], and are presented in **Table \@ref(tab:cal-results-sd)**.

(ref:cal-results-sd) Miniature Wideband Transceiver (Simrad WBT Mini) beam model results estimated from calibrations of echosounders aboard USVs using a WC38.1.

```{r cal-results-sd,results='asis'}
if (doc.type == "docx") {
  # create kable object (for Word)
  pander(all.output.sd)
} else {
  # print LaTeX table for HTML or PDF
  kable(all.output.sd, format = knitr.format, 
        align = c("l","l", rep("c",ncol(all.output.sd) - 2)),
        booktabs = T, escape = F, linesep = "",
        caption = '(ref:cal-results-sd)') %>% 
    kable_styling(position = "center", 
                  latex_options = c("hold_position"),
                  font_size = 8) %>% 
    # row_spec(18, hline_after = T) %>% 
    # add_header_above(c(" " = 2, "1045" = 2, "1046" = 2, "1047" = 2)) %>% 
    add_header_above(c(" " = 2, "Saildrone (Frequency)" = 6))
}
```  

\newpage

## Data collection {#results-data-collection}
### Acoustic and net sampling {#results-acoustic-trawl-sampling}  

```{r load-nearshore-nasc-summary}
load(here("Output/purse_seine_sets.Rdata"))
load(here("Output/nasc_summ_tx_ns.Rdata"))

nasc.summ.lbc.ns <- filter(nasc.summ.ns, vessel.name == "LBC")
nasc.summ.lm.ns <- filter(nasc.summ.ns, vessel.name == "LM")
```  

The core survey region spanned an area from approximately `r survey.landmark.n` to `r survey.landmark.s` (**Fig. \@ref(fig:station-sampling)**). _`r survey.vessel`_, _Carranza_, and the three USVs sampled `r nrow(nasc.summ)` east-west transects totaling `r prettyNum(sum(nasc.summ$distance), digits = 1, big.mark = ",")` nmi, and conducted `r nrow(trawl.summ)` Nordic trawls.  

The nearshore region spanned an area from approximately Cape Flattery, WA to San Diego, CA, including around Santa Cruz and Santa Catalina Islands. _Lisa Marie_ surveyed from approximately Cape Flattery, WA to Stewarts Point, CA, with `r nrow(nasc.summ.lm.ns)` east-west transects totaling `r sprintf("%.0f",sum(nasc.summ.lm.ns$distance))` nmi and `r nrow(lm.sets)` purse seine sets (**Fig. \@ref(fig:nasc-seine-lm)**).  _Long Beach Carnage_ surveyed from approximately Stewarts Point to San Diego, CA, and around the Santa Cruz and Santa Catalina Islands, with `r nrow(nasc.summ.lbc.ns)` east-west transects totaling `r sprintf("%.0f",sum(nasc.summ.lbc.ns$distance))` nmi and `r nrow(lbc.sets)` purse seine sets (**Fig. \@ref(fig:nasc-seine-lbc)**).

**Leg I**  

On 6 July, _`r survey.vessel`_ departed from 10th Avenue Marine Terminal in San Diego, CA at ~1700 (all times UTC). Prior to the transit toward northern Vancouver Island, the Simrad EC150-3C was calibrated northwest of the sea buoy outside San Diego Bay (32.6598 N,  117.3833 W). Throughout the transit, sampling was conducted during the day with CUFES, EK80s, ME70, MS70 and SX90. Due to departure delays and weather delays during transit, sampling off Vancouver Island was abandoned. On 12 July at ~1930, _`r survey.vessel`_ began acoustic sampling along Transect 140 off Cape Flattery, WA. On 18 July, after sampling most of Transect 116, _`r survey.vessel`_ transited south to Transect 108 and resumed sampling transects from south to north for the remainder of Leg I. On 22 July, acoustic sampling ceased after the completion of Transect 116 off Newport, OR. _`r survey.vessel`_ arrived at the Marine Operations-Pacific (MOC-P) Pier in Newport, OR at ~1730 to complete Leg I.

During Leg I, _Lisa Marie_ sampled Transects 352 to 291, the nearshore region between Cape Flattery, WA to Coos Bay, OR, from 16 to 22 July. Two USVs (SD-1055 and SD-1059) sampled Transects 139 to 127, between Cape Flattery, WA to the Columbia River, from 11 to 26 July.

**Leg II**  

On 27 July, after a two-day delay, _`r survey.vessel`_ departed from the Marine Operations-Pacific (MOC-P) Pier at ~1130 and transited south; acoustic sampling  resumed along Transect 106 at ~1300 on 28 July.  An Autonomous Spar Buoy Recorder (DASBR) was deployed for the SWFSC Marine Mammal and Turtle Division on 31 July before starting Transect 099.  After completing Transect 099, _`r survey.vessel`_ transited to Humboldt Bay to embark the Second Cook. On 13 August, acoustic sampling ceased after the completion of Transect 057 off Point Estero in Harmony Headlands State Park. On 15 August, _`r survey.vessel`_ arrived at the 10th Avenue Marine Terminal in San Diego Bay at ~1700 to complete Leg II.

During Leg II, _Lisa Marie_ sampled Transects 289 to 231, the nearshore region between Coos Bay, OR to Fort Ross, CA, from 28 July to 5 August. _Long Beach Carnage_ sampled Transects 230 to 176, the nearshore region between Fort Ross to Point Conception, CA, from 12 to 21 August. Two USVs (SD-1055 and SD-1059) sampled Transects 125 to 109, between the Columbia River to Coos Bay, OR, from 26 July to 10 August; two USVs (SD-1036 and SD-1055) then sampled Transects 080 to 062, between Point Arena to Big Sur, CA, from 26 August to 6 September.

**Leg III** 

On 8 September, _`r survey.vessel`_ departed from the fuel pier at the 10th Avenue Marine Terminal in San Diego, CA at ~1315 and began the transit to resume acoustic sampling along Transect 053 at ~1500. On 20 September, acoustic sampling ceased after the completion of Transect 039 off San Diego, CA. On 20 September, _`r survey.vessel`_ arrived at the 10th Avenue Marine Terminal at ~0300 to complete Leg III.

During Leg III, _Long Beach Carnage_ sampled Transects 174 to 138, the nearshore region between Point Conception, CA to the USA/Mexico border, and the Santa Cruz and Santa Catalina Islands, from 12 to 19 September. Three USVs (SD-1036, SD-1055, and SD-1059) sampled Transects 060 to 040, between Big Sur to San Diego, CA, from 6 to 24 September, where Transects 051 to 040 were the offshore extents of the _`r survey.vessel`_ transects. 

**Leg IV** 

On 25 September, _`r survey.vessel`_ departed from the 10th Avenue Marine Terminal in San Diego Bay at ~1730. Without a permit to begin the survey in Mexico, _`r survey.vessel`_ transited north toward Cape Blanco, OR to conduct additional acoustic sampling along transects where CPS eggs and backscatter were observed toward the offshore ends of previously sampled transects. On 28 September, _`r survey.vessel`_ sought shelter from rough seas in Drake’s Bay near San Francisco, CA. Prior to dropping anchor, a second calibration of the EC150-3C ADCP was conducted north of the shipping channel (37.8880 N, 122.8870  W). During this time, engineers tended to the thrust bearing on the propeller shaft that began leaking lubricant during the calibration. At ~1500 on 30 September, _`r survey.vessel`_ weighed anchor and continued the transit to Cape Blanco, OR. At ~1400 on 2 October, acoustic sampling resumed along Transect 107. On 4 October, after sampling a portion of Transect 113, permission to survey in Mexico was received; _`r survey.vessel`_ promptly ceased acoustic sampling and turned south toward Mexico. On 7 October, Keighley Lane was put ashore via the _`r survey.vessel`_ work boat and _`r survey.vessel`_ continued toward the survey area off northern Baja California. At ~1500 on 8 October, acoustic sampling resumed along Transect 031 near Tijuana. On 14 October, acoustic sampling ceased after the completion of transect 018 off Las Flores, MX. On 15 October, _`r survey.vessel`_ arrived at the fuel pier at 10th Avenue Marine Terminal in San Diego at ~0630  to complete the survey.

During Leg IV, _Carranza_ sampled Transects 055 to 027, between Las Flores to Punta Abreojos, MX, from 19 October to 8 November.

\newpage

### Ichthyoplankton and oceanographic sampling {#results-other-sampling}  

A total of `r nrow(ctd.sta)` CTD casts and `r nrow(uctd.sta)` UCTD casts were conducted from _`r survey.vessel`_ and _Carranza_ (**Fig. \@ref(fig:station-sampling)** and **Appendix \@ref(appendix-ctd-sampling)**), and `r prettyNum(nrow(cufes.all), digits = 1, big.mark = ",")` CUFES samples were collected underway.  

(ref:station-sampling) The locations of surface trawls (white points), CTD and UCTD casts (red circles), and bongo nets (orange triangles) relative to the planned east-west acoustic transects (solid and dashed grey lines) and cruise tracks (thick black line) of _`r survey.vessel`_ (north of El Rosario, MX) and _Carranza_ (south of El Rosario, MX).

```{r station-sampling,fig.cap='(ref:station-sampling)',out.height='7in',fig.align='center',fig.pos='H'}
include_graphics(here("Figs/fig_station_samples.png"))
```  

## Distribution of CPS {#results-cps-distribution}
### Core region  

Acoustic backscatter ascribed to CPS (**Fig. \@ref(fig:nasc-cufes-trawl)a**), sampled by _`r survey.vessel`_, _Carranza_, and the USVs, was observed throughout the survey area, but was most prevalent: nearshore between Cape Flattery, WA to Newport, OR, Cape Blanco, OR to Cape Mendocino, CA, and in Baja California; offshore in the Southern California Bight; and dispersed both nearshore and offshore off the coast of California between Cape Mendocino and Point Conception. 

Pacific Sardine eggs were abundant in CUFES samples offshore of the Columbia River; offshore between Newport and Cape Blanco, OR; between Tijuana and El Rosario, MX; and off Maria, MX (**Fig. \@ref(fig:nasc-cufes-trawl)b**). Northern Anchovy eggs were most abundant in the Southern California Bight and off San Antonio, MX; and to a lesser extent off of Newport, OR, between Fort Bragg and Bodega Bay, CA, and outside Monterey Bay, CA. Jack Mackerel eggs were observed offshore between Westport, WA and the mouth of the Columbia River; between Newport, OR and Cape Mendocino, CA; and between San Francisco and Monterey Bay, CA. Jack Mackerel eggs were coincident with Pacific Sardine eggs north of Cape Mendocino, CA.  

Pacific Sardine were caught in trawls predominantly: between Newport and Cape Blanco, OR; in the Southern California Bight; and between Punta Colonet and Punta Abreojos, MX (**Fig. \@ref(fig:nasc-cufes-trawl)c**). Northern Anchovy were collected throughout the entire survey area south of Oregon. Jack Mackerel were most abundant throughout the survey area between Westport, WA and Cape Mendocino, CA; and in the Southern Califonia Bight down to Punta Abreojos, MX. Pacific Mackerel were caught predominantly between Rosario and Punta Abreojos, MX. Pacific Herring were most abundant off the mouth of the Columbia River and near the border of Oregon and California. Round Herring were only observed north of Punta Eugenia and near Punta Abreojos, MX. The combined catches of the `r nrow(trawl.summ)` trawls included `r prettyNum(haul.CPS.kg, digits = 1, big.mark = ",")` kg of CPS (`r prettyNum(haul.Sardine.kg, digits = 1, big.mark = ",")` kg Pacific Sardine, `r prettyNum(haul.Anchovy.kg, digits = 1, big.mark = ",")` kg Northern Anchovy, `r prettyNum(haul.JackMack.kg, digits = 1, big.mark = ",")` kg Jack Mackerel, `r prettyNum(haul.PacMack.kg, digits = 1, big.mark = ",")` kg Pacific Mackerel, `r prettyNum(haul.PacHerring.kg, digits = 1, big.mark = ",")` kg Pacific Herring, and `r prettyNum(haul.RndHerring.kg, digits = 1, big.mark = ",")` kg Round Herring; **Appendix \@ref(appendix-trawl-sampling)**).  

\newpage  
\blandscape  

(ref:nasc-cufes-trawl) Survey transects overlaid with the distributions of: 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^;  averaged over 2000-m distance intervals and from `r int.start`- to `r cps.depth`-m deep) ascribed to CPS (a); egg densities (eggs m^-3^) for Northern Anchovy, Jack Mackerel, and Pacific Sardine from the CUFES (b); and proportions, by weight, of CPS species in each trawl catch (c; black points indicate trawls with no CPS). Species with low catch weights are not visible at this scale.

```{r nasc-cufes-trawl,fig.cap='(ref:nasc-cufes-trawl)',out.width='8in',fig.pos='H'}
include_graphics(here("Figs/fig_nasc_cufes_haul_wt.png"))
``` 

\elandscape

### Nearshore region  

Acoustic backscatter sampled by _Lisa Marie_ and ascribed to CPS was observed throughout the nearshore survey area, but was most prevalent between the OR/CA border and Bodega Bay, CA (**Fig. \@ref(fig:nasc-seine-lm)a**).  The CPS backscatter sampled by _Long Beach Carnage_ was observed throughout the entire nearshore survey area off California, and was most prevalent between Bodega Bay to San Francisco, San Simeon to Point Conception, Santa Barbara to Ventura, and around Santa Cruz Island (**Fig. \@ref(fig:nasc-seine-lbc)a**).  

Purse seine catches by _Lisa Marie_ included predominantly Pacific Herring north of Cape Mendocino, CA, and Northern Anchovy south of Cape Mendocino, CA (**Fig. \@ref(fig:nasc-seine-lm)b**). Catches by _Long Beach Carnage_ included predominantly Northern Anchovy north of Long Beach, CA; Pacific Sardine south of San Simeon, CA; and Pacific Mackerel near Santa Cruz Island (**Fig. \@ref(fig:nasc-seine-lbc)b**).

(ref:nasc-seine-lm) Nearshore survey transects conducted by _Lisa Marie_ overlaid with the distributions of: 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^; averaged over 2000-m distance intervals and from `r int.start`- to `r cps.depth`-m deep) ascribed to CPS (a); and the proportions, by weight, of CPS in each purse seine catch (b). Species with low catch weights are not visible at this scale.

```{r nasc-seine-lm, fig.cap='(ref:nasc-seine-lm)', out.height='7in', fig.pos='H'}
if (file.exists(here("Figs/fig_nasc_seine_proportion_set_wt_LisaMarie.png"))) {
  include_graphics(here("Figs/fig_nasc_seine_proportion_set_wt_LisaMarie.png"))  
} else {
  print("No purse seing sampling figure present.")
}
```  

\newpage  

(ref:nasc-seine-lbc) Nearshore survey transects conducted by _Long Beach Carnage_ overlaid with the distributions of: 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^; averaged over 2000-m distance intervals and from `r int.start`- to `r cps.depth`-m deep) ascribed to CPS (a); and the proportions, by weight, of CPS in each purse seine catch (b). Species with low catch weights are not visible at this scale.

```{r nasc-seine-lbc, fig.cap='(ref:nasc-seine-lbc)', out.height='7in', fig.pos='H'}
if (file.exists(here("Figs/fig_nasc_seine_proportion_set_wt_LongBeachCarnage.png"))) {
  include_graphics(here("Figs/fig_nasc_seine_proportion_set_wt_LongBeachCarnage.png"))  
} else {
  print("No purse seing sampling figure present.")
}
```  

\newpage  

<!-- (ref:nasc-seine-ns) Nearshore survey transects conducted by F/Vs _Lisa Marie_ and _Long Beach Carnage_ overlaid with a) the distribution of 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^; averaged over 2000-m distance intervals and from `r int.start`- to `r cps.depth`-m deep) ascribed to CPS and b) the proportions, by weight, of CPS in each purse seine set or trawl cluster later used to apportion acoustic backscatter. Species with low catch weights may not visible at this scale. -->

<!-- ```{r nasc-seine-ns, fig.cap='(ref:nasc-seine-ns)', out.height='7in', fig.pos='H'} -->
<!-- if (file.exists(here("Figs/fig_nasc_acoustic_cluster_ns.png"))) { -->
<!--   include_graphics(here("Figs/fig_nasc_acoustic_cluster_ns.png"))   -->
<!-- } else { -->
<!--   print("No purse seing sampling figure present.") -->
<!-- } -->
<!-- ``` -->

\newpage  

# Discussion {#discussion}  

The principal objectives of the `r survey.das`-day Summer 2021 CCE Survey were to survey the northern stock of Pacific Sardine and the northern and central stocks of Northern Anchovy. Then, as possible, to survey the stocks of Pacific Mackerel, Jack Mackerel, Pacific Herring, Pacific Round Herring, and the southern stock of Pacific Sardine. For the first time, the domain of the CCE survey extended coverage into Mexico. The combined sampling from _`r survey.vessel`_, _Lisa Marie_, _Long Beach Carnage_, Saildrones and _Carranza_, spanned the offshore and nearshore areas from Cape Flattery, WA to Punta Abreojos, MX. The forage fish assemblage was dominated by Jack Mackerel between Westport, WA and Cape Mendocino, CA; Northern Anchovy between Cape Mendocino and El Rosario, MX; and Pacific Sardine between Punta Eugenia, MX and Punta Abreojos, MX. Sardine were virtually absent from catches between Cape Blanco, OR and Monterey Bay, CA, a distance of over 700 km.  

# Disposition of Data {#data-disposition}

```{r calc-raw-size, eval=FALSE}
if (calc.raw.size) {
  # calculate sizes of ER60, EK80, ME70, MS70, and SX90 .RAW files
  ek60.file.size <- sum(dir_info(file.path(survey.dir,'DATA/EK60/RAW'), 
                                 regexp = '.raw$', recursive = T)$size)
  ek80.file.size <- sum(dir_info(file.path(survey.dir,'DATA/EK80/RAW'), 
                                 regexp = '.raw$', recursive = T)$size)
  me70.file.size <- sum(dir_info(file.path(survey.dir,'DATA/ME70/RAW'), 
                                 regexp = '.raw$', recursive = T)$size)
  ms70.file.size <- sum(dir_info(file.path(survey.dir,'DATA/MS70/RAW'), 
                                 regexp = '.raw$', recursive = T)$size)
  sx90.file.size <- sum(dir_info(file.path(survey.dir,'DATA/SX90/RAW'), 
                                 regexp = '.raw$', recursive = T)$size)
  
  save(ek60.file.size, ek80.file.size, me70.file.size, ms70.file.size, sx90.file.size,
       file = here("Output/raw_file_info.Rdata"))
} else {
  load(here("Output/raw_file_info.Rdata"))
}
```  

All raw EK60, EK80, ME70, MS70, SX90, and EC150-3C data, including the EK60 and EK80 calibration data, are archived on the SWFSC data server. For more information, contact: David Demer (Southwest Fisheries Science Center, 8901 La Jolla Shores Drive, La Jolla, California, 92037, U.S.A.; phone: 858-546-5603; email: <david.demer@noaa.gov>).

# Acknowledgements {#acknowledgements}  

We thank the crew members of the NOAA ship _`r survey.vessel`_ and INAPESCA ship _Carranza_, and all of the scientists who participated in the sampling operations at sea. We thank Roberto Vallarta-Zárate and the team from INAPESCA for the processing and dissemination of acoustic and biological sampling data from _Carranza_.  We thank Captains Rick Blair (_Lisa Marie_) and Rich Ashley and Tom Brinton (_Long Beach Carnage_), along with all the F/V crew members, for their coordination and cooperation during the nearshore sampling. We thank Diane Pleschner-Steele for contracting the _Long Beach Carnage_ to conduct the nearshore survey. We thank Dianna Porzio from CDFW for coordinating the biological sampling and for organizing, validating, and disseminating the resulting data. We thank Kristen Hinton and Patrick Biondo from WDFW for the biological sampling at sea aboard _Lisa Marie_; and Kelly Kloos, T. Nguyen, Joel van Noord, and Trevor Stocking from CDFW for sampling aboard _Long Beach Carnage_. Critical reviews by Andrew Thompson improved this report.  

# References {-}  

<div id = 'refs'></div>  

\newpage  

# (APPENDIX) Appendix {-}
# Appendix {-} 
# Centerboard positions {#appendix-cb-pos}

Date, time, and location associated with changes to the position of the centerboard and transducer depth. The information is obtained from event data generated by the ship's bridge, and may not be comprehensive.

```{r cb-pos,results='asis'}
# get centerboard position records
cb.pos <- filter(bridge.snap, 
                 Button %in% c("Retracted (5 m)","Intermediate (7 m)","Extended (9 m)")) %>% 
  select(datetime, Button, Lat, Lon) %>% 
  rename(`Date Time` = datetime, `Position (depth)` = Button, 
         `Latitude` = Lat, `Longitude` = Lon)

if (doc.type == "docx") {
  # create kable object (for Word)
  pander(cb.pos)

} else {
  # print LaTeX table for HTML or PDF
  kable(cb.pos, align = c("l","l","c","c"), digits = c(0,0,4,4),
        escape = F, booktabs = T, linesep = "") %>% 
    kable_styling(position = "center",
                  latex_options = c("striped", "hold_position"))
}
```   

\newpage

# CTD and UCTD sampling locations {#appendix-ctd-sampling}

Times and locations of conductivity and temperature versus depth casts while on station (CTD) and underway (UCTD).  

```{r uctd-sample-table,results='asis'}
# Rename
all.ctds.table <- all.ctds %>% 
  mutate(Button = str_replace(Button, " Cast","")) %>% 
  rename(`Date Time` = Date, `Cast Type` = Button,
         `Latitude` = Latitude, `Longitude` = Longitude)

if (doc.type == "docx") {
  # create flextable object (for Word)
  pander(all.ctds.table)
} else {
  # print LaTeX table for HTML or PDF
  kable(all.ctds.table,
        align = c("l","l","c","c"), 
        digits = c(0,0,4,4),
        escape = F, longtable = T, 
        booktabs = T) %>% 
    kable_styling(position = "center", 
                  latex_options = c("repeat_header","hold_position"))
}
```  

\newpage
\blandscape

# Trawl sample summary {#appendix-trawl-sampling}

Date, time, location at the start of trawling (i.e., at net equilibrium, when the net is fully deployed and begins fishing), and biomasses (kg) of CPS collected for each trawl haul.

```{r trawl-catch-summary,results='asis'}
# Summarize catch by species, used to subset columns
pos.cps <- trawl.summ %>% 
  select(-Haul, -Date, -Latitude, -Longitude, -"All CPS") %>% 
  gather(key = "scientificName", value = "weight") %>% 
  group_by(scientificName) %>% 
  summarise(weight = sum(weight, na.rm = T)) %>% 
  filter(weight != 0) %>% 
  pull(scientificName)

# Select only species with positive catch weight
trawl.summ <- trawl.summ %>% 
  select(Haul, `Date Time` = Date, `Latitude` = Latitude, 
         `Longitude` = Longitude,
         all_of(pos.cps), "All CPS") %>% 
  arrange(Haul)

# Replace zeros with NA
trawl.summ[trawl.summ == 0] <- NA

if (doc.type == "docx") {
  # create kable object (for Word)
  pander(trawl.summ)
} else {
  # print LaTeX table for HTML or PDF
  kable(trawl.summ,escape = F,longtable = T,booktabs = T,
        align = c("r","c",rep("r",ncol(trawl.summ) - 2)),
        digits = c(0,0,4,4,rep(2, ncol(trawl.summ) - 4))) %>% 
    kable_styling(position = "center", 
                  latex_options = c("repeat_header","hold_position"))
}
```  

\elandscape
