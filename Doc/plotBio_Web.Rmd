---
output:
  bookdown::html_document2:
    toc: no
    toc_float: no
    number_sections: no
css: css/ast.css
---

```{r setup,echo=F,message=F,warning=F,error=F,include=F}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,raster,cowplot,DBI,odbc,RSQLite,scatterpie,ggspatial,vroom,
               reshape2,readxl,lubridate,rnaturalearth,sf,rgeos,here,naniar,mapview,
               shadowtext,knitr,ggrepel,fs,plotly,leaflet,leaflet.extras,bookdown,
               leaflet.minicharts,maptools,htmltools,leafem,DT,rworldmap,rworldxtra,
               lwgeom,htmlwidgets,beepr)

# Install and load required packages from Github -------------------------------
# surveyR
pacman::p_load_gh("kstierhoff/surveyR")
# atm
pacman::p_load_gh("kstierhoff/atm")
# rnaturalearth data
pacman::p_load_gh("ropenscilabs/rnaturalearthdata")
pacman::p_load_gh("ropenscilabs/rnaturalearthhires")

# Define method of table generation (whether kable or xtable) for best formatting
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')
doc.name <- knitr::current_input()
if (is.null(doc.type)) {doc.type <- "html"}
if (is.null(doc.name)) {doc.name <- "plotBio_Web.Rmd"}

# global knitr chunk options
knitr::opts_chunk$set(
  echo = FALSE, warning = FALSE, message = FALSE, 
  fig.align = "center", dev = "png", dev.args = list(type = "cairo"), dpi = 150
)
knitr::opts_chunk$set(cache = FALSE)
```

```{r user-input, include=FALSE}
# Get project name from directory
prj.name <- last(unlist(str_split(here(), "/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste0("settings_", prj.name, ".R"))]

source(here("Doc/settings", prj.settings))
```

```{r experimental-vars}
# Set minimum NASC value for plotting
nasc.plot.min    <- 0
```

```{r processing-controls}
# Control script behavior (usually T)
get.nav            <- T # Download NOAA Ship nav data
nav.source         <- "SCS" # Navigation data source: ERDDAP or SCS
save.figs          <- T # Save figures
get.nav.sd         <- F # Download Saildrone nav data from ERDDAP
copy.files         <- T # Copy data files from data to plotBio directory
overwrite.files    <- T # Overwrite existing files when copying (not CSV, see below)
process.csv        <- T # Process acoustic backscatter files
process.csv.krill  <- T # Process krill backscatter files
process.csv.all    <- F # Process all CSV files (F = new files only)
get.db             <- T # Import trawl database

# Are we sampling? If no, F. Skips data processing steps.
sampling.acoustics <- T 
sampling.cufes     <- T 
sampling.trawl     <- T 

# Control script behavior (often F)
resize.map         <- F # Resize map during survey; if T, uses anticipated bounds of survey area
overwrite.csv      <- T # Overwrite existing Echoview CSV files when copying
save.imap          <- F # Save interactive map using "mapshot"
```

```{r config-project}
dir_create(here(), c("Output", "Figs"))
```

```{r copy-files, include=F}
if (copy.files) {
  # Create data directories
  dir_create(here("Data", c("Backscatter","CUFES","Trawl")))
  dir_create(here("Data/Backscatter", nasc.vessels))
  
  # Copy trawl Access database
  haul.db <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/HAUL"),
                    regexp = trawl.db.access)
  file_copy(haul.db, here("Data/Trawl"), overwrite = overwrite.files)
  
  # Copy CUFES files
  cufes.file <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/CUFES")) 
  file_copy(cufes.file, here("Data/CUFES"), overwrite = overwrite.files)
  
  # Copy CSV files for CPS
  csv.files.cps <- dir_ls(file.path(survey.dir[survey.vessel.primary], 
                                    nasc.dir[survey.vessel.primary]), 
                          regexp = nasc.pattern.cps[survey.vessel.primary],
                          ignore.case = TRUE)
  file_copy(csv.files.cps, here("Data/Backscatter", survey.vessel.primary), 
            overwrite = overwrite.csv)
  
  # Copy CSV files for Krill
  csv.files.krill <- dir_ls(file.path(survey.dir[survey.vessel.primary], 
                                      nasc.dir[survey.vessel.primary]), 
                            regexp = nasc.pattern.krill[survey.vessel.primary],
                            ignore.case = FALSE)
  file_copy(csv.files.krill, here("Data/Backscatter", survey.vessel.primary), 
            overwrite = overwrite.csv)
}
```

```{r process-nav}
# Source code to get nav data from ERDDAP or SCS
if (nav.source == "ERDDAP") {
  source(here("Code/get_nav_erddap.R"))
} else if (nav.source == "SCS") {
  source(here("Code/get_nav_scs.R"))
}

# Read transect waypoints
wpts <- read_csv(here("Data/Nav", wpt.filename))

# Convert planned transects to sf; CRS = crs.geog
wpts.sf <- wpts %>% 
  filter(Type %in% wpt.types) %>% 
  st_as_sf(coords = c("Longitude","Latitude"), crs = crs.geog) %>% 
  mutate(
    label = paste("Transect", Transect),
    popup = paste('<b>Transect:</b>', Transect, Type)
  )

transects.sf <- wpts.sf %>% 
  group_by(Type, Transect, Region) %>% 
  summarise(do_union = FALSE) %>% 
  st_cast("LINESTRING") %>% 
  ungroup() %>% 
  mutate(
    distance = round(as.numeric(st_length(.))/1852,1),
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type, '<br/>',
                     'Distance:', distance, 'nmi<br/>')
  )

# Create gps.csv file from nav to replace missing data in Echoview
nav.gps <- nav %>% 
  mutate(GPS_date = format(time, format = "%F"),
         GPS_time = format(time, format = "%T")) %>% 
  select(GPS_date, GPS_time, latitude = lat, longitude = long)

write_csv(nav.gps, here("Output/nav.gps.csv"))

# Get most recent vessel position for plotting
nav.now <- tail(nav.sf, 1) %>% 
  mutate(label = paste("Last position:", time, "UTC"),
         popup = paste0('<b>Vessel name: </b>', survey.vessel, '<br/>',
                        '<b>Last position: </b>', time, ' UTC<br/>'))

# Set padding around data  
if (resize.map) {
  # Use nav data to resize map to survey progress
  map.bounds <- nav.paths.sf %>% 
    st_transform(crs = crs.proj) %>%
    st_bbox()  
} else {
  # Use nav data to resize map to survey progress
  map.bounds <- transects.sf %>%
    st_transform(crs = crs.proj) %>%
    st_bbox()  
}
```

```{r get-saildrone-nav}
if (get.nav.sd) {
  # Load existing nav data
  if (file.exists(here("Data/Nav/nav_data_saildrone.Rdata"))) {
    load(here("Data/Nav/nav_data_saildrone.Rdata"))
    
    # Calculate difference between max nav time and now
    nav.lag.sd <- difftime(now(tzone = "UTC"), max(ymd_hms(nav.sd$datetime)), units = "hours")
    
    # Get new erddap start date from max date
    erddap.survey.start.sd <- paste0(format(max(date(nav.sd$time)), ""), "T00%3A00%3A00Z")
  } else {
    nav.lag.sd <- 24
  }
  
  if (get.nav) {
    # Update only every 24 h to reduce processing time, especially at sea
    if (nav.lag.sd >= 24) {
      # Generate ERDDAP URL
      saildroneURL <- URLencode(paste0(
        erddap.url.sd, ".csv0?", erddap.vars.sd,
        "&time%3E=", erddap.survey.start.sd, "&time%3C=", erddap.survey.end.sd))
      
      # Download and parse ERDDAP nav data
      nav.temp.sd <- read_csv(saildroneURL, lazy = FALSE,
                              col_names = erddap.headers.sd) %>% 
        mutate(datetime = ymd_hms(time)) %>%
        filter(!is.nan(lat), !is.nan(long)) %>%
        filter(long != 0, lat != 0)
      
      # Append new nav data
      if (exists("nav.sd")) {
        nav.sd <- bind_rows(nav.sd, nav.temp.sd) %>% 
          distinct()
      } else {
        nav.sd <- nav.temp.sd
      }
    }
    
    # Convert saildrone nav to spatial
    nav.sd.sf <- st_as_sf(nav.sd, coords = c("long","lat"), crs = crs.geog)
    
    # Get most recent vessel position for plotting
    nav.now.sd <- nav.sd.sf %>% 
      group_by(saildrone) %>% 
      slice(n()) %>% 
      mutate(label = paste("Saildrone", saildrone, "Last position:", datetime, "UTC"),
             popup = paste0('<b>Saildrone: </b>', saildrone, '<br/>',
                            '<b>Last position: </b>', datetime, ' UTC<br/>'))
    
    # Convert saildrone nav to spatial
    nav.sd.paths.sf <- nav.sd.sf %>% 
      group_by(saildrone) %>% 
      summarise(do_union = FALSE) %>% 
      st_cast("LINESTRING") %>% 
      mutate(tracklength = st_length(.))
    
    # Save nav data
    save(nav.sd, nav.sd.sf, nav.sd.paths.sf, nav.now.sd, 
         file = here("Data/NAV/nav_data_saildrone.Rdata"))
    
    # Create gps.csv files from ERDDAP data
    for (i in unique(nav.sd$saildrone)) {
      saildrone.gps <- filter(nav.sd, saildrone == i) %>% 
        mutate(GPS_date = format(datetime, format = "%F"),
               GPS_time = format(datetime, format = "%T")) %>% 
        select(GPS_date, GPS_time, latitude = lat, longitude = long)
      
      write_csv(saildrone.gps, here("Output", paste(i, "_erddap.gps.csv", sep = "")))
    }
  } else {
    # Load nav data
    load(here("Data/NAV/nav_data_saildrone.Rdata"))
  }
}
```

```{r import-trawl-data}
if (sampling.trawl) {
  if (get.db) {
    if (trawl.source == "SQL") {
      # Configure ODBC connection to TRAWL database
      trawl.channel  <- dbConnect(odbc(), 
                                  Driver = "SQL Server", 
                                  Server = "161.55.235.187", 
                                  Database = "TRAWL", 
                                  Trusted_Connection = "True")
    } else if (trawl.source == "Access") {
      trawl.channel  <- dbConnect(odbc::odbc(), 
                                  Driver = "Microsoft Access Driver (*.mdb, *.accdb)", 
                                  DBQ = file.path(here("Data/Trawl"),trawl.db.access))
    }
    
    # Import trawl database tables
    catch.all	     <- tbl(trawl.channel,"Catch") %>% collect()
    haul.all       <- tbl(trawl.channel,"Haul") %>% collect()
    lengths.all    <- tbl(trawl.channel,"Specimen") %>% collect()
    lengthFreq.all <- tbl(trawl.channel,"LengthFrequency") %>% collect()
    spp.codes      <- tbl(trawl.channel,"SpeciesCodes") %>% collect()
    
    # Close database channel
    dbDisconnect(trawl.channel)
    
    # Save imported database data to .Rdata file
    save(catch.all, haul.all, lengths.all, spp.codes, lengthFreq.all, 
         file = here("Data/Trawl/trawl_data.Rdata"))
  } else {
    # Load data
    load(here("Data/Trawl/trawl_data.Rdata"))
  } 
} 
```  

```{r process-haul-data}
if (sampling.trawl) {
  # Create startLatitudeDecimal and startLongitudeDecimal for Access data
  if (trawl.source == "Access") {
    if (year(haul.all$netInWaterTime[1]) >= 2021) {
      haul <- haul.all %>% 
        arrange(haul) %>% 
        mutate(
          startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
          startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
          stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
          stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60))) 
      
    } else {
      haul <- haul.all %>% 
        arrange(haul) %>% 
        mutate(
          startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
          startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
          stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
          stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60)), 
          equilibriumTime  =   ymd_hms(paste(as.character(trawlDate),
                                             format(haul.all$EquilibriumTime,
                                                    format = "%H:%M:%S"))),
          haulBackTime     =   ymd_hms(paste(as.character(trawlDate),
                                             format(haul.all$haulbackTime,
                                                    format = "%H:%M:%S")))) %>%
        mutate(haulBackTime = case_when(
          haulBackTime < equilibriumTime ~ haulBackTime + days(1),
          TRUE ~ haulBackTime)) %>%
        rename(cruise = Cruise, ship = Ship, haul = Haul,
               collection = Collection, notes = Notes)
      
      # Identify hauls where date of equilibriumTime or haulBackTime is incorrect
      eq.fix <- which(c(0, diff(haul$equilibriumTime)) < 0)
      hb.fix <- which(c(0, diff(haul$haulBackTime)) < 0)
      
      # Correct equilibriumTime or haulBackTime
      haul$equilibriumTime[eq.fix] <- haul$equilibriumTime[eq.fix] + days(1)
      haul$haulBackTime[eq.fix]    <- haul$haulBackTime[eq.fix] + days(1)
    }
    
  } else if (trawl.source == "SQL") {
    # Filter haul data for current survey
    haul <- haul.all %>% 
      arrange(haul) %>% 
      mutate(equilibriumTime = ymd_hms(equilibriumTime),
             haulBackTime    = ymd_hms(haulBackTime)) %>% 
      select(cruise,ship,haul,collection,startLatDecimal,startLongDecimal,stopLatDecimal,
             stopLongDecimal,equilibriumTime,haulBackTime,trawlPerformance,notes) %>% 
      filter(cruise %in% cruise.name & ship %in% cruise.ship) 
    
  } else if (trawl.source == "Excel") {
    # Format haul data
    haul.all <- haul.all %>% 
      mutate(
        startLatDecimal  =   DecLatitude,
        startLongDecimal =   DecLongitude,
        stopLatDecimal   =   DecLatitude,
        stopLongDecimal  =   DecLongitude,
        equilibriumTime  =   mdy_hms(paste(as.character(trawlDate),
                                           format(haul.all$EquilibriumTime, 
                                                  format = "%H:%M:%S"))),
        haulBackTime     =   equilibriumTime + minutes(`Duration(dec)`*60))
    
    # Filter haul data for current survey
    haul <- haul.all %>% 
      select(cruise = Cruise,ship = Ship,haul = Haul,collection = Collection,
             startLatDecimal,startLongDecimal,stopLatDecimal,
             stopLongDecimal,equilibriumTime,haulBackTime)
  }
  
  haul <- haul %>% 
    filter(cruise %in% cruise.name & ship %in% cruise.ship) %>% 
    # Remove bad trawls
    filter(!trawlPerformance %in% trawl.performance) %>% 
    arrange(haul) %>% 
    mutate(duration = difftime(haulBackTime, equilibriumTime, units = "mins"), # Calculate duration
           cluster  = cumsum(c(0, diff(equilibriumTime)) > 12) + 1,
           leg      = cut(as.numeric(date(equilibriumTime)), leg.breaks, labels = FALSE))  
  
  # Find midpoint of each haul as the mean lat/long
  haul.mid <- haul %>% 
    group_by(cluster, haul) %>% 
    summarise(
      lat  = mean(c(startLatDecimal, stopLatDecimal)),
      long = mean(c(startLongDecimal, stopLongDecimal))) 
  
  # Find midpoint of each haul cluster as the average of haul midpoints
  cluster.mid <- haul.mid %>% 
    group_by(cluster) %>% 
    summarise(
      lat  = mean(lat),
      long = mean(long))
  
  # Save haul data
  save(haul, file = here("Output/haul_info.Rdata")) 
}
```  

```{r process-catch-data, message=FALSE}
if (sampling.trawl) {
  # Filter catch data
  catch <- catch.all %>% 
    left_join(select(spp.codes, species, scientificName, commonName)) %>% 
    filter(cruise %in% cruise.name & ship %in% cruise.ship & 
             scientificName %in% cps.spp & netSampleType == 'codend') %>% 
    left_join(select(haul, haul, cluster)) %>% 
    mutate(key = paste(haul, scientificName),
           totalWeight = subSampleWtkg + remainingSubSampleWtkg)
  
  if (nrow(catch) > 0) {
    # Summarize trawl catch by species
    haul.summ.wt <- catch %>% 
      select(haul, cluster, scientificName, totalWeight) %>% 
      tidyr::spread(scientificName, totalWeight) 
    
    # Add species with zero total weight
    if (!has_name(haul.summ.wt, "Engraulis mordax"))      {haul.summ.wt$`Engraulis mordax`      <- 0}
    if (!has_name(haul.summ.wt, "Sardinops sagax"))       {haul.summ.wt$`Sardinops sagax`       <- 0}
    if (!has_name(haul.summ.wt, "Scomber japonicus"))     {haul.summ.wt$`Scomber japonicus`     <- 0}
    if (!has_name(haul.summ.wt, "Trachurus symmetricus")) {haul.summ.wt$`Trachurus symmetricus` <- 0}
    if (!has_name(haul.summ.wt, "Clupea pallasii"))       {haul.summ.wt$`Clupea pallasii`       <- 0}
    if (!has_name(haul.summ.wt, "Atherinopsis californiensis")) {haul.summ.wt$`Atherinopsis californiensis` <- 0}
    if (!has_name(haul.summ.wt, "Etrumeus acuminatus")) {haul.summ.wt$`Etrumeus acuminatus` <- 0}
    
    # Calculate total weight of all CPS species
    haul.summ.wt <- haul.summ.wt %>%  
      replace(is.na(.), 0) %>% 
      mutate(AllCPS = rowSums(select(., -haul, -cluster))) %>%
      # mutate(AllCPS = rowSums(.[, 3:ncol(.)])) %>%
      rename("Jacksmelt"  = "Atherinopsis californiensis",
             "PacHerring" = "Clupea pallasii",
             "Anchovy"    = "Engraulis mordax",
             "Sardine"    = "Sardinops sagax",
             "PacMack"    = "Scomber japonicus",
             "JackMack"   = "Trachurus symmetricus",
             "RndHerring" = "Etrumeus acuminatus") 
    
    # Summarise catch by cluster
    cluster.summ.wt <- haul.summ.wt %>% 
      select(-haul, -AllCPS) %>% 
      group_by(cluster) %>% 
      summarise_all(list(sum)) %>% 
      mutate(AllCPS = rowSums(select(., -cluster))) %>% 
      right_join(cluster.mid) %>% 
      replace(is.na(.), 0)
    
    # Add lat/long to haul summary for plotting
    haul.summ.wt <- haul.summ.wt %>% 
      right_join(haul.mid) %>% 
      replace(is.na(.), 0)
    
  } else {
    # Summarize trawl catch by species
    haul.summ.wt <- bind_cols(select(haul, haul, cluster),
                              data.frame(
                                "Jacksmelt"  = rep(0, nrow(haul)),
                                "PacHerring" = rep(0, nrow(haul)),
                                "Anchovy"    = rep(0, nrow(haul)),
                                "Sardine"    = rep(0, nrow(haul)),
                                "PacMack"    = rep(0, nrow(haul)),
                                "JackMack"   = rep(0, nrow(haul)),
                                "RndHerring" = rep(0, nrow(haul)),
                                "AllCPS"     = rep(0, nrow(haul)))) %>% 
      right_join(haul.mid)
    
    # Summarise catch by cluster
    cluster.summ.wt <- haul.summ.wt %>% 
      select(-haul, -AllCPS) %>% 
      group_by(cluster) %>% 
      summarise_all(list(sum)) %>% 
      mutate(AllCPS = rowSums(select(., -cluster))) %>%
      right_join(cluster.mid) %>% 
      replace(is.na(.), 0)
  }
  
  # Prepare catch data for plotting ----------------------------------------------
  # Select and rename trawl data for pie charts
  haul.pie <- haul.summ.wt %>% 
    select(haul, long, lat, Anchovy, JackMack, 
           Jacksmelt, PacHerring, PacMack, RndHerring, Sardine, AllCPS) %>%
    # Create bins for defining point size in NASC plots
    mutate(bin       = cut(AllCPS, trawl.breaks, include.lowest = TRUE),
           bin.level = as.numeric(bin)) %>% 
    project_df(to = crs.proj)
  
  cluster.pie <- cluster.summ.wt %>% 
    select(cluster, long, lat, Anchovy, JackMack, 
           Jacksmelt, PacHerring, PacMack, RndHerring, Sardine, AllCPS) %>% 
    # Create bins for defining point size in NASC plots
    mutate(bin       = cut(AllCPS, trawl.breaks, include.lowest = TRUE),
           bin.level =  as.numeric(bin)) %>% 
    project_df(to = crs.proj)
  
  # Filter for empty trawls
  haul.zero    <- filter(haul.pie, AllCPS == 0)
  
  cluster.zero <- filter(cluster.pie, AllCPS == 0)
  
  # Calculate pie radius based on latitude range
  pie.radius <- as.numeric(abs(map.bounds$ymin - map.bounds$ymax)*pie.scale)
  
  # Calculate pie radius of each pie, based on All CPS landings
  if (scale.pies) {
    haul.pie$r    <- pie.radius*log(haul.pie$bin.level+1)
    cluster.pie$r <- pie.radius*log(cluster.pie$bin.level+1)
  } else {
    haul.pie$r    <- pie.radius
    cluster.pie$r <- pie.radius
  }
  
  # Filter for positive hauls and clusters
  haul.pos <- filter(haul.pie, AllCPS > 0) %>% 
    arrange(desc(X))
  
  cluster.pos <- filter(cluster.pie, AllCPS > 0) %>% 
    arrange(desc(X))
  
  # Substitute very small value for species with zero catch, just for pie charts
  if (nrow(haul.pos) > 0) {
    haul.pos <- haul.pos %>% 
      replace(. == 0, 0.0000001) 
    
    cluster.pos <- cluster.pos %>% 
      replace(. == 0, 0.0000001) 
  }
  
  # Convert haul data for plotting
  haul.catch <- haul.summ.wt %>% 
    st_as_sf(coords = c("long", "lat"), crs = crs.geog) 
  
  haul.catch <- project_sf(haul.catch, crs = crs.proj) 
}

# Save haul and cluster data
save(haul.pie, cluster.pie, haul.pos, cluster.pos, haul.zero, cluster.zero,
     file = here("Output/trawl_pie_plotBio.Rdata"))
```

```{r process-cufes}
if (sampling.cufes) {
  # Read CUFES data
  cufes.filename <- list.files(here("Data/CUFES"), pattern = "*.sqlite")
  cufes.con      <- dbConnect(SQLite(), dbname = here("Data/CUFES", cufes.db.sqlite))
  cufes.raw      <- tbl(cufes.con, "cufessqlite") %>%
    collect() %>% 
    mutate(
      Start = case_when(
        cufes.date.format == "mdy" ~ mdy_hms(Start), #"06/01/2019-15:43:00"
        cufes.date.format == "ymd" ~ ymd_hms(Start)),#"1996-03-15 15:43:00 -08:00"
      Stop = case_when(
        cufes.date.format == "mdy" ~ mdy_hms(Stop), #"06/01/2019-15:43:00"
        cufes.date.format == "ymd" ~ ymd_hms(Stop)),#"1996-03-15 15:43:00 -08:00"
      Duration = as.numeric(difftime(Stop, Start, units = "mins")),
      Year = year(Start),
      AllEggs = SardineEggs + AnchovyEggs + JackMackerelEggs,
      leg = cut(as.numeric(date(Start)), leg.breaks, 
                                labels = FALSE)) %>% 
    rename(lat = StartLatitude, long = StartLongitude) %>%
    filter(!is.na(lat), !is.na(long), !is.na(Stop)) %>% 
    project_df(to = crs.proj)
  
  # Close connection
  dbDisconnect(cufes.con)
  
  # save raw cufes table to CSV
  write_csv(cufes.raw, file = here("Output/cufes_raw.csv"))
  
  # Process CUFES data
  cufes <- cufes.raw %>% 
    # Convert cufes to long format for plotting
    select(
      SampleNumber, Year, Ship, Cruise, lat, long, X, Y, Duration, 
      SardineEggs, AnchovyEggs, JackMackerelEggs, SquidEggs, HakeEggs, OtherFishEggs,
      Comments) %>%
    gather(Species, Counts, -SampleNumber, -Year, -Ship, -Cruise, 
           -lat, -long, -X, -Y, -Duration, -Comments) %>% 
    mutate(Density = Counts/Duration/0.64,
           # Create bins for defining point size in NASC plots
           bin = cut(Density, cufes.breaks, include.lowest = TRUE),
           bin.level = as.numeric(bin)) %>% 
    left_join(select(cufes.raw, SampleNumber, Start, Stop, leg)) 
  
  if (exists("cufes.date.range")) {
    if (!is.na(cufes.date.range["start"])) {
      cufes <- cufes %>% 
        filter(between(Start, cufes.date.range["start"], cufes.date.range["stop"]))
    }
  }
  
  # Save processed cufes to CSV
  write_csv(cufes, file = here("Output/cufes_proc.csv"))
  
  # Prepare CUFES data for plotting ----------------------------------------------
  # Select CUFES sample with zero density for plotting
  cufes.neg <- filter(cufes.raw, AllEggs == 0) %>% 
    mutate(bin.level = 1) %>% 
    select(X, Y, Start, SampleNumber)
  
  if (exists("cufes.date.range")) {
    if (!is.na(cufes.date.range["start"])) {
      cufes.neg <- cufes.neg %>% 
        filter(between(Start, cufes.date.range["start"], cufes.date.range["stop"]))
    }
  }
  
  # Identify bad CUFES samples
  cufes.bad <- filter(cufes.raw, Duration <= 0)
  
  save(cufes.bad, file = here("Output/cufes_bad.Rdata"))
  
  # Remove bad samples from CUFES
  cufes <- cufes %>% 
    filter(!SampleNumber %in% cufes.bad$SampleNumber)
  
  # Write CUFES data from current survey to CSV
  write_csv(cufes, file = here("Output/cufes_data.csv"))
  
  # Create bins for defining point size in NASC plots
  cufes <- cufes %>% 
    mutate(bin = cut(Density, cufes.breaks, include.lowest = TRUE),
           bin.level = as.numeric(bin))
  
  # Project CUFES data from CPS
  cufes.plot <- cufes %>% 
    filter(Density > 0, Species %in% cufes.plot.spp) %>%
    arrange(desc(Density))
  
  # Project CUFES data from squid
  cufes.plot.squid <- cufes %>% 
    filter(Density > 0, Species == "SquidEggs") %>% 
    arrange(desc(Density))
  
  # Project CUFES data from other fish eggs (mostly P. mackerel)
  cufes.plot.ofe <- cufes %>% 
    filter(Density > 0, Species == "OtherFishEggs") %>%
    filter(str_detect(Comments, c("Scomber japonicus","scomber japonicus",
                                  "S. japonicus"))) %>% 
    arrange(desc(Density))  
}
```  

```{r process-csv-cps}
if (sampling.acoustics) {
  
  # Get fileSnapshot at the beginning of the knit, to compare with the end of the last knit
  csv.snapshot.start <- fileSnapshot(here("Data/Backscatter", survey.vessel.primary),
                                     full.names = FALSE)
  
  # Load fileSnapshot from last knit, or make equal to the start
  if (file.exists(here("Output/csv_snapshot_end.rds"))){
    # saveRDS(csv.snapshot.start, here("Output/csv_snapshot_end.rds"))
    csv.snapshot.end <- readRDS(here("Output/csv_snapshot_end.rds"))
  } else {
    csv.snapshot.end <- csv.snapshot.start
  }
  
  # Identify new and changed files
  csv.changed    <- changedFiles(csv.snapshot.end, csv.snapshot.start) 
  # List files that need to be processed
  csv.to.process <- c(csv.changed$changed, csv.changed$added)
  
  if (process.csv) {
    # Process added and changed CSV files --------------------------
    # List all CSV files
    csv.files.cps <- dir_ls(here("Data/Backscatter", survey.vessel.primary), 
                            regexp = nasc.pattern.cps[survey.vessel.primary],
                            ignore.case = TRUE)
    
    if (process.csv.all) {
      # Create an empty data frame
      nasc.cps <- data.frame()
      
    } else {
      if (file.exists(here("Output/nasc_cps.Rdata"))) {
        # Load data frame with already processed backscatter data
        load(here("Output/nasc_cps.Rdata")) 
        
        if (length(csv.changed$changed) > 0) {
          # If files have changed, remove those data
          nasc.cps <- nasc.cps %>% 
            filter(!path_file(filename) %in% path_file(fs_path(csv.changed$changed))) 
        }
      } else {
        # Create an empty data frame
        nasc.cps <- data.frame()
      }
      
      if (length(csv.to.process) > 0) {
        # List only new CSV files
        csv.files.cps <- csv.files.cps[fs::path_file(csv.files.cps) %in% 
                                         path_file(fs_path(csv.to.process))]  
      } else {
        # Set length of csv.files.cps to zero
        csv.files.cps <- character(0)
      }
    }
    
    if (length(csv.files.cps) > 0) {
      # Configure progress bar
      pb <- winProgressBar(title = "CSV File Processing Progress - CPS", 
                           label = "0% done", min = 0, max = 100, initial = 0)
      
      # Process all .CSV files
      for (i in 1:length(csv.files.cps)) {
        # Process i-th file
        nasc.cps <- bind_rows(nasc.cps, extract_csv(csv.files.cps[i]))
        
        # Update the progress bar
        info <- sprintf("%d%% done", round((i / length(csv.files.cps)) * 100))
        setWinProgressBar(pb, round((i / length(csv.files.cps)) * 100), label = info)
      }
      close(pb)
      
      # Calculate summary interval
      nasc.cps <- nasc.cps %>%
        mutate(int = cut(Interval, seq(1, max(Interval) + nasc.summ.interval, nasc.summ.interval),
                         labels = FALSE, include.lowest = TRUE),
               leg = cut(as.numeric(date(datetime)), leg.breaks, labels = FALSE)) %>% 
        arrange(datetime)
      
      # Save results
      save(nasc.cps, file = here("Output/nasc_cps.Rdata"))
      write_csv(nasc.cps, file = here("Output/nasc_cps.csv"))
    }
    
    # Save snapshot
    saveRDS(csv.snapshot.start, here("Output/csv_snapshot_end.rds"))
    
  } else {
    load(here("Output/nasc_cps.Rdata"))
  }
  
  # Get intervals with bad lat/long values
  bad.nasc.cps <- filter(nasc.cps, lat == 999, long == 999)
  write_csv(bad.nasc.cps, here("Output/nasc_bad_cps.csv"))
  
  # If missing, set cps.nasc to fixed depth using supplied variable
  if (is.null(nasc.cps$cps.nasc)) {
    nasc.cps$cps.nasc <- nasc.cps[ , nasc.depth.cps]
  }
  
  # average NASC data over new intervals or number of intervals in a 2 km radius
  nasc.summ.cps <- nasc.cps %>%
    filter(lat != 999, long != 999) %>% 
    group_by(transect, int) %>%
    summarise(
      bins    = length(int),
      bin.mid = as.integer(round(bins / 2)),
      lat     = lat[1],
      long    = long[1],
      NASC    = mean(cps.nasc)
    )
  
  # Average cps.nasc over defined interval
  # Summarize by filename, not transect, so that renamed (i.e., strip.tx.chars == TRUE) transects get included.
  nasc.cps.sf <- nasc.cps %>%
    filter(lat != 999, long != 999) %>%
    select(filename, transect, int, dist_m, datetime, lat, long, cps.nasc) %>% 
    group_by(filename, transect, int) %>% 
    summarise(
      lat   = lat[1],
      long  = long[1],
      NASC  = mean(cps.nasc),
      label = paste0('Transect: ', transect[1], "; ",
                     'Distance: ', round(min(dist_m)), "-", round(max(dist_m)), ' m'),
      popup = paste0('<b>Transect: </b>', transect[1], '<br/>',
                     '<b>Time: </b>', min(datetime), " - ", max(datetime), ' UTC<br/>',
                     '<b>Distance: </b>', round(min(dist_m)), "-", round(max(dist_m)), ' m<br/>',
                     '<b>Latitude: </b>', round(lat,4), ", ", '<b>Longitude: </b>', round(long,4), '<br/>',
                     '<b>NASC: </b>', round(mean(NASC)), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>%
    # Create bins for defining point size in NASC plots
    mutate(bin       = cut(NASC, nasc.breaks, include.lowest = TRUE),
           bin.level =  as.numeric(bin)) %>% 
    filter(!is.na(bin)) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) 
  
  nasc.plot.cps <- project_sf(nasc.cps.sf, crs.proj)
  
  # create acoustic transect labels
  nasc.tx.labels.cps <- nasc.cps %>%
    group_by(transect) %>%
    summarise(
      lat = lat[which.max(long)],
      long = max(long)
    )
  
  # Combine all backscatter data
  nasc.all <- nasc.cps
  
  # Create file for selecting levels for backscatter plot
  nasc.plot.all   <- nasc.cps.sf %>% 
    filter(NASC >= nasc.plot.min) 
}
```

```{r process-csv-krill}
if (sampling.acoustics) {
  if (process.csv.krill) {
    if (process.csv) {
      if (!process.csv.all) {
        if (file.exists(here("Output/processed_krill.Rdata"))) {
          # Load already processed CSV files
          load(here("Output/processed_krill.Rdata"))
        }
      }
      
      # List local CSV files
      csv.files.krill <- dir_ls(here("Data/Backscatter", survey.vessel.primary), 
                                regexp = nasc.pattern.krill[survey.vessel.primary],
                                ignore.case = TRUE)
      
      if (process.csv.all) {
        # Create final data frame
        nasc.krill <- data.frame()
      } else {
        if (file.exists(here("Output/nasc_krill.Rdata"))) {
          # Load already processed files
          load(here("Output/nasc_krill.Rdata")) 
        } else {
          # Create final data frame
          nasc.krill <- data.frame()
        }
        
        if (exists("processed.krill")) {
          # List only new CSV files
          csv.files.krill <- csv.files.krill[!fs::path_file(csv.files.krill) %in% processed.krill]  
        }
      }
      
      if (length(csv.files.krill) > 0) {
        # Configure progress bar
        pb <- winProgressBar(title = "CSV File Processing Progress - Krill", 
                             label = "0% done", min = 0, max = 100, initial = 0)
        
        # Process all .CSV files
        for (i in 1:length(csv.files.krill)) {
          # Process i-th file
          nasc.krill <- bind_rows(nasc.krill, extract_csv(csv.files.krill[i]))
          
          # Update the progress bar
          info <- sprintf("%d%% done", round((i / length(csv.files.krill)) * 100))
          setWinProgressBar(pb, round((i / length(csv.files.krill)) * 100), label = info)
        }
        close(pb)
        
        # Calculate summary interval
        nasc.krill <- nasc.krill %>%
          mutate(int = cut(Interval, seq(1, max(Interval) + nasc.summ.interval, nasc.summ.interval),
                           labels = FALSE, include.lowest = TRUE)) 
        
        # Save results
        save(nasc.krill, file = here("Output/nasc_krill.Rdata"))
        write_csv(nasc.krill, file = here("Output/nasc_krill.csv"))
      }
    } else {
      load(here("Output/nasc_krill.Rdata"))
    }
    
    # Get intervals with bad lat/long values
    bad.nasc.krill <- filter(nasc.krill, lat == 999, long == 999)
    write_csv(bad.nasc.krill, here("Output/nasc_bad_krill.csv"))
    
    # If missing, set krill.nasc to fixed depth using supplied variable
    if (is.null(nasc.krill$krill.nasc)) {
      nasc.krill$krill.nasc <- nasc.krill[ , nasc.depth.krill]
    }
    
    # Average NASC data over new intervals or number of intervals in a 2 km radius
    nasc.summ.krill <- nasc.krill %>%
      filter(lat != 999, long != 999) %>%
      group_by(transect, int) %>%
      summarise(
        bins    = length(int),
        bin.mid = as.integer(round(bins / 2)),
        lat     = lat[1],
        long    = long[1],
        NASC    = mean(krill.nasc)
      )
    
    # Average krill.nasc over defined interval
    # Summarize by filename, not transect, so that renamed (i.e., strip.tx.chars == TRUE) transects get included.
    nasc.krill.sf <- nasc.krill %>%
      filter(lat != 999, long != 999) %>%
      select(filename, transect, int, dist_m, datetime, lat, long, krill.nasc) %>% 
      group_by(filename, transect, int) %>% 
      summarise(
        lat   = lat[1],
        long  = long[1],
        NASC  = mean(krill.nasc),
        label = paste0('Transect: ', transect[1], "; ",
                       'Distance: ', round(min(dist_m)), "-", round(max(dist_m)), ' m'),
        popup = paste0('<b>Transect: </b>', transect[1], '<br/>',
                       '<b>Time: </b>', min(datetime), " - ", max(datetime), ' UTC<br/>',
                       '<b>Latitude: </b>', round(lat,4), ", ", '<b>Longitude: </b>', round(long,4), '<br/>',
                       '<b>Distance: </b>', round(min(dist_m)), "-", round(max(dist_m)), ' m<br/>',
                       '<b>NASC: </b>', round(mean(NASC)), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>%
      # Create bins for defining point size in NASC plots%>% 
      mutate(bin       = cut(NASC, nasc.breaks, include.lowest = TRUE),
             bin.level =  as.numeric(bin))  %>% 
      filter(!is.na(bin)) %>% 
      st_as_sf(coords = c("long","lat"), crs = crs.geog) 
    
    nasc.plot.krill <- project_sf(nasc.krill.sf, crs.proj)
    
    # create acoustic transect labels
    nasc.tx.labels.krill <- nasc.krill %>%
      group_by(transect) %>%
      summarise(
        lat = lat[which.max(long)],
        long = max(long)
      )
    
    # List already processed CSV files and save
    processed.krill <- unique(fs::path_file(nasc.krill$filename))
    save(processed.krill, file =  here("Output/processed_krill.Rdata"))
    
    # Combine all backscatter data
    nasc.all <- bind_rows(nasc.all, nasc.krill)
    
    # Select plot levels for backscatter data
    nasc.plot.all   <- rbind(nasc.plot.all, nasc.krill.sf) %>% 
      filter(NASC >= nasc.plot.min)  
  }
}
```

```{r find-big-nasc}
if (exists("nasc.all")) {
  # Select top 200 nasc values and look for outliers
  big.nasc <- nasc.all %>%
    arrange(desc(NASC)) %>%
    mutate(NASC  = NASC/19,
           rank  = seq(n()),
           label = paste0('Transect: ', transect, 
                          ' - Distance: ', round(dist_m), " m"),
           popup = paste0('<b>Transect: </b>', transect, '<br/>', 
                          '<b>Time: </b>', min(datetime), "-", max(datetime), ' UTC<br/>',
                          '<b>Distance: </b>', round(dist_m), ' m<br/>',
                          '<b>Latitude: </b>', round(lat,4), ", ", '<b>Longitude: </b>', round(long,4), '<br/>',
                          '<b>NASC: </b>', round(NASC), ' m<sup>2</sup> nmi<sup>-2</sup>')) %>% 
    top_n(100, NASC) %>% 
    select(rank, NASC, label, popup, type, datetime, dist_m, lat, long) 
  
  # Save NASC outliers
  save(big.nasc, file = here("Output/nasc_big.Rdata"))  
}
```

```{r create-basemap,include=F}
# Configure base map options -----------------
# Import landmarks
locations <- filter(read.csv(here("Data/Map/locations.csv")), name %in% label.list) %>%
  project_df(to = crs.proj)

# Get state data
states <- ne_states(country = 'United States of America', returnclass = 'sf')
ca     <- filter(states, name == "California")

# Get countries
countries <- ne_countries(scale = "large", returnclass = "sf") %>%
  filter(subregion %in% c("Northern America","Central America"))

# Read bathy contours shapefile 
bathy <- st_read(here("Data/GIS/bathy_contours.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = Contour)

# Determine map aspect ratio and set height and width
map.aspect <- (map.bounds$xmax - map.bounds$xmin)/(map.bounds$ymax - map.bounds$ymin)
map.height <- 10
map.width  <- map.height*map.aspect

# Create base map
base.map <- get_basemap(nav.paths.sf, states, countries, locations, bathy, map.bounds, crs = crs.proj) 

# Save the basemap
ggsave(base.map, file = here("Figs/fig_basemap.png"), 
       height = map.height, width = map.width)

save(base.map, file = here("Data/Map/basemap.Rdata"))
```

```{r create-static-maps}
if (save.figs) {
  # Create maps of backscatter, trawl catch, and CUFES egg density
  if (sampling.acoustics) {
    source(here("Code/plot_sA_CPS.R"))
    if (exists("nasc.krill")) {
      source(here("Code/plot_sA_Krill.R"))   
    }
  }
  
  if (sampling.cufes) {
    source(here("Code/plot_cufes.R"))
  }
  
  if (sampling.trawl) {
    source(here("Code/plot_haul_proportion_wt.R"))
    source(here("Code/plot_cluster_proportion_wt.R"))    
  }
  
  # Combine all plots
  if (sampling.acoustics & sampling.cufes & sampling.trawl) {
    nasc.cufes.haul.wt <- plot_grid(nasc.map.cps, cufes.density.all, trawl.pie.haul.wt, 
                                    nrow = 1, labels = c("a)", "b)", "c)")) 
    
    # Save composite plot
    ggsave(nasc.cufes.haul.wt,
           filename = here("Figs/fig_nasc_cufes_haul_wt.png"),
           width = map.width*3, height = map.height)  
  }
} 
```

```{r get-spatial-files,include=F}
# Import shapefiles ------------------------------------------------
# Read CA State Waters shapefile
ca_waters <- st_read(here("Data/GIS/ca_state_waters.shp")) %>% 
  st_transform(crs.geog)

or_waters <- st_read(here("Data/GIS/or_state_waters.shp")) %>% 
  st_transform(crs.geog)

# Read CA MPAs shapefile
ca_mpas <- st_read(here("Data/GIS/ca_mpas.shp")) %>% 
  st_transform(crs.geog) %>% 
  mutate(MPA = paste(NAME, Type))

or_mpas <- st_read(here("Data/GIS/or_mpas.shp")) %>% 
  st_transform(crs.geog) 

wc_mpas <- st_read(here("Data/GIS/wc_mpas.shp")) %>% 
  st_transform(crs.geog) 

baja_mpas <- st_read(here("Data/GIS/baja_mpas.shp")) %>% 
  st_transform(crs.geog) 

# Read CA MPAs shapefile
eez_usa <- st_read(here("Data/GIS/eez_us.shp")) %>% 
  st_transform(crs.geog)
eez_can <- st_read(here("Data/GIS/eez_canada.shp")) %>% 
  st_transform(crs.geog)
eez_mex <- st_read(here("Data/GIS/eez_mex.shp")) %>% 
  st_transform(crs.geog)

if (sampling.acoustics) {
  # Create spatial objects -------------------------------------------
  # Convert NASC data to sf; CRS = crs.geog (WGS84)
  big.nasc.sf <- big.nasc %>% 
    top_n(20, NASC) %>%
    mutate(popup = paste(label, ": ", round(NASC),
                         " m<sup>2</sup> nmi<sup>-2</sup>",
                         sep = "")) %>%
    st_as_sf(coords = c("long","lat"), crs = crs.geog)
}

if (sampling.trawl) {
  # Convert haul paths and midpoints to sf; CRS = crs.geog
  # Create haul paths from starts and ends
  haul.paths <- select(haul, haul, lat = startLatDecimal, long = startLongDecimal) %>% 
    bind_rows(select(haul, haul, lat = stopLatDecimal, long = stopLongDecimal)) %>% 
    arrange(haul) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    group_by(haul) %>% 
    summarise(do_union = FALSE) %>% 
    st_cast("LINESTRING") %>% 
    left_join(select(haul.catch, -X, -Y, -cluster)) %>% 
    replace(is.na(.), 0) %>% 
    mutate(
      distance = round(as.numeric(st_length(.))/1852,1),
      label    = paste("Haul", haul),
      popup    = paste('<b>Haul:', haul, '</b><br/>',
                       'Anchovy:', Anchovy, 'kg<br/>',
                       'Sardine:', Sardine, 'kg<br/>',
                       'Jack Mackerel:', JackMack, 'kg<br/>',
                       'P. herring:', PacHerring, 'kg<br/>',
                       'P. mackerel:', PacMack, 'kg<br/>',
                       'All CPS:', AllCPS, 'kg'))
  
  haul.locs.sf <- haul.mid %>% 
    mutate(label = paste("Haul", haul)) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) 
  
  cluster.locs.sf <- cluster.mid %>% 
    mutate(label = paste("Cluster", cluster)) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) 
  
  # Convert haul catch to sf and create labels
  cluster.catch.sf <- cluster.pie %>%
    st_as_sf(coords = c("X","Y"), crs = crs.proj) %>%
    st_transform(crs = crs.geog) %>% 
    mutate(
      label = paste("Cluster", cluster),
      popup = paste('<b>Cluster:', cluster, '</b><br/>',
                    'Anchovy:', Anchovy, 'kg<br/>',
                    'Sardine:', Sardine, 'kg<br/>',
                    'Jack Mackerel:', JackMack, 'kg<br/>',
                    'P. herring:', PacHerring, 'kg<br/>',
                    'P. mackerel:', PacMack, 'kg<br/>',
                    'All CPS:', AllCPS, 'kg'))
}  

if (sampling.cufes) {
  # Convert CUFES to sf; CRS - crs.geog
  cufes.sf <- cufes %>% 
    filter(Density > 0, Species %in% cufes.plot.spp) %>%
    mutate(
      spp.label = case_when(
        Species == "SardineEggs" ~ "Sardine",
        Species == "AnchovyEggs" ~ "Anchovy",
        Species == "JackMackerelEggs"~ "Jack mackerel",
        TRUE ~ Species),
      label = paste(spp.label, " eggs: ", round(Density, 1), " /cubic m", sep = ""),
      popup = paste('<b>Species:', spp.label, '</b><br/>', round(Density, 1),"eggs m<sup>3</sup>")) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    arrange(desc(Density))
  
  cufes.squid.sf <- cufes %>% 
    filter(Density > 0, Species == "SquidEggs") %>%
    mutate(
      spp.label = case_when(
        Species == "SquidEggs" ~ "Squid",
        TRUE ~ Species),
      label = paste(spp.label, " eggs: ", round(Density, 1), " /cubic m", sep = ""),
      popup = paste('<b>Species:', spp.label, '</b><br/>', round(Density, 1),"eggs m<sup>3</sup>")) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog)
  
  cufes.ofe.sf <- cufes %>% 
    filter(Density > 0, Species == "OtherFishEggs") %>%
    filter(str_detect(Comments, c("Scomber japonicus","scomber japonicus",
                                  "S. japonicus"))) %>%
    mutate(
      spp.label = case_when(
        Species == "OtherFishEggs" ~ "Other fish",
        TRUE ~ Species),
      label = paste(spp.label, " eggs: ", round(Density, 1), " /cubic m", sep = ""),
      popup = paste('<b>Species:', spp.label, '</b><br/>', round(Density, 1),"eggs m<sup>3</sup><br/>", 
                    '</b>Comment:</b>', Comments)) %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog)
  
  # Convert negative CUFES samples to sf; CRS - crs.geog
  cufes.neg.sf <- filter(cufes.raw, AllEggs == 0) %>% 
    mutate(bin.level = 1) %>% 
    st_as_sf(coords = c("long", "lat"), crs = crs.geog) %>% 
    select(SampleNumber, bin.level)    
}

```

```{r load-ctds}
if (file.exists(here("Output/uctd_summary_table.csv"))) {
  uctd.casts <- read_csv(here("Output/uctd_summary_table.csv")) %>% 
    st_as_sf(coords = c("Lon", "Lat"), crs = crs.geog)
}

if (file.exists(here("Output/ctd_summary_table.csv"))) {
  ctd.casts <- read_csv(here("Output/ctd_summary_table.csv")) %>% 
    st_as_sf(coords = c("Lon", "Lat"), crs = crs.geog)
}
```

```{r create-leaflet-map, out.width="100%", out.height="8in"}
# Leaflet options
# https://rstudio.github.io/leaflet/

# Info on tile caching
# https://bhaskarvk.github.io/leaflet.extras/reference/TileCaching.html

# Set padding around data  
imap.bounds <- map_bounds(nav$lat, nav$long, 0.1) 

# Create color palette for MPAs
## CA and OR MPAs
all.mpa.types <- as.factor(c(unique(as.character(ca_mpas$Type)), 
                             unique(as.character(or_mpas$Label))))

mpaPal  <- colorFactor(topo.colors(10), all.mpa.types)

## All West Coast MPAs
mpaPalWC <- colorFactor(topo.colors(10), unique(wc_mpas$Design))

# Create color pallette for CUFES
cufesPal <- colorFactor(cufes.colors, cufes.plot.spp)

# Create color palette for seep types
seepPal <- colorFactor(c("red","blue"), c("Seep","Uncertain"))

# Create color pallette for planned transects
txPal    <- colorFactor(wpt.colors, wpt.types)
trawlPal <- c('#00CD66', '#0000FF', '#A020F0',
              '#F5DEB3', '#00FFFF', '#FF0000')

if (sampling.acoustics) {
  # Select plot levels for backscatter data
  nasc.levels.all <- sort(unique(nasc.plot.all$bin.level))
  nasc.labels.all <- nasc.labels[sort(nasc.levels.all)]
  nasc.sizes.all  <- nasc.sizes[sort(nasc.levels.all)]
  nasc.colors.all <- nasc.colors[sort(nasc.levels.all)]
  
  # Create color palette for NASC
  nascPal <- colorFactor(nasc.colors.all, nasc.levels.all)  
}

# Plotting preferences -------------------------------------------------------
# Leaflet tile options; set both to T if caching

# Create leaflet map
i.map <- leaflet() %>% 
  # Enable tile caching
  enableTileCaching() %>%
  # Add provider tiles; # http://leaflet-extras.github.io/leaflet-providers/preview/index.html
  addProviderTiles(providers$Esri.OceanBasemap,
                   options = tileOptions(useCache = useCachedTile,
                                         crossOrigin = useCrossOrigin)) %>%
  # Add EEZs
  addPolylines(data = eez_usa, color = "#000414", weight = 3, 
               label = "EEZ-U.S.", group = "Exclusive Economic Zones") %>% 
  addPolylines(data = eez_can, color = "#000414", weight = 3, 
               label = "EEZ-Canada", group = "Exclusive Economic Zones") %>% 
  addPolylines(data = eez_mex, color = "#000414", weight = 3, 
               label = "EEZ-Mexico", group = "Exclusive Economic Zones") %>% 
  # Add bathymetry contours
  addPolylines(data = bathy, color = "white", weight = 2, 
               label = ~paste(Depth, "m"), group = "Bathymetry Contours") %>% 
  # Add State waters
  addPolygons(data = or_waters, weight = 2, fillColor = "transparent", 
              opacity = 0.75,
              label = ~htmlEscape("OR State Waters"),
              group = "State Waters") %>%
  addPolygons(data = ca_waters, weight = 2, fillColor = "transparent",
              opacity = 0.75,
              label = ~htmlEscape("CA State Waters"),
              group = "State Waters") %>%
  # # Add CA MPAs
  # addPolygons(data = ca_mpas, color = "#000414", weight = 2, fillColor = ~mpaPal(Type),
  #             fillOpacity = 0.3, label = ~htmlEscape(MPA), group = "MPAs") %>%
  # # Add OR MPAs
  # addPolygons(data = or_mpas, color = "#000414", weight = 2, fillColor =  ~mpaPal(Label),
  #             fillOpacity = 0.3, label = ~htmlEscape(Name), group = "MPAs") %>%
  # Add West Coast MPAs
  addPolygons(data = wc_mpas, color = "#000414", weight = 2, fillColor =  ~mpaPalWC(Design),
              fillOpacity = 0.3, label = ~htmlEscape(Site_Nm), group = "MPAs") %>%
    # Add Baja California MPAs
  addPolygons(data = baja_mpas, color = "#000414", weight = 2, fillColor =  ~NOMBRE,
              fillOpacity = 0.3, label = ~htmlEscape(NOMBRE), group = "MPAs") %>%
  # Add core planned transects
  addPolylines(data = filter(transects.sf, Type %in% c("Compulsory", "Adaptive")),
               color = ~txPal(Type), weight = 3, opacity = 0.5,
               label = ~htmlEscape(paste(Type, Transect)),
               popup = ~popup,
               group = "Planned Transects (Core)") %>%
  addCircleMarkers(data = filter(wpts.sf, Type %in% c("Compulsory", "Adaptive")),
                   radius = 3, color = "#000414", stroke = FALSE, opacity = 0.5,
                   fillOpacity = 0.5, fillColor =  ~txPal(Type), 
                   label = ~htmlEscape(paste(Type, Waypoint)),
                   popup = ~popup,
                   group = "Planned Transects (Core)") %>%
  # Add ancillary planned transects
  addPolylines(data = filter(transects.sf, !Type %in% c("Compulsory", "Adaptive")),
               color = ~txPal(Type), weight = 3, opacity = 0.5,
               # label = ~htmlEscape(paste(Type, Transect)),
               popup = ~popup,
               group = "Planned Transects (Ancillary)") %>%
  addCircleMarkers(data = filter(wpts.sf, !Type %in% c("Compulsory", "Adaptive")),
                   radius = 3, color = "#000414", stroke = FALSE, opacity = 0.5,
                   fillOpacity = 0.5, fillColor =  ~txPal(Type),
                   # label = ~htmlEscape(paste(Type, Waypoint)),
                   popup = ~popup,
                   group = "Planned Transects (Ancillary)") %>%
  # Add scale bar
  addScaleBar(position = "bottomright") %>%
  # Add map coordinates
  addMouseCoordinates() %>% 
  # Add measurement tool
  addMeasure(primaryLengthUnit = "miles", secondaryLengthUnit = "km",
             primaryAreaUnit = "sqmiles", secondaryAreaUnit = "sqmeters",
             position = "topleft") %>% 
  # Add layer controls
  addLayersControl(
    overlayGroups = c("MPAs", "State Waters", "Exclusive Economic Zones", 
                      "Bathymetry Contours",
                      "Planned Transects (Core)", "Planned Transects (Ancillary)",
                      "Vessel Track", "Vessel Positions", 
                      "Trawls", "CTD Casts",
                      "Backscatter-CPS", "Backscatter-CPS (Small)",
                      "Backscatter-Krill", "Backscatter-Krill (Small)",
                      "Backscatter (Large)",
                      "CUFES Egg Density", "CUFES Egg Density-Other",
                      "CUFES Egg Density-Squid", "CUFES (Negative)",
                      "Saildrone Tracks", "Saildrone Positions"),
    options = layersControlOptions(collapsed = FALSE)) %>% 
  fitBounds(imap.bounds$range.lon[1], imap.bounds$range.lat[1],
            imap.bounds$range.lon[2], imap.bounds$range.lat[2])

# Add UCTD casts
if (exists("uctd.casts"))
  i.map <- i.map %>% 
  # Add uctd data
  addMarkers(data = uctd.casts, label = ~Filename, popup = ~Filename, 
             group = "CTD Casts")

if (exists("uctd.casts"))
  i.map <- i.map %>% 
  # Add uctd data
  addMarkers(data = ctd.casts, label = ~Filename, popup = ~Filename, 
             group = "CTD Casts")

# Add vessel positions
if (exists("nav.paths.sf"))
  i.map <- i.map %>% 
  # Add nav data
  addPolylines(data = nav.paths.sf, color = "#000414", weight = 1, 
               label = ~leg, group = "Vessel Track") %>%
  addMarkers(data = nav.now, label = ~label, popup = ~popup, 
             group = "Vessel Positions")

if (sampling.cufes) {
  # Add CUFES data
  if (nrow(cufes.neg.sf) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = cufes.neg.sf, radius = ~bin.level*2, color = "#000414", stroke = FALSE, weight = 1,
                       fillOpacity = 0.50, fillColor =  "#000414", label = ~htmlEscape(SampleNumber),
                       group = "CUFES (Negative)")
  
  if (nrow(cufes.sf) > 0) 
    i.map <- i.map %>% 
      addLegend("bottomleft", colors = cufes.colors, 
                values = ~sort(unique(cufes.sf$Species)), 
                labels = cufes.spp.labels, 
                title = "CUFES Egg Density <br/> (eggs m<sup>-3</sup>)", 
                opacity = 1, group = "CUFES Egg Density")
  
  if (nrow(filter(cufes.sf, Species == "AnchovyEggs")) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = filter(cufes.sf, Species == "AnchovyEggs"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~cufesPal(Species), label = ~label,
                       popup = ~popup, group = "CUFES Egg Density")
  
  if (nrow(filter(cufes.sf, Species == "JackMackerelEggs")) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = filter(cufes.sf, Species == "JackMackerelEggs"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~cufesPal(Species), label = ~label,
                       popup = ~popup, group = "CUFES Egg Density")
  
  if (nrow(filter(cufes.sf, Species == "SardineEggs")) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = filter(cufes.sf, Species == "SardineEggs"),
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~cufesPal(Species), label = ~label,
                       popup = ~popup, group = "CUFES Egg Density")
  
  if (nrow(cufes.squid.sf) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = cufes.squid.sf,
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  "#FFFFFF", label = ~label,
                       popup = ~popup, group = "CUFES Egg Density-Squid")
  
  if (nrow(cufes.ofe.sf) > 0)
    i.map <- i.map %>% 
      addCircleMarkers(data = cufes.ofe.sf,
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  pac.mack.color, label = ~label,
                       popup = ~popup, group = "CUFES Egg Density-Other") 
}

if (sampling.acoustics) {
  # Add backscatter data
  if (nrow(filter(nasc.cps.sf, NASC < 200)) > 0)
    i.map <- i.map %>%  
      addCircleMarkers(data = filter(nasc.cps.sf, NASC < 200), 
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75,  fillColor = ~nascPal(bin.level), 
                       label = ~label, popup = ~popup, 
                       group = "Backscatter-CPS (Small)")
  
  if (nrow(filter(nasc.cps.sf, NASC >= 200)) > 0)
    i.map <- i.map %>%  
      addCircleMarkers(data = filter(nasc.cps.sf, NASC >= 200), 
                       radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                       fillOpacity = 0.75, fillColor =  ~nascPal(bin.level), 
                       label = ~label, popup = ~popup,
                       group = "Backscatter-CPS") %>%
      # Add legends
      addLegend("bottomleft", colors = nasc.colors.all, 
                values = sort(unique(nasc.cps.sf$bin.level)),
                labels = nasc.labels.all, 
                title = "CPS Backscatter<br/> (s<sub>A</sub>; m<sup>2</sup> nmi<sup>-2</sup>)", 
                opacity = 1, group = "Backscatter-CPS")
  
  if (exists("nasc.krill.sf")) {
    if (nrow(filter(nasc.krill.sf, NASC >= 200)) > 0)
      i.map <- i.map %>%  
        addCircleMarkers(data = filter(nasc.krill.sf, NASC >= 200), 
                         radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                         fillOpacity = 0.75, fillColor =  ~nascPal(bin.level), 
                         label = ~label, popup = ~popup,
                         group = "Backscatter-Krill") %>% 
        addLegend("bottomleft", colors = nasc.colors.all, 
                  values = ~sort(unique(nasc.krill.sf$bin.level)),
                  labels = nasc.labels.all, 
                  title = "Krill Backscatter<br/> (s<sub>A</sub>; m<sup>2</sup> nmi<sup>-2</sup>)", 
                  opacity = 1, group = "Backscatter-Krill")  
  }
  
  if (exists("nasc.krill.sf")) {
    if (nrow(filter(nasc.krill.sf, NASC < 200)) > 0)
      i.map <- i.map %>%  
        addCircleMarkers(data = filter(nasc.krill.sf, NASC < 200), 
                         radius = ~bin.level*2, color = "#000414", stroke = TRUE, weight = 1,
                         fillOpacity = 0.75, fillColor = ~nascPal(bin.level), 
                         label = ~label, popup = ~popup,
                         group = "Backscatter-Krill (Small)") 
  }
  
  if (nrow(big.nasc.sf) > 0)
    i.map <- i.map %>%  
      addMarkers(data = big.nasc.sf, label = ~label, popup = ~popup,
                 group = "Backscatter (Large)")
} 

if (sampling.trawl) {
  if (exists("haul.paths"))
    i.map <- i.map %>% 
      # Add trawl paths 
      addPolylines(data = haul.paths, color = c("#000000"), weight = 5, opacity = 0.8, 
                   popup = ~popup, label = ~label, 
                   group = "Trawls")
  
  if (exists("cluster.catch.sf"))
    i.map <- i.map %>% 
      # Add trawl catch
      addCircleMarkers(data = cluster.catch.sf, radius = 5, color = "#000000", stroke = TRUE, weight = 2,
                       opacity = 0.8, fillOpacity = 1, fillColor =  "white",
                       popup = ~popup, label = ~label,
                       group =  "Trawls")    
}

# Add Saildrone data
if (exists("nav.sd.paths.sf"))
  i.map <- i.map %>% 
  addPolylines(data = nav.sd.paths.sf, color = c("#000414"), weight = 3,
               label = ~paste("Saildrone", saildrone), group = "Saildrone Tracks")
if (exists("nav.now.sd"))
  i.map <- i.map %>% 
  addMarkers(data = nav.now.sd, label = ~label, popup = ~popup, 
             group = "Saildrone Positions")

# Set visible layers
i.map <- i.map %>%  
  hideGroup(c("Backscatter (Large)", "Backscatter-Krill", "Backscatter-Krill (Small)", 
              "CUFES Egg Density", "CUFES Egg Density-Other",
              "CUFES Egg Density-Squid", "CUFES (Negative)",
              "Vessel Positions", "Saildrone Tracks", 
              "Saildrone Tracks", "Saildrone Positions",
              "State Waters", "Exclusive Economic Zones", "CTD Casts"))

# Save i.map
dir_create(here("Output/imap"))

if (save.imap) {
  mapshot(i.map, url = here("Output/imap/plotBio_explorer.HTML"))
}
```

```{r get-big-nasc, out.width="90%", out.height="90%"}
if (exists("big.nasc")) {
  # Create outlier plot
  nasc.outlier.plot <- ggplot(big.nasc, aes(rank, NASC, ids = label, fill = type)) +
    geom_point(shape = 21, size = 2, alpha = 0.7) +
    geom_text_repel(data = top_n(big.nasc, 20, NASC), 
                    aes(rank, NASC, label = label), size = 2) +
    scale_fill_manual(name = "NASC\ntype", 
                      values = c("CPS" = "blue", "Krill" = "yellow")) +
    ylab("NASC / 19\n") + xlab("\nRank") +
    theme_bw()
  
  # Create outlier plot for plotly
  nasc.outlier.plotly <- ggplot(big.nasc, 
                                aes(rank, NASC, ids = label, fill = type)) +
    geom_point(shape = 21, size = 4, alpha = 0.7) +
    scale_fill_manual(name = "NASC\ntype", 
                      values = c("CPS" = "blue", "Krill" = "yellow")) +
    ylab("NASC / 19\n") + xlab("\nRank") +
    theme_bw()
  
  # Save plotly graph
  save(nasc.outlier.plotly, file = here("Output/nasc_backscatter_plotly.Rdata"))
  
  if (save.figs) {
    # Save figure
    ggsave(nasc.outlier.plot, filename = here("Figs/fig_nasc_outliers.png"), 
           height = 5, width = 5)
  } 
}
```  

```{r create-saidrone-map}
if (get.nav.sd) {
  if (save.figs) {
    # Create Saildrone map
    saildrone.map <- base.map +
      geom_sf(data = nav.sd.paths.sf, aes(colour = factor(saildrone)), 
              show.legend = "line") + 
      scale_colour_discrete("Saildrone") + 
      coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
               xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
               ylim = c(map.bounds["ymin"], map.bounds["ymax"]))
    
    # Save map
    ggsave(saildrone.map, file = here("Figs/fig_saildrone_map.png"),
           height = map.height, width = map.width)
  }
  
  # Subset track lengths
  sd.tracklength <- nav.sd.paths.sf %>% 
    select(saildrone, tracklength) %>% 
    mutate(tracklength = as.numeric(tracklength/1000)) %>% 
    st_set_geometry(NULL)
  
  # Summarize saildrone data
  nav.sd.summ <- nav.sd %>% 
    group_by(saildrone) %>% 
    summarise(start = min(datetime), 
              end = max(datetime),
              das = n_distinct(date(datetime))) %>% 
    left_join(sd.tracklength)
  
  write_csv(nav.sd.summ, here("Output/saildrone_nav_summary.csv")) 
}
```

```{r summarize-data}
# Compute total survey distance from nav data
nav.dist <- nav.paths.sf %>% 
  st_transform(crs = crs.proj) %>% 
  mutate(distance_km  = as.numeric(st_length(.)/1000),
         distance_nmi = distance_km*0.539957)

# Compute transect distance from backscatter data
nasc.summ <- nasc.cps %>% 
  group_by(leg, transect) %>% 
  summarise(
    start     = min(datetime),
    end       = max(datetime),
    duration  = difftime(end, start, units = "hours"),
    n_int     = length(Interval),
    distance  = round(length(Interval)*nasc.interval/1852),
    lat       = lat[which.min(long)],
    long      = long[which.min(long)],
    mean_nasc = mean(cps.nasc)) %>% 
  arrange(transect, start)

# Summarize acoustic distance by leg
nasc.summ.leg <- nasc.summ %>% 
  group_by(leg) %>% 
  summarise(distance = sum(distance))

# Summarize hauls
haul.summ <- haul %>% 
  group_by(leg) %>% 
  tally()

# Summarize cufes samples
cufes.summ <- cufes %>% 
  group_by(leg) %>% 
  summarise(n  = n_distinct(SampleNumber)) 
```

### Acoustic backscatter, CUFES Egg Density, and Trawl Species Proportions for the `r survey.name` 

#### SWFSC Advanced Survey Technologies Group  

_**Last updated:**_ `r format(Sys.time(), "%F %T", tz = "America/Los_Angeles", usetz = TRUE)`

An interactive map of the distribution of 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^;  averaged over 2000-m distance intervals) ascribed to CPS (from 5 to `r nasc.depth.cps`-m deep) and krill (5 to `r nasc.depth.krill`-m deep); CUFES egg density (eggs m^-3^) for anchovy, sardine, and jack mackerel; catch (by weight) of CPS species in trawl clusters (the combination of up to three trawl hauls conducted within a 12 h period; white points); and some other miscellaneous survey data. Hover-over or click on some map objects for more info.  

To date, _`r survey.vessel`_ has transited a total of `r prettyNum(sum(nav.dist$distance_nmi), big.mark = ',' ,digits = 1)` nmi (or `r prettyNum(sum(nav.dist$distance_km), big.mark = ',' ,digits = 1)` km), completed `r n_distinct(nasc.cps$transect)` acoustic transects totaling `r prettyNum(sum(nasc.summ$distance),big.mark = ',', digits = 1)` nmi, conducted `r nrow(haul)` nighttime Nordic trawls, and collected `r n_distinct(cufes$SampleNumber)` CUFES samples.  

```{r interactive-map,out.height="12in",out.width="100%"}
# Display map
i.map
```  

For questions about this page, please contact Kevin Stierhoff ([kevin.stierhoff@noaa.gov](mailto:kevin.stierhoff@noaa.gov)).

# Acoustic backscatter
## Examine backscatter outliers 

(ref:nasc-outliers) An interactive plot of the top 100 backscatter ($s_A$) intervals, labeled with the transect name and interval to facilitate further scrutiny of processing steps in Echoview.

```{r plot-big-nasc, fig.cap='(ref:nasc-outliers)'}
if (file.exists(here("Output/nasc_backscatter_plotly.Rdata"))) {
  # Load NASC outliers
  load(here("Output/nasc_backscatter_plotly.Rdata"))
  
  # Plot NASC outliers using plotly
  plotly::ggplotly(nasc.outlier.plotly)
} else {
  print("No backscatter data yet.")
}
``` 

## CPS

(ref:backscatter-map-cps) The distribution of 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^;  averaged over 2000-m distance intervals and from 5 to `r nasc.depth.cps`-m deep) ascribed to CPS.

```{r plot-backscatter-cps,fig.cap='(ref:backscatter-map-cps)',out.width="100%"}
if (file.exists(here("Figs/fig_backscatter_cps.png"))) {
  include_graphics(here("Figs/fig_backscatter_cps.png"))
} else {
  print("No CPS backscatter plot yet.")
}
```

\newpage

## Krill

(ref:backscatter-map-krill) The distribution of 200-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^;  averaged over 2000-m distance intervals and from 5 to `r nasc.depth.krill`-m deep) ascribed to krill.

```{r plot-backscatter-krill,fig.cap='(ref:backscatter-map-krill)',out.width="100%"}
if (file.exists(here("Figs/fig_backscatter_krill.png"))) {
  include_graphics(here("Figs/fig_backscatter_krill.png"))
} else {
  print("No krill backscatter plot.")
}
```

\newpage  

# CUFES Egg Density

(ref:cufes-egg-density) Map of CUFES egg density (eggs m^-3^) for anchovy, jack mackerel, and sardine.

```{r plot-cufes,fig.cap='(ref:cufes-egg-density)',out.width="100%"}
if (file.exists(here("Figs/fig_cufes_egg_density.png"))) {
  include_graphics(here("Figs/fig_cufes_egg_density.png"))
} else {
  print("No CUFES plot yet.")
}

```  

\newpage

**Table 1.** Bad CUFES samples

```{r bad-cufes-table}
if (file.exists(here("Output/cufes_bad.Rdata"))) {
  # Load bad CUFES data
  load(here("Output/cufes_bad.Rdata"))  
  
  if (nrow(cufes.bad) > 0) {
    datatable(cufes.bad)
  } else {
    print("No bad CUFES samples.")
  }
} else {
  print("No CUFES data yet.")
}
```


\newpage

# Trawl species proportions  

(ref:trawl-proportion-haul-wt) Proportions of CPS species in trawl hauls, by weight (black points indicate trawl hauls with no CPS).

```{r plot-trawl-proportion-haul-wt,fig.cap='(ref:trawl-proportion-haul-wt)',out.width='100%'}
if (file.exists(here("Figs/fig_trawl_proportion_haul_wt.png"))) {
  include_graphics(here("Figs/fig_trawl_proportion_haul_wt.png"))
} else {
  print("No trawl haul proportion plot yet.")
}
```

\newpage  

# Backscatter, CUFES egg density, and trawl species proportions  

(ref:nasc-cufes-trawl) A map of the a) distribution of 38-kHz integrated backscattering coefficients ($s_A$, m^2^ nmi^-2^;  averaged over 2000-m distance intervals and from 5 to 70-m deep) ascribed to CPS, b) CUFES egg density (eggs m^-3^) for anchovy and sardine, and c) proportions of CPS species (by weight) in trawl hauls (black points indicate trawl hauls with no CPS).

```{r plot-combo-maps,fig.cap='(ref:nasc-cufes-trawl)',out.width='100%'}
if (file.exists(here("Figs/fig_nasc_cufes_haul_wt.png"))) {
  include_graphics(here("Figs/fig_nasc_cufes_haul_wt.png"))
} else {
  print("No backscatter/CUFES/haul proportion plot yet.")
}
```

# Plot saildrone data

(ref:saildrone-transects) Transect sampled by Saildrone unmanned surface vehicles (USVs).

```{r plot-saildrone,fig.cap='(ref:saildrone-transects)',out.width='100%'}
if (file.exists(here("Figs/fig_saildrone_map.png"))) {
  include_graphics(here("Figs/fig_saildrone_map.png"))
} else {
  print("No Saildrone plot yet.")
}
```
