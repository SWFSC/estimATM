---
title: "Acoustic Line Kilometers-Summer 2018 Saildrone (1807RL)"
author: "Kevin L. Stierhoff"
date: '`r format(Sys.time(), format = "%F %T", tz = "GMT", usetz = T)`'
css: css/ast.css
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
---

```{r setup, include=FALSE}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,swfscMisc,lubridate,cowplot,here,marmap,fs,sf,
               mapview,mapdata,photobiology,ggmap,knitr,DT,bookdown,
               rnaturalearth,ggspatial)

# Install and load required packages from Github -------------------------------
# surveyR
pacman::p_load_gh("kstierhoff/surveyR")
# atm
pacman::p_load_gh("kstierhoff/atm")
# rnaturalearth data
pacman::p_load_gh("ropenscilabs/rnaturalearthdata")
pacman::p_load_gh("ropenscilabs/rnaturalearthhires")

# knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, error = FALSE, warning = FALSE,
                      fig.align = "center")

# Create output directories
dir_create(here(), c("Data", "Figs", "Output"))
```

```{r project-settings}
# Get project name from directory
prj.name <- last(unlist(str_split(here(), "/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste(prj.name, ".R", sep = ""))]
source(here("Doc/settings", prj.settings))
```

```{r user-input}
# Set processing controls -------------------------------------------------
get.nav    <- T # Download nav data from ERDDAP
get.bathy  <- F # Extract ETOPO1 bathymetry data in the survey footprint
resize.map <- F # Resize map during survey; if T, uses anticipated bounds of survey area
```

```{r process-nav}
if (get.nav) {
  # Load existing nav data
  if (file.exists(here("Data/Nav/nav_data.Rdata"))) {
    load(here("Data/Nav/nav_data.Rdata"))
    
    # Calculate difference between max nav time and now
    nav.lag <- difftime(now(tzone = "UTC"), max(ymd_hms(nav$time)), units = "hours")
    
    # Get new erddap start date from max date
    erddap.survey.start <- max(date(nav$time))
  } else {
    nav.lag <- 24
  }
  
  if (nav.lag >= 24) {
    # Generate ERDDAP URL
    dataURL <- URLencode(paste(
      "http://coastwatch.pfeg.noaa.gov/erddap/tabledap/fsuNoaaShip",
      erddap.vessel, ".csv0?", erddap.vars,
      "&time>=", erddap.survey.start, "&time<=", erddap.survey.end,
      sep = ""))
    
    # Download and parse ERDDAP nav data
    nav.temp <- data.frame(read.csv(dataURL, header = F, colClasses = erddap.classes, 
                                    row.names = NULL, skip = 0))
    names(nav.temp) <- erddap.headers
    
    # Filter to remove bad SST values
    nav.temp <- nav.temp %>% 
      mutate(long     = long - 360,
             SOG      = SOG * 1.94384,
             datetime = ymd_hms(time),
             SST      = na_if(SST, NaN),
             leg      = paste("Leg", cut(as.numeric(date(datetime)), 
                                         leg.breaks, labels = F))) %>%
      filter(is.nan(SOG) == F, SOG > 0, SOG < 15,
             between(lat, min(survey.lat), max(survey.lat)), 
             between(long, min(survey.long), max(survey.long)))
    
    # Append new nav data
    if (exists("nav")) {
      nav <- bind_rows(nav, nav.temp) %>% 
        distinct()
    } else {
      nav <- nav.temp
    }
  }
  
  # Convert nav to spatial
  nav.sf <- st_as_sf(nav, coords = c("long","lat"), crs = crs.geog) 
  
  # Cast nav to transects
  nav.paths.sf <- nav.sf %>% 
    group_by(leg) %>% 
    summarise(do_union = F) %>% 
    st_cast("LINESTRING")
  
  # Save results
  save(nav, nav.sf, nav.paths.sf, file = here("Data/Nav/nav_data.Rdata"))
} else {
  # Load nav data
  load(here("Data/Nav/nav_data.Rdata"))
}

# Read transect waypoints
wpts <- read_csv(here("Data/Nav", wpt.filename))

# Convert planned transects to sf; CRS = crs.geog
wpts.sf <- wpts %>% 
  filter(Type %in% wpt.types) %>% 
  st_as_sf(coords = c("Longitude","Latitude"), crs = crs.geog) %>% 
  mutate(
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type)
  )

transects.sf <- wpts.sf %>% 
  group_by(Type, Transect) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING") %>% 
  ungroup() %>% 
  mutate(
    distance = round(as.numeric(st_length(.))/1852,1),
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type, '<br/>',
                       'Distance:', distance, 'nmi<br/>')
  )

# Summarise nav
mean.sog <- mean(nav$SOG)

# Set padding around data  
if (resize.map) {
  # Use nav data to resize map to survey progress
  map.bounds <- nav.paths.sf %>% 
    st_transform(crs = crs.proj) %>%
    st_bbox()  
} else {
  # Use nav data to resize map to survey progress
  map.bounds <- transects.sf %>%
    st_transform(crs = crs.proj) %>%
    st_bbox()  
}
```

```{r get-bathy}
# Get bathymetry data across range of nav data (plus/minus one degree lat/long)
if (get.bathy) {
  # Get boundaries for bathymetry grid
  bathy.bounds <- nav.sf %>% 
    st_bbox() 
  
  # Download bathy grid
  noaa.bathy <- getNOAA.bathy(
    lon1 = bathy.bounds$xmin - 1, 
    lon2 = bathy.bounds$xmax + 1,
    lat1 = bathy.bounds$ymax + 1, 
    lat2 = bathy.bounds$ymin - 1, 
    resolution = 1)
  
  # Save bathy results
  save(noaa.bathy, file = paste(here("Data/GIS"), "/bathy_data_",
                                survey.name,".Rdata", sep = ""))  
} else {
  load(paste(here("Data/GIS"), "/bathy_data_",
             survey.name,".Rdata", sep = ""))
}
```

```{r}
# Summarize NASC by date and lat/long
nav.sun <- nav %>% 
  mutate(date = date(datetime)) %>% 
  group_by(date) %>% 
  summarise(lat = mean(lat),
            long = mean(long)) %>% 
  as.data.frame()

# Get sunrise/sunset for each survey day
nav.daynight <- data.frame()

for (i in 1:nrow(nav.sun)) {
  tmp <- day_night(date = nav.sun$date[i], 
                   geocode = data.frame(lat = nav.sun$lat[i], lon = nav.sun$long[i]),
                   twilight = survey.twilight)
  nav.daynight <- bind_rows(nav.daynight, tmp)
}

# Format the results
nav.daynight <- nav.daynight %>% 
  mutate(sunrise = ymd_hms(paste(day, hms::as_hms(sunrise*3600))) - minutes(survey.twilight.offset),
         sunset  = sunrise + daylength*3600 + minutes(survey.twilight.offset),
         sunrise = as.character(sunrise), # convert to character to work with gather()
         sunset  = as.character(sunset)) %>% 
  select(day, sunrise, sunset) %>% 
  gather(period, time, -day) %>% 
  mutate(time    = ymd_hms(time, tz = "UTC"), # convert back to POSIX
         sun_key = as.character(time)) %>% 
  arrange(time) %>% 
  mutate(id = seq(1, nrow(.)))


# Process FSV data from ERDDAP
nav <- nav %>%
  mutate(time = ymd_hms(time),
         date = date(time),
         dist = SOG*60/1000) %>%  # Distance in km
  filter(between(long, min.long, max.long), between(lat, min.lat, max.lat))

# Get nav depth and compute photoperiod
nav.depth <- get.depth(noaa.bathy, nav$long, nav$lat, locator = F, distance = T) %>%
  rename(long = lon) %>%
  bind_cols(select(nav, datetime, dist)) %>%
  mutate(dist.depth = c(0, diff(dist.km))) %>%
  filter(dist.depth < 100)  %>% # Remove distant points
  mutate(depth_bin = cut(depth, c(min(depth), -200, 0), include.lowest = T, labels = F),
         id = cut(as.numeric(datetime), as.numeric(nav.daynight$time),
                  include.lowest = T, labels = F),
         depth_bin = case_when(
           depth_bin == 1 ~ ">200m",
           depth_bin == 2 ~ "< 200 m")) %>%
  filter(!is.na(depth_bin)) %>%
  left_join(select(nav.daynight, id, period)) %>%
  mutate(day_night = case_when(
    period == "sunrise" ~ "Day",
    period == "sunset"  ~ "Night")) %>%
  mutate(pings = 60*(750/abs(depth))) %>% # Compute time interval
  project_df(to = crs.proj)

# Summarise distance by day/night and depth
# Number of pings per km were estimated as ...
nav.summ <- nav.depth %>% 
  filter(!is.nan(dist)) %>% 
  group_by(depth_bin, day_night) %>% 
  summarise(
    dist_km    = round(sum(dist)),
    pings_ek80 = sum(pings)) %>% 
  mutate(
    dist_nmi   = round(dist_km * 0.539957)) %>% 
  select(depth_bin:dist_km, dist_nmi, everything())

# Write results to file
write_csv(nav.summ, paste0(here("Output"), "/", survey.name, "_LineKilometers_", survey.vessel, ".csv"))
```

# Summarize effort by depth and day/night

```{r effort-summary}
datatable(nav.summ)
```

```{r create-basemap,include=F}
# Configure base map options -----------------
# Import landmarks
locations <- filter(read.csv(here("Data/Map/locations.csv")), name %in% label.list) %>%
 project_df(to = crs.proj)

# Get state data
states <- ne_states(country = 'United States of America', returnclass = 'sf')
ca     <- filter(states, name == "California")

# Get countries
countries <- ne_countries(scale = "large", returnclass = "sf") %>%
  filter(subregion %in% c("Northern America","Central America"))

# Read bathy contours shapefile 
bathy <- st_read(here("Data/GIS/bathy_contours.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = Contour)

# Determine map aspect ratio and set height and width
map.aspect <- (map.bounds$xmax - map.bounds$xmin)/(map.bounds$ymax - map.bounds$ymin)
map.height <- 10
map.width  <- map.height*map.aspect

# Create base map
base.map <- get_basemap(nav.paths.sf, states, countries, locations, bathy, map.bounds, crs = crs.proj) +
  # Add scalebar
  annotation_scale(style = "ticks", location = "br", height = unit(0.15, "cm"))

# Save the basemap
ggsave(base.map, file = here("Figs/fig_basemap.png"), 
       height = map.height, width = map.width)

save(base.map, file = here("Data/Map/basemap.Rdata"))
```

# Map vessel nav by depth and day/night

```{r map-daynight-bathy}
# Map results by depth bin
bathy.plot <- base.map + 
  geom_point(data = nav.depth, aes(X, Y, colour = depth_bin), size = 0.5) +
  scale_colour_manual(name = "Depth", values = c("#40C270","#1C1C8A")) +
  theme(legend.position      = c(0,0),
        legend.justification = c(0,0),
        legend.background    = element_blank(),
        legend.key           = element_blank()) +
  ggtitle("Vessel nav by depth") 

# Map results by day/night
daynight.plot <- base.map + 
  geom_point(data = nav.depth, aes(X, Y, colour = day_night), size = 0.5) +
  scale_colour_manual(name = "Time of day", values = c("yellow", "black")) +
  theme(legend.position      = c(0,0),
        legend.justification = c(0,0),
        legend.background    = element_blank(),
        legend.key           = element_blank()) +
  ggtitle("Vessel nav by day/night")

# Combine plots
bathy.photo.plot <- plot_grid(bathy.plot, 
                              daynight.plot, 
                              nrow = 1, align = "v")

# Save combo plot
ggsave(bathy.photo.plot, 
       filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_day_", survey.vessel, ".png"),
       height = map.height, width = map.width*2)

include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_day_", survey.vessel, ".png"))
```

# Map vessel nav by depth (daytime only)

```{r map-daytime-bathy}
# Map only daytime nav by depth
day.plot <- base.map + 
  geom_point(data = filter(nav.depth, day_night == "Day"), 
             aes(X, Y, colour = depth_bin), size = 0.5) +
  scale_colour_manual(name = "Depth", values = c("#40C270", "#1C1C8A")) +
  theme(legend.position      = c(0,0),
        legend.justification = c(0,0),
        legend.background    = element_blank(),
        legend.key           = element_blank()) +
  ggtitle("Daytime vessel nav by depth")

# Save daytime only plot
ggsave(day.plot, 
       filename = paste0(here("Figs"), "/", survey.name, "_nav_depth_", survey.vessel, ".png"),
       height = map.height, width = map.width)

include_graphics(paste0(here("Figs"), "/", survey.name, "_nav_depth_", survey.vessel, ".png"))
```



