---
title: "OR Scientific Collection Permit Reporting"
author: "Kevin Stierhoff"
output:
  bookdown::html_document2:
    toc: yes
    toc_float: yes
    number_sections: yes
css: css/ast.css
---

```{r set-up, error=FALSE, message=FALSE, warning=FALSE, echo=F}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,swfscMisc,lubridate,sp,mapview,RODBC,leafem,
               knitr,geosphere,ggrepel,cowplot,sf,leaflet, htmltools, janitor,
               odbc,kableExtra,rnaturalearth,shadowtext,here,fs,ggspatial,
               RSQLite)

# Install and load required packages from Github -------------------------------
# surveyR
pacman::p_load_gh("kstierhoff/surveyR")
pacman::p_load_gh("kstierhoff/atm")


# Define method of table generation (whether kable or xtable) for best formatting
doc.type <- knitr::opts_knit$get('rmarkdown.pandoc.to')
if (is.null(doc.type)) {doc.type <- "html"}

# Set global knitr chunk options
if (.Platform$OS.type == "unix") {
  # Do not specify Cairo device for MacOS
  knitr::opts_chunk$set(echo = F, warning = F, message = F,
                        fig.align = 'center', out.width = '100%', dev = "png", dpi = 150)
} else {
  knitr::opts_chunk$set(echo = F, warning = F, message = F,
                        fig.align = 'center', out.width = '100%', dev = "png", dpi = 150,
                        dev.args = list(type = "cairo"))
}

# Set kable options
options(knitr.kable.NA = '-')

# determine global knitr table format
if (doc.type == "latex") {
  knitr.format <- "latex"
} else {
  knitr.format <- "html" 
}
```

```{r project-info,include=FALSE}
# Get project name from directory
prj.name <- last(unlist(str_split(here(),"/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste0("settings_", prj.name, ".R"))]
source(here("Doc/settings", prj.settings))
```

```{r user-controls}
# Processing settings
get.db     <- T
get.nav    <- T
do.spatial <- T
nav.source <- "ERDDAP" # Navigation data source: ERDDAP or SCS
resize.map <- F # Resize map during survey; if T, uses anticipated bounds of survey area

# Sampling settings
sampling.cufes <- F
```

```{r get-trawl-data}
if (get.db) {
  # Source script to collect data from trawl database
  source(here("Code/collect_trawl_database.R"))
  
} else {
  # Load trawl data
  load(here("Data/Trawl/trawl_data_raw.Rdata"))
  
}
```

```{r format-trawl-data}
# Source script to format data from trawl database
source(here("Code/format_trawl_database.R"))
```

```{r process-trawl-data}
# Further process haul data --------------------------------------
haul.all <- haul.all %>% 
  # Remove bad trawls
  filter(!trawlPerformance %in% trawl.performance) %>% 
  # Remove trawls from other surveys
  filter(cruise %in% cruise.name & ship %in% cruise.ship) %>% 
  mutate(duration = difftime(haulBackTime, equilibriumTime, units = "mins"), # Calculate duration
         cluster  = cumsum(c(0, diff(equilibriumTime)) > 12) + 1) # Assign cluster

# Find midpoint of each haul as the mean lat/lon
haul.mid <- haul.all %>% 
  group_by(cluster, haul) %>% 
  summarise(
    lat  = mean(c(startLatDecimal, stopLatDecimal)),
    long = mean(c(startLongDecimal, stopLongDecimal))) 

# Create haul paths from starts and ends
haul.paths <- select(haul.all, haul, lat = startLatDecimal, long = startLongDecimal) %>% 
  bind_rows(select(haul.all, haul, lat = stopLatDecimal, long = stopLongDecimal)) %>% 
  arrange(haul) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  group_by(haul) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING")

# Find midpoint of each haul cluster as the average of haul midpoints
cluster.mid <- haul.mid %>% 
  group_by(cluster) %>% 
  summarise(
    lat  = mean(lat),
    long = mean(long))

# Filter specimens for this cruise
lengths.all <- lengths.all %>% 
  filter(cruise %in% cruise.name)
```

```{r filter-trawl-data, include=FALSE}
# Load spatial files
oregon <- ne_states(country = 'United States of America', returnclass = 'sf') %>% 
  filter(name == "Oregon")

## Read State Waters shapefiles -------------------------------
or_waters <- st_read(here("Data/GIS/or_state_waters.shp")) %>%
  st_transform(4326)

# Create State Waters shapefile -------------------------------
or_waters_12 <- oregon %>% 
  # Convert to meters for accurate buffer
  st_transform(crs = 3310) %>% 
  st_buffer(dist = 1852*12) %>% 
  # Transform back to WGS84 for mapping
  st_transform(4326)

if (do.spatial) {
  # Find hauls in WA waters
  haul.or <- haul.mid %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    # Find hauls in OR state waters
    st_intersection(or_waters)
  
  # Find hauls within 12 nmi
  haul.or.12 <- haul.mid %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    st_intersection(or_waters_12)
  
  save(haul.or, haul.or.12, file = here("Output/haul_data_reportCatchOr.Rdata"))
} else {
  load(here("Output/haul_data_reportCatchOr.Rdata"))
}

# Filter hauls in OR waters
haul.out <- haul.mid %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  filter(!haul %in% haul.or.12$haul)
```

```{r process-nav,include=FALSE}
# Source code to get nav data from ERDDAP or SCS
if (nav.source == "ERDDAP") {
  source(here("Code/get_nav_erddap.R"))
} else if (nav.source == "SCS") {
  source(here("Code/get_nav_scs.R"))
}

# Read transect waypoints
wpts <- read_csv(here("Data/Nav", wpt.filename)) %>% 
  rename(lat = Latitude, long = Longitude) %>% 
  project_df(to = crs.proj)

# Convert planned transects to sf; CRS = crs.geog
wpts.sf <- wpts %>% 
  filter(Type %in% wpt.types) %>% 
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  mutate(
    label    = paste("Transect", Transect),
    popup    = paste('<b>Transect:</b>', Transect, Type)
  )

# Create transect lines from waypoint files and add line bearing
transects.sf <- wpts.sf %>% 
  group_by(Type, Transect, Region) %>% 
  summarise(do_union = F) %>% 
  st_cast("LINESTRING") %>% 
  ungroup() %>% 
  mutate(distance = round(as.numeric(st_length(.))/1852,1),
         brg      = 360 + stplanr::line_bearing(.),
         label    = paste("Transect", Transect),
         popup    = paste('<b>Transect:</b>', Transect, Type, '<br/>',
                          'Distance:', distance, 'nmi<br/>')) 

st_write(transects.sf, here("Output/planned_transects.shp"), 
         delete_layer = TRUE)

# Create gps.csv file from nav to replace missing data in Echoview
nav.gps <- nav %>% 
  mutate(GPS_date = format(time, format = "%F"),
         GPS_time = format(time, format = "%T")) %>% 
  select(GPS_date, GPS_time, latitude = lat, longitude = long)

write_csv(nav.gps, here("Output/nav.gps.csv"))

# Get most recent vessel position for plotting
nav.now <- tail(nav, 1) %>%
  st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
  mutate(label = paste("Last position:", time, "UTC"))
```

```{r configure-base-map,include=F}
# Get map data -------------------------------
# Import landmarks
locations <- filter(read.csv(here("Data/Map/locations.csv")), name %in% label.list) %>% 
  project_df(to = crs.proj)

# Get land features --------------------------
# Get state data
states <- ne_states(country = 'United States of America', returnclass = 'sf')
ca     <- filter(states, name == "California")
wa     <- filter(states, name == "Washington")

# Get countries
countries <- ne_countries(scale = "large", returnclass = "sf") %>%
  filter(subregion %in% c("Northern America","Central America"))

# Read bathy contours shapefile 
bathy <- st_read(here("Data/GIS/bathy_contours.shp")) %>% 
  st_transform(crs.geog) %>% 
  rename(Depth = Contour)

# Read isoline
bathy_5m_line <- st_read(here("Data/GIS/bathy_us_wc_5m.shp")) %>% 
  st_transform(4326) %>% 
  rename(Depth = CONTOUR)

# Read 5m bathymetry points shapefile
bathy_5m_points <- st_read(here("Data/GIS/isobath_5m_final.shp"))

# Read 5m bathymetry polygon
bathy_5m_poly <- bathy_5m_points %>% 
  summarise(do_union = F) %>% 
  st_cast("POLYGON")

# Create a reduced coastline for nearshore point estimation
bathy_5m_df <- bathy_5m_points %>%
  mutate(
    long = as.data.frame(st_coordinates(.))$X,
    lat = as.data.frame(st_coordinates(.))$Y) %>% 
  st_set_geometry(NULL)

write_csv(bathy_5m_df, here("Data/GIS/bathy_5m_final.csv"))

# Read State Waters shapefiles -------------------------------
ca_waters <- st_read(here("Data/GIS/ca_state_waters.shp")) %>%
  st_transform(4326)

# Read CA MPAs shapefile --------------------------------------
ca_mpas <- st_read(here("Data/GIS/ca_mpas.shp")) %>%
  st_transform(4326) %>%
  mutate(MPA = paste(NAME, Type))

# Read EEZ shapefiles -----------------------------------------
eez_usa <- st_read(here("Data/GIS/eez_us.shp")) %>% 
  st_transform(4326)

# Set padding around data  
if (resize.map) {
  # Use nav data to resize map to survey progress
  map.bounds <- nav.sf %>% 
    st_transform(crs = crs.proj) %>%
    st_bbox() 
} else {
  # Use nav data to resize map to survey progress
  map.bounds <- or_waters %>%
    st_transform(crs = crs.proj) %>%
    st_bbox()  
}

# Determine map aspect ratio and set height and width
map.aspect <- (map.bounds$xmax - map.bounds$xmin)/(map.bounds$ymax - map.bounds$ymin)
map.width  <- map.height*map.aspect

# Create base map
base.map <- get_basemap(nav.paths.sf, states, countries, locations, bathy, map.bounds, crs = crs.proj) +
  # Add scalebar
  annotation_scale(style = "ticks", location = "br", height = unit(0.15, "cm"))

# Create base map for inset maps
base.map.bw <- ggplot() +
  # Plot bathymetry contours
  geom_sf(data = bathy, colour = "gray90") +
  # Plot high-res land polygons
  geom_sf(data = countries, fill = "gray90", color = "gray50") +
  geom_sf(data = states, fill = "gray90", colour = "gray50") +
  # Format axes and titles
  xlab("Longitude") + ylab("Latitude") + 
  coord_sf(crs = crs.proj, # CA Albers Equal Area Projection
           xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
           ylim = c(map.bounds["ymin"], map.bounds["ymax"])) +
  theme_bw() + 
  theme(axis.text.x  = element_blank(),
        axis.text.y  = element_blank(),
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        axis.ticks.x = element_blank(),
        axis.ticks.y = element_blank())

# Save the basemap
ggsave(base.map,file = here("Figs/fig_basemap_wa.png"), 
       height = map.height, width = map.width)

ggsave(base.map.bw,
       file = here("Figs/fig_basemap_wa_bw.png"), 
       height = map.height, width = map.width)
```

```{r ca-waters-map, eval=F}
# Add OR state waters layer
base.map + 
  geom_sf(data = or_waters, colour = "red", fill = NA) +
  geom_sf(data = or_waters_12, colour = "green", fill = NA) +
  coord_sf(crs = crs.proj, 
           xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
           ylim = c(map.bounds["ymin"], map.bounds["ymax"]))
```

```{r or-hauls-map, eval=F}
# Add OR state waters layer
base.map + 
  geom_sf(data = or_waters, colour = "red", fill = NA) +
  geom_sf(data = or_waters_12, colour = "green", fill = NA) +
  geom_sf(data = haul.or, fill = "red", shape = 21) +
  geom_sf(data = haul.or.12, fill = "green", shape = 21) +
  coord_sf(crs = crs.proj, 
           xlim = c(map.bounds["xmin"], map.bounds["xmax"]), 
           ylim = c(map.bounds["ymin"], map.bounds["ymax"]))
```

```{r extract-catch}
catch.or <- catch.all %>% 
  filter(haul %in% haul.or.12$haul) %>% 
  left_join(spp.codes) %>% 
  filter(!subSampleWtkg == 0) 
```

```{r process-catch}
# Summarize species catch by weight and number
catch.summary <- catch.or %>% 
  mutate(totalWeight = subSampleWtkg + remainingSubSampleWtkg,
         totalNum = totalWeight/(subSampleWtkg/subSampleCount)) %>%
  group_by("Scientific Name" = scientificName, 
           "Common Name" = commonName) %>% 
  summarise("Total weight (kg)" = round(sum(totalWeight), 2),
            "Total number (n)"  = round(sum(totalNum), 0)) %>% 
  arrange(desc(`Total weight (kg)`)) 

write_csv(catch.summary,
          here("Output", paste0(survey.name, "_catch_summary_ODFW.csv")),
          na = "")
```

```{r extract-specimens}
# Extract specimens from hauls in CA waters
specimens.or <- lengths.all %>% 
  filter(haul %in% haul.or.12$haul) %>% 
  # left_join(select(haul.ca, key, date_time)) %>% 
  left_join(spp.codes)

# Write specimen level data to CSV
write_csv(specimens.or, 
          file = here("Output", paste0(survey.name, "_specimen_info_ODFW.csv")))

# Summarize specimens
specimen.summ <- specimens.or %>% 
  # Select specimens where weights, otoliths, and/or DNA were taken
  filter(!is.na(otolithNumber) | !is.na(DNAvialNumber) | 
           !is.na(weightg)) %>% 
  select(haul, commonName, scientificName, weightg, 
         otolithNumber, DNAvialNumber, hasDNAfinClip, adiposeCondition) %>% 
  group_by(haul, commonName, scientificName) %>% 
  # !is.na(var) converts to logical then sum gives the total counts
  summarise(measured = sum(!is.na(weightg)), 
            otoliths = sum(!is.na(otolithNumber)),
            DNA      = sum(!is.na(DNAvialNumber)),
            adipose_intact  = sum(adiposeCondition == "intact", na.rm = TRUE),
            adipose_clipped = sum(adiposeCondition == "clipped", na.rm = TRUE)) %>% 
  arrange(scientificName) %>% 
  adorn_totals()

# Save specimen summary to CSV
write_csv(specimen.summ, 
          here("Output", paste0(survey.name, "_specimen_table_ODFW.csv")),
          na = "")
```

# Interactive trawl plot

A map showing all trawl hauls (white points), trawls in OR State waters (within 3 nmi of the coast; red points). Hovering over points will show the haul number.  

```{r catch-map-leaflet}
# Configure palette for MPAs
# factpal <- colorFactor(topo.colors(10), ca_mpas$MPA)

# Create leaflet map
if (nrow(haul.or) > 0 | nrow(haul.or.12) > 0) {
  leaflet() %>% 
    addProviderTiles(providers$Esri.OceanBasemap) %>%  
    # Add EEZs
    addPolylines(data = eez_usa, color = "#000414", weight = 3, 
                 label = "EEZ-U.S.") %>% 
    addPolygons(data = or_waters, weight = 2, fillColor = "transparent") %>% 
    addPolygons(data = or_waters_12, weight = 2, fillColor = "transparent") %>% 
    addPolylines(data = haul.paths, color = c("#000000"), weight = 5, opacity = 0.8, 
                 popup = ~~paste("Haul:", haul), label = ~paste("Haul:", haul)) %>% 
    addCircleMarkers(data = haul.out, radius = 3, color = "#000000", stroke = TRUE, weight = 2,
                     opacity = 0.8, fillOpacity = 1, fillColor =  "white",
                     label = ~paste("Haul:", haul),
                     popup = ~paste("Haul:", haul)) %>% 
    addCircleMarkers(data = haul.or, radius = 3, color = "#000000", stroke = TRUE, weight = 2,
                     opacity = 0.8, fillOpacity = 1, fillColor =  "red",
                     label = ~paste("Haul:", haul),
                     popup = ~paste("Haul:", haul)) %>% 
    addCircleMarkers(data = haul.or.12, radius = 3, color = "#000000", stroke = TRUE, weight = 2,
                     opacity = 0.8, fillOpacity = 1, fillColor =  "green",
                     label = ~paste("Haul:", haul),
                     popup = ~paste("Haul:", haul)) %>% 
    # Add scale bar
    addScaleBar(position = "bottomright") %>%
    # Add map coordinates
    addMouseCoordinates() %>% 
    # Add measurement tool
    addMeasure(primaryLengthUnit = "miles", secondaryLengthUnit = "km",
               primaryAreaUnit = "sqmiles", secondaryAreaUnit = "sqmeters",
               position = "topleft") 
} else {
  leaflet() %>% 
    addProviderTiles(providers$Esri.OceanBasemap) %>%  
    # Add EEZs
    addPolylines(data = eez_usa, color = "#000414", weight = 3, 
                 label = "EEZ-U.S.") %>% 
    addPolygons(data = or_waters, weight = 2, fillColor = "transparent") %>% 
    addPolygons(data = or_waters_12, weight = 2, fillColor = "transparent") %>% 
    addPolylines(data = haul.paths, color = c("#000000"), weight = 5, opacity = 0.8, 
                 popup = ~~paste("Haul:", haul), label = ~paste("Haul:", haul)) %>% 
    addCircleMarkers(data = haul.out, radius = 3, color = "#000000", stroke = TRUE, weight = 2,
                     opacity = 0.8, fillOpacity = 1, fillColor =  "white",
                     label = ~paste("Haul:", haul),
                     popup = ~paste("Haul:", haul)) %>% 
    addCircleMarkers(data = haul.or, radius = 3, color = "#000000", stroke = TRUE, weight = 2,
                     opacity = 0.8, fillOpacity = 1, fillColor =  "red",
                     label = ~paste("Haul:", haul),
                     popup = ~paste("Haul:", haul))  %>% 
    addCircleMarkers(data = haul.or.12, radius = 3, color = "#000000", stroke = TRUE, weight = 2,
                     opacity = 0.8, fillOpacity = 1, fillColor =  "green",
                     label = ~paste("Haul:", haul),
                     popup = ~paste("Haul:", haul))  %>% 
    # Add scale bar
    addScaleBar(position = "bottomright") %>%
    # Add map coordinates
    addMouseCoordinates() %>% 
    # Add measurement tool
    addMeasure(primaryLengthUnit = "miles", secondaryLengthUnit = "km",
               primaryAreaUnit = "sqmiles", secondaryAreaUnit = "sqmeters",
               position = "topleft")
}
```

# Catch summary
## By species

Catch for all trawl samples in  are summarized in the table below. Species are listed descending by weight. For hauls with large catches (i.e., > 5 baskets), the total number was estimated from the total weight and the average weight of specimens in the subsample.

```{r catch-summary}
if (nrow(catch.or) > 0) {
  catch.summary %>% 
    kable(format = knitr.format,booktabs = TRUE, escape = FALSE) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"), 
                  full_width = FALSE) %>%
    row_spec(0, align = c("c")) %>% 
    column_spec(1, italic = T) %>% 
    scroll_box(height = "500px")  
} else {
  cat("No catch in Oregon.")
}
```

## By haul

Catch for each trawl sample by species.

```{r catch-hauls}
if (nrow(catch.or) > 0) {
  catch.all <- catch.or %>% 
    select(Haul = haul,
           "Scientific Name" = scientificName,
           "Common Name" = commonName,
           "Total weight (kg)" = totalWeight, 
           "Total number (n)" = totalNum) %>% 
    arrange(Haul, desc(`Total weight (kg)`))
  
  write_csv(catch.all,
            here("Output", paste0(survey.name, "_catch_table_ODFW.csv")),
            na = "")
  
  catch.all %>% 
    kable(format = knitr.format,booktabs = TRUE, escape = FALSE) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"), 
                  full_width = FALSE) %>%
    row_spec(0, align = c("c")) %>% 
    column_spec(2, italic = T) %>% 
    scroll_box(height = "500px")
  
} else {
  cat("No catch in Oregon.")
}
```

# Specimen summary

A summary of samples taken from specimens collected in Oregon.

```{r specimen-summary}
if (nrow(specimens.or) > 0) {
  specimen.summ %>% 
    kable(format = knitr.format,booktabs = TRUE, escape = FALSE) %>% 
    kable_styling(bootstrap_options = c("striped","hover","condensed"), 
                  full_width = FALSE) %>%
    row_spec(0, align = c("c")) %>% 
    column_spec(3, italic = T) %>% 
    scroll_box(height = "500px")  
} else {
  cat("No specimens in Oregon.")
}
```

# CUFES samples

```{r import-cufes-data}
if (sampling.cufes) {
  if (get.db) {
    if (cufes.source == "SQLite") {
      # Configure ODBC connection to TRAWL database
      cufes.filename <- path_file(dir_ls(here("Data/CUFES"), regexp = "*.sqlite"))
      cufes.con      <- dbConnect(SQLite(), dbname = here("Data/CUFES", cufes.filename))
      # Create the pointer to the CUFES table
      cufes.all <- tbl(cufes.con, "cufessqlite") %>% collect()
      
      # Close connection
      dbDisconnect(cufes.con)  
    } else if (cufes.source == "SQL") {
      cufes.con  <- dbConnect(odbc::odbc(), 
                              Driver = "SQL Server", 
                              Server = "161.55.235.187", 
                              Database = "CUFES", 
                              Trusted_Connection = "True")
      # Create the pointer to the CUFES table
      cufes.all <- tbl(cufes.con, "CUFES") %>% collect()
      
      # Close connection
      dbDisconnect(cufes.con)  
    } else if (cufes.source == "CSV") {
      # cufes.source = "CSV"
      cufes.filename <- file.path(here("Data/CUFES", cufes.db.csv))
      
      cufes.all <- read_csv(cufes.filename) %>% 
        mutate(Cruise = as.character(Cruise))
      
      if (is.null(cufes.all$Comments)) cufes.all$Comments <- NA_character_
    }
    
    # Read CUFES data
    cufes.all <- cufes.all %>%
      # collect() %>% 
      mutate(
        Start = case_when(
          cufes.date.format == "mdy" ~ mdy_hms(Start), #"06/01/2019-15:43:00"
          cufes.date.format == "ymd" ~ ymd_hms(Start)),#"1996-03-15 15:43:00 -08:00"
        Stop = case_when(
          cufes.date.format == "mdy" ~ mdy_hms(Stop), #"06/01/2019-15:43:00"
          cufes.date.format == "ymd" ~ ymd_hms(Stop)),#"1996-03-15 15:43:00 -08:00"
        Duration = as.numeric(difftime(Stop, Start, units = "mins")),
        Year = year(Start),
        AllEggs = SardineEggs + AnchovyEggs + JackMackerelEggs) %>% 
      filter(between(Start, date(cufes.start), date(cufes.end)),
             Ship %in% cruise.ship) 
    
    if (survey.name %in% c("1507SH")) {
      cufes.all <- cufes.all %>% 
        rename(lat = StopLatitude, long = StopLongitude) %>% 
        project_df(to = crs.proj)
    } else {
      cufes.all <- cufes.all %>% 
        rename(lat = StartLatitude, long = StartLongitude)%>% 
        project_df(to = crs.proj)
    }
    
    # Save imported database data to .Rdata file
    save(cufes.all, file = here("Data/CUFES/cufes_data.Rdata"))
  } else {
    # Load previously imported database data
    load(here("Data/CUFES/cufes_data.Rdata"))
  }
  
  cufes.sf <- cufes.all %>% 
    st_as_sf(coords = c("long","lat"), crs = crs.geog) %>% 
    st_intersection(or_waters)
  
  cufes.all %>% 
    filter(SampleNumber %in% cufes.sf$SampleNumber) %>% 
    select(SampleNumber, Start, lat, long, SardineEggs, AnchovyEggs,
           JackMackerelEggs, HakeEggs, SquidEggs, OtherFishEggs, Comments) %>% 
    write_csv(here("Output", paste0(survey.name, "_CUFES_table_ODFW.csv")),)
} else {
  print("No CUFES data collected.")
}
``` 

For questions about the contents of this report, please contact Kevin Stierhoff ([kevin.stierhoff@noaa.gov](mailto:kevin.stierhoff@noaa.gov)).

