---
title: "plotTrawls: Trawl Data Explorer"
author: "Kevin Stierhoff (maintainer)"
date: 'Last updated: `r format(Sys.time(), "%F %T", tz = "America/Los_Angeles", usetz = TRUE)`'
output:
  bookdown::html_document2:
    toc: no
    toc_float: no
    number_sections: yes
css: css/ast.css
bibliography: bib/ast_bib.bib
csl: csl/ices-journal-of-marine-science.csl
---

```{r set-up,echo=F,message=F,warning=F,error=F,include=F}
# Install and load pacman (library management package)
if (!require("pacman")) install.packages("pacman")
if (!require("pak")) install.packages("pak")

# Install and load required packages from CRAN ---------------------------------
pacman::p_load(tidyverse,plotly,lubridate,here,odbc,DBI,glue,
               knitr,DT,fs,cowplot,oce,sf,mapview,shadowtext,
               patchwork)

# Install and load required packages from Github -------------------------------
if (!require("atm")) pkg_install("SWFSC/atm")
if (!require("surveyR")) pkg_install("SWFSC/surveyR")
pacman::p_load_gh("SWFSC/atm")
pacman::p_load_gh("SWFSC/surveyR")

# Knitr options
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE,
                      out.width = "90%")

theme_set(theme_bw())
```

```{r project-settings, include=FALSE}
# Get project name from directory
prj.name <- last(unlist(str_split(here(),"/")))

# Get all settings files
settings.files <- dir(here("Doc/settings"))

# Source survey settings file
prj.settings <- settings.files[str_detect(settings.files, paste0("settings_", prj.name, ".R"))]
source(here("Doc/settings", prj.settings))

# Create required directories
dir_create(here(c("Figs/TDR", "Output")))
```

```{r user-settings}
# User-specified settings
copy.files   <- T # Copy TDR files
process.rsk  <- T # Process RBR Duet^3^ TDR files (.rsk format)
process.asc  <- F # Process Seabird TDR files (.asc format)
asc.offset   <- 0 # ASCII file time offset, in hours
process.tv80 <- T # Process Simrad TV80 data

# Usually F; set T to reprocess all TDR/TV80 files
process.tdr.all   <- F # Process all TDR files 
process.tv80.all  <- F # Process all TV80 files

get.db      <- T # Extract data from trawl database (F for testing)
get.nav     <- T # Download NOAA Ship nav data
get.nav.sh  <- F # Download NOAA Ship nav data
```

```{r copy-files}
if (copy.files) {
  # Create directory for TDR files -------------------------------------------------
  dir_create(here("Data/TDR", c("Kite","Footrope")))
  
  # Copy TDR files
  tdr.files.kite <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/TDR/Kite"),
                           regexp = tdr.pattern)
  file_copy(tdr.files.kite, here("Data/TDR/Kite"), overwrite = TRUE)
  
  tdr.files.foot <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/TDR/Footrope"),
                           regexp = tdr.pattern)
  file_copy(tdr.files.foot, here("Data/TDR/Footrope"), overwrite = TRUE)
  
  # Create directory for TV80 files -------------------------------------------------
  dir_create(here("Data/TV80"))
  
  # Copy TV80 files
  tv80.files <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/TV80"),
                       regexp = "*measurements.csv", recurse = TRUE)
  
  # Copy files where file is empty (size > 0 bytes)
  file_copy(tv80.files[file_info(tv80.files)$size>0], here("Data/TV80"), overwrite = TRUE)
}
```

```{r get-nav}
# Source code to get nav data from ERDDAP or SCS
if (tdr.nav.source == "ERDDAP") {
  source(here("Code/get_nav_erddap.R"))
} else if (nav.source == "SCS") {
  source(here("Code/get_nav_scs.R"))
}

# Get nav data from Shimada
if (get.nav.sh) {
  source(here("Code/get_nav_erddap_SH.R"))
  
  nav <- bind_rows(nav, nav.sh)
}
```

```{r get-trawl-data}
if (get.db) {
  if (tdr.trawl.source == "SQL") {
    # Configure ODBC connection to TRAWL database
    trawl.con  <- dbConnect(odbc(), 
                            Driver = "SQL Server", 
                            Server = "161.55.235.187", 
                            Database = "Trawl", 
                            Trusted_Connection = "True")
  } else if (tdr.trawl.source == "Access") {
    # Copy trawl Access database
    haul.db <- dir_ls(file.path(survey.dir[survey.vessel.primary], "DATA/BIOLOGICAL/HAUL"),
                      regexp = trawl.db.access)
    
    file_copy(haul.db, here("Data/Trawl"), overwrite = TRUE)
    
    # Configure ODBC connection to TRAWL database
    trawl.con  <- dbConnect(odbc(), 
                            Driver = "Microsoft Access Driver (*.mdb, *.accdb)", 
                            DBQ = file.path(here("Data/Trawl"),trawl.db.access))
  }
  # Import trawl database tables
  haul.all       <- tbl(trawl.con,"Haul") %>% collect()
  
  # Close database channel
  dbDisconnect(trawl.con)
  
  # Save trawl data
  saveRDS(haul.all,
          file = here("Data/Trawl/haul_data_tdr.rds"))
  
} else {
  # Load trawl data
  haul.all <- readRDS(here("Data/Trawl/haul_data_tdr.rds"))
  
}
```

```{r format-trawl-data}
# Create startLatitudeDecimal and startLongitudeDecimal for Access data
if (tdr.trawl.source == "Access") {
  # Reformat haul data to match SQL
  haul.all <- haul.all %>% 
    arrange(haul) %>% 
    mutate(
      startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
      startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
      stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
      stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60))) %>%
    mutate(haulBackTime = case_when(
      haulBackTime < equilibriumTime ~ haulBackTime + days(1),
      TRUE ~ haulBackTime))
  
  # Identify hauls where date of equilibriumTime or haulBackTime is incorrect
  eq.fix <- which(c(0, diff(haul.all$equilibriumTime)) < 0)
  hb.fix <- which(c(0, diff(haul.all$haulBackTime)) < 0)
  
  # Correct equilibriumTime or haulBackTime
  haul.all$equilibriumTime[eq.fix] <- haul.all$equilibriumTime[eq.fix] + days(1)
  haul.all$haulBackTime[eq.fix]    <- haul.all$haulBackTime[eq.fix] + days(1)
  
} else if (tdr.trawl.source == "SQL") {
  haul.all <- haul.all %>% 
    arrange(haul) %>% 
    mutate(
      equilibriumTime = ymd_hms(equilibriumTime),
      haulBackTime    = ymd_hms(haulBackTime)) #%>% 
  #     mutate(
  #         startLatDecimal  =   startLatitudeDegrees + (startLatitudeMinutes/60),
  #         startLongDecimal = -(startLongitudeDegrees + (startLongitudeMinutes/60)),
  #         stopLatDecimal   =   stopLatitudeDegrees + (stopLatitudeMinutes/60),
  #         stopLongDecimal  = -(stopLongitudeDegrees + (stopLongitudeMinutes/60)))
}

# Classify hauls by season (spring or summer)
haul.all <- haul.all %>% 
  mutate(season = case_when(
    month(equilibriumTime) < 6 ~ "spring",
    TRUE ~ "summer"))

# Get only hauls from current survey
haul <- filter(haul.all, cruise %in% tdr.cruise) %>% 
  arrange(haul) %>% 
  mutate(
    netInWaterTime  = ymd_hms(netInWaterTime,  tz = tdr.tz),
    equilibriumTime = ymd_hms(equilibriumTime, tz = tdr.tz),
    haulBackTime    = ymd_hms(haulBackTime,    tz = tdr.tz),
    netOnDeckTime   = ymd_hms(netOnDeckTime,   tz = tdr.tz),
    duration        = difftime(haulBackTime, equilibriumTime, units = "mins"), # Calculate duration
    cluster   = cumsum(c(0, diff(equilibriumTime)) > 12) + 1) 

# Find midpoint of each haul as the mean lat/lon
haul.mid <- haul %>% 
  group_by(cluster, haul) %>% 
  summarise(
    lat  = mean(c(startLatDecimal, stopLatDecimal)),
    long = mean(c(startLongDecimal, stopLongDecimal))) 

# Find midpoint of each haul cluster as the average of haul midpoints
cluster.mid <- haul.mid %>% 
  group_by(cluster) %>% 
  summarise(
    lat  = mean(lat),
    long = mean(long))
```

```{r process-tdr-rsk}
# Calculate mean latitude for computing depth from pressure
# Could be improved (marginally) by extracting the latitude for each haul
mean.lat <- mean(haul$startLatDecimal)

# Process TDR files ----------------------------------------------------------------------
# Get fileSnapshot at the beginning of the knit, to compare with the end of the last knit
tdr.snapshot.start.k <- fileSnapshot(here("Data/TDR/Kite"), full.names = FALSE)
tdr.snapshot.start.f <- fileSnapshot(here("Data/TDR/Footrope"), full.names = FALSE)

# Load fileSnapshot from last knit, or make equal to the start
if (file.exists(here("Output/tdr_snapshot_end_k.rds"))){
  tdr.snapshot.end.k <- readRDS(here("Output/tdr_snapshot_end_k.rds"))
} else {
  tdr.snapshot.end.k <- tdr.snapshot.start.k
}

# Load fileSnapshot from last knit, or make equal to the start
if (file.exists(here("Output/tdr_snapshot_end_f.rds"))){
  tdr.snapshot.end.f <- readRDS(here("Output/tdr_snapshot_end_f.rds"))
} else {
  tdr.snapshot.end.f <- tdr.snapshot.start.f
}

# Identify new and changed files
tdr.changed.k    <- changedFiles(tdr.snapshot.end.k, tdr.snapshot.start.k) 
tdr.changed.f    <- changedFiles(tdr.snapshot.end.f, tdr.snapshot.start.f) 
# List files that need to be processed
tdr.to.process.k <- c(tdr.changed.k$changed, tdr.changed.k$added)
tdr.to.process.f <- c(tdr.changed.f$changed, tdr.changed.f$added)

if (process.rsk) {
  # List all kite files
  rsk.files.kite <- dir_ls(tdr.dir.kite, 
                           recurse = tdr.recurse, regexp = tdr.pattern)
  # List all footrope files
  rsk.files.foot <- dir_ls(tdr.dir.foot, 
                           recurse = tdr.recurse, regexp = tdr.pattern)
  
  if (process.tdr.all) {
    # If processing all files, create empty tibbles for TDR data
    tbl.all <- tibble()
    
  } else  {
    if (file.exists(here("Output/tdr_data_all.Rdata"))) {
      # Load data frame with already processed TDR data
      load(here("Output/tdr_data_all.Rdata")) 
      
      # If files have changed, remove those data from the already processed data
      if (length(tdr.changed.k$changed) > 0) {
        tbl.all <- tbl.all %>% 
          filter(!path_file(filename) %in% path_file(fs_path(tdr.changed.k$changed)))
      }
      
      if (length(tdr.changed.f$changed) > 0) {
        tbl.all <- tbl.all %>% 
          filter(!path_file(filename) %in% path_file(fs_path(tdr.changed.k$changed))) 
      }
      
    } else {
      # Create an empty data frame
      tbl.all <- tibble()
    }
    
    if (length(tdr.to.process.k) > 0) {
      # List only new TDR files
      rsk.files.kite <- rsk.files.kite[fs::path_file(rsk.files.kite) %in% 
                                         path_file(fs_path(tdr.to.process.k))]  
    } else {
      # Set length of csv.files.cps to zero
      rsk.files.kite <- character(0)
    }
    
    if (length(tdr.to.process.f) > 0) {
      # List only new TDR files
      rsk.files.foot <- rsk.files.foot[fs::path_file(rsk.files.foot) %in% 
                                         path_file(fs_path(tdr.to.process.f))]  
    } else {
      # Set length of csv.files.cps to zero
      rsk.files.foot <- character(0)
    }
  }
  
  # Save snapshot
  saveRDS(tdr.snapshot.start.k, here("Output/tdr_snapshot_end_k.rds"))
  saveRDS(tdr.snapshot.start.f, here("Output/tdr_snapshot_end_f.rds"))
  
  # Process Kite files ----------------------------------------------------------------------
  ## Create tibble for storing results
  tbl.kite <- tibble()
  
  if (length(rsk.files.kite) > 0) {
    for (i in rsk.files.kite) {
      rsk.kite <- read.rsk(i)
      
      # Convert to tibble
      tbl.kite.tmp <- as_tibble(rsk.kite@data) %>% 
        mutate(filename = path_file(rsk.kite@metadata$filename),
               cruise = str_extract(filename, "^\\d{4}\\w{2}"),
               haul = as.numeric(str_sub(filename, nchar(cruise) + 1, nchar(cruise) + 3)),
               depth = surveyR::calc_depth(mean.lat, pressure*100),
               loc   = "Kite",
               time  = force_tz(time, tz = tdr.tz)) 
      
      
      tbl.kite <- bind_rows(tbl.kite, tbl.kite.tmp)
    }
  }
  
  # Process Footrope files ----------------------------------------------------------------------
  ## Create tibble for storing results
  tbl.foot <- tibble()
  
  if (length(rsk.files.foot) > 0) {
    for (i in rsk.files.foot) {
      rsk.foot <- read.rsk(i)
      
      # Convert to tibble
      tbl.foot.tmp <- as_tibble(rsk.foot@data) %>% 
        mutate(filename = path_file(rsk.foot@metadata$filename),
               cruise = str_extract(filename, "^\\d{4}\\w{2}"),
               haul = as.numeric(str_sub(filename, nchar(cruise) + 1, nchar(cruise) + 3)),
               depth = surveyR::calc_depth(mean.lat, pressure*100),
               loc   = "Footrope",
               time  = force_tz(time, tz = tdr.tz)) 
      
      tbl.foot <- bind_rows(tbl.foot, tbl.foot.tmp)
    }
  }
  
  # Combine new data
  tbl.all.new <- bind_rows(tbl.kite, tbl.foot)
  
  # Combine new and existing data
  tbl.all <- bind_rows(tbl.all, tbl.all.new)
  
  # Save processed TDR data
  save(tbl.all, file = here("Output/tdr_data_all.Rdata"))
} else {
  # Load already processed TDR data
  load(here("Output/tdr_data_all.Rdata"))
}
```

```{r process-tdr-asc}
# Process .asc files from Seabird TDRs
if (process.asc) {
  # List all kite files
  asc.files.stbd <- dir_ls(tdr.dir.stbd, 
                           recurse = TRUE, regexp = "*.asc")
  # List all footrope files
  asc.files.port <- dir_ls(tdr.dir.port, 
                           recurse = TRUE, regexp = "*.asc")
  
  # Process Starboard files ------------------------------------------------------------------
  ## Create tibble for storing results
  tbl.stbd <- tibble()
  
  if (length(asc.files.stbd) > 0) {
    for (i in asc.files.stbd) {
      asc.stbd <- read_csv(i, skip = 11,
                           col_names = c("temperature","pressure","date","time")) %>% 
        mutate(filename = path_file(i),
               cruise = survey.name,
               haul  = as.numeric(str_sub(filename, nchar("starboard_") + 1, nchar("starboard_") + 3)),
               loc   = "Starboard",
               depth = surveyR::calc_depth(mean.lat, pressure*100)-10,
               time = dmy_hms(paste(date, time)) - hours(asc.offset),
               time = with_tz(time, tzone = tdr.tz))
      
      tbl.stbd <- bind_rows(tbl.stbd, asc.stbd)
    }
    
    # Combine results
    tbl.all <- bind_rows(tbl.all, filter(tbl.stbd, !filename %in% unique(tbl.all$filename)))
    
    # Combine with tbl.all.new
    if(nrow(tbl.all.new) > 0) {
      tbl.all.new <- bind_rows(tbl.all.new, filter(tbl.stbd, haul %in% unique(tbl.all.new$haul)))
    }
  }
  
  # Process Port files ----------------------------------------------------------------------
  ## Create tibble for storing results
  tbl.port <- tibble()
  
  if (length(asc.files.port) > 0) {
    for (i in asc.files.port) {
      asc.port <- read_csv(i, skip = 11,
                           col_names = c("temperature","pressure","date","time")) %>% 
        mutate(filename = path_file(i),
               cruise = survey.name,
               haul  = as.numeric(str_sub(filename, nchar("port_") + 1, nchar("port_") + 3)),
               loc   = "Port",
               depth = surveyR::calc_depth(mean.lat, pressure*100)-10,
               time = dmy_hms(paste(date, time)) - hours(asc.offset),
               time = with_tz(time, tzone = tdr.tz))
      
      tbl.port <- bind_rows(tbl.port, asc.port)
    }
    
    # Combine results
    tbl.all <- bind_rows(tbl.all, filter(tbl.port, !filename %in% unique(tbl.all$filename)))
    
    # Combine with tbl.all.new
    if(nrow(tbl.all.new) > 0) {
      tbl.all.new <- bind_rows(tbl.all.new, filter(tbl.port, haul %in% unique(tbl.all.new$haul)))
    }
  }
}
```

```{r process-tv80}
if (process.tv80) {
  # Get fileSnapshot at the beginning of the knit, to compare with the end of the last knit
  tv80.snapshot.start <- fileSnapshot(here("Data/TV80"), full.names = FALSE)
  
  # Load fileSnapshot from last knit, or make equal to the start
  if (file.exists(here("Output/tv80_snapshot_end.rds"))){
    # saveRDS(csv.snapshot.start, here("Output/csv_snapshot_end.rds"))
    tv80.snapshot.end <- readRDS(here("Output/tv80_snapshot_end.rds"))
  } else {
    tv80.snapshot.end <- tv80.snapshot.start
  }
  
  # Identify new and changed files
  tv80.changed    <- changedFiles(tv80.snapshot.end, tv80.snapshot.start) 
  # List files that need to be processed
  tv80.to.process <- c(tv80.changed$changed, tv80.changed$added)
  
  if (process.tv80) {
    # Process added and changed CSV files --------------------------
    # List TV80 measurement files
    tv80.files <- fs::dir_ls(here("Data/TV80"), 
                             recurse = TRUE,
                             regexp = "*.measurements.csv")
    
    if (process.tv80.all) {
      print("Processing all TV80 data.")
      
      # Create an empty data frame
      tv80.meas <- data.frame()
      
    } else {
      if (file.exists(here("Output/tv80_measurements.Rdata"))) {
        # Load data frame with already processed backscatter data
        load(here("Output/tv80_measurements.Rdata")) 
        
        if (length(tv80.changed$changed) > 0) {
          # If files have changed, remove those data
          tv80.meas <- tv80.meas %>% 
            filter(!path_file(file) %in% path_file(fs_path(tv80.changed$changed))) 
        }
      } else {
        # Create an empty data frame
        tv80.meas <- data.frame()
      }
      
      if (length(tv80.to.process) > 0) {
        # List only new TV80 files
        tv80.files <- tv80.files[fs::path_file(tv80.files) %in% 
                                   path_file(fs_path(tv80.to.process))]  
      } else {
        print("No new/changed TV80 data.")
        
        # Set length of tv80.files to zero
        tv80.files <- character(0)
      }
    }
    
    if (length(tv80.files) > 0) {
      print("Processing new/changed TV80 data.")
      
      # Configure progress bar
      pb <- winProgressBar(title = "TV80 File Processing Progress", 
                           label = "0% done", min = 0, max = 100, initial = 0)
      
      # Process all TV80 measurement files
      for (i in 1:length(tv80.files)) {
        # Process i-th file
        tv80.meas <- bind_rows(tv80.meas,
                               atm::extract_tv80(file = tv80.files[i]))
        
        # Update the progress bar
        info <- sprintf("%d%% done", round((i / length(tv80.files)) * 100))
        setWinProgressBar(pb, round((i / length(tv80.files)) * 100), label = info)
      }
      close(pb)
      
      # Save results
      save(tv80.meas, file = here("Output/tv80_measurements.Rdata"))
      write_csv(tv80.meas, file = here("Output/tv80_measurements.csv"))
    }
    
    # Save snapshot
    saveRDS(tv80.snapshot.start, here("Output/tv80_snapshot_end.rds"))
    
  } else {
    print ("Loading processed TV80 data.")
    load(here("Output/tv80_measurements.Rdata"))
  }
}
```

```{r plot-results}
# Plot and save all new deployments
if(nrow(tbl.all.new) > 0) {
  for (k in unique(tbl.all.new$haul)) {
    # Get TDR data from haul k
    tdr.plot <- filter(tbl.all.new, haul == k) %>% 
      mutate(time = time + hours(tdr.offset[k]))
    
    # Get haul info from haul k
    trawl.window <- haul %>% 
      filter(haul == k)
    
    # Format data for text labels
    trawl.text <- trawl.window %>% 
      select(haul, 'Net in water' = netInWaterTime, 'Equilibrium' = equilibriumTime, 
             'Haul back' = haulBackTime, 'Net on deck' = netOnDeckTime) %>% 
      pivot_longer(cols = 'Net in water':'Net on deck', names_to = "event", values_to = "time") 
    
    # Get date range to set x-axis limits
    tdr.date.lims <- range(trawl.text$time)
    
    # Buffer lims to show geom_rect
    tdr.date.lims[1] <- tdr.date.lims[1] - minutes(2)
    tdr.date.lims[2] <- tdr.date.lims[2] + minutes(2)
    
    # Extract nav data for 30 min before and after haul
    trawl.nav <- nav %>% 
      mutate(time = with_tz(time, tzone = tdr.tz) + hours(-1))  %>%
      filter(between(time,  
                     min(trawl.text$time, na.rm = TRUE) - minutes(10), 
                     max(trawl.text$time, na.rm = TRUE) + minutes(10)))
    
    # Extract TDR data for 30 min before and after haul 
    tdr.plot <- tdr.plot %>% 
      filter(between(time,  
                     min(trawl.text$time, na.rm = TRUE) - minutes(10), 
                     max(trawl.text$time, na.rm = TRUE) + minutes(10)))
    
    # Pivot wider to compute mouth opening height
    if (exists("tdr.plot.wider")) rm(tdr.plot.wider)
    
    if ("Kite" %in% tdr.plot$loc && "Footrope" %in% tdr.plot$loc) {
      tdr.plot.wider <- tdr.plot %>% 
        select(time, depth, loc) %>% 
        pivot_wider(names_from = loc, values_from = depth) %>% 
        mutate(height = Kite - Footrope)  
    }
    
    # Plot TDR data
    plot.tdr <- ggplot() + 
      geom_line(data = tdr.plot,
                aes(time, depth + 10, colour = loc)) + 
      scale_colour_manual(name = "Location", values = c(Footrope = "blue", Kite = "purple",
                                                        Starboard = "magenta", Port = "green"),
                          guide = guide_legend(reverse = TRUE)) +
      geom_hline(yintercept = 0, colour = "gray50") +
      scale_y_continuous(limits = c(-60, 12), 
                         breaks = c(-60, -50, -40, -30, -20, -10, seq(0, 12,4))) +
      scale_x_datetime(date_breaks = "5 min", date_labels = "%R",
                       limits = tdr.date.lims) +
      labs(x = "Time (PST)",
           y = "Depth (m)",
           title = paste("Cruise:", unique(tdr.plot$cruise), 
                         "; Haul:", unique(tdr.plot$haul),
                         "; Date:", date(tdr.plot$time[1]))) + 
      theme(legend.position.inside = c(0.99,0.01),
            legend.justification   = c(1,0),
            axis.text.x = element_text(angle = 45, vjust = 0.5)) 
    
    # Add SOG if present
    if (nrow(trawl.nav) > 0) {
      plot.tdr <- plot.tdr + 
        geom_line(data = trawl.nav,
                  aes(time, SOG),
                  colour = "black") 
    }
    
    # Plot mouth opening height
    if (exists("plot.height")) rm(plot.height)
    if (exists("tdr.plot.wider")) {
      plot.height <- ggplot() + 
        geom_path(data = tdr.plot.wider, 
                  aes(time, height, colour = height),
                  show.legend = FALSE) +
        geom_hline(yintercept = 20, linetype = "dashed") +
        scale_x_datetime(date_breaks = "5 min", date_labels = "%R",
                         limits = tdr.date.lims) +
        scale_colour_viridis_c(option = "plasma") +
        theme(axis.text.x = element_text(angle = 45, vjust = 0.5)) +
        labs(x = "Time (PST)", y = "Height (m)")  
    }
    
    # Add TV80 data, if present
    if(exists("tv80.meas")) {
      # Extract TV80 data for 30 min before and after haul
      trawl.tv80 <- tv80.meas %>% 
        mutate(datetime = with_tz(datetime, tzone = tdr.tz) + hours(-1))  %>%
        filter(between(datetime,  
                       min(trawl.text$time, na.rm = TRUE) - minutes(10), 
                       max(trawl.text$time, na.rm = TRUE) + minutes(10))) %>% 
        filter(DOR_Depth_Prt < 100, DOR_Depth_Std < 100, VES_Speed < 10, DOR_Spread < 150)
      
      # Add TV80 data to plot
      if (nrow(trawl.tv80) > 0) {
        plot.tdr <- plot.tdr + 
          geom_line(data = trawl.tv80,
                    aes(datetime, VES_Speed), colour = "gray50", alpha = 0.5) +
          geom_line(data = trawl.tv80, aes(datetime, -DOR_Depth_Prt), colour = "green") +
          geom_line(data = trawl.tv80, aes(datetime, -DOR_Depth_Std), colour = "red") 
      }
      
      # Plot door spread
      if (exists("plot.spread")) rm(plot.spread)
      if (nrow(trawl.tv80) > 0) {
        plot.spread <- ggplot() + 
          geom_path(data = trawl.tv80, 
                    aes(datetime, DOR_Spread, colour = DOR_Spread),
                    show.legend = FALSE) +
          geom_hline(yintercept = 65, linetype = "dashed") +
          scale_x_datetime(date_breaks = "5 min", date_labels = "%R",
                           limits = tdr.date.lims) +
          scale_colour_viridis_c(option = "plasma") +
          theme(axis.text.x = element_text(angle = 45, vjust = 0.5)) +
          labs(x = "Time (PST)", y = "Door spread (m)")  
      }
    }
    
    # Add trawl window, if present
    if (nrow(trawl.window) > 0) {
      plot.tdr <- plot.tdr + 
        geom_rect(data = trawl.window,
                  aes(xmin = equilibriumTime,
                      xmax = haulBackTime,
                      ymin = -60,
                      ymax = 12),
                  fill = 'gray70', alpha = 0.5) +
        geom_rect(data = trawl.window,
                  aes(xmin = netInWaterTime,
                      xmax = netOnDeckTime,
                      ymin = -60,
                      ymax = 12), fill = NA,
                  colour = 'gray50', linetype = "dashed", alpha = 0.5) +
        geom_text(data = trawl.text,
                  aes(time, -60, label = event),
                  size = 3, angle = 90, hjust = 0, vjust = -0.3, nudge_y = 1)
      
      if (exists("plot.height")) {
        plot.height <- plot.height +
          geom_rect(data = trawl.window,
                    aes(xmin = equilibriumTime,
                        xmax = haulBackTime,
                        ymin = 0,
                        ymax = 45),
                    fill = 'gray70', alpha = 0.5) +
          geom_rect(data = trawl.window,
                    aes(xmin = netInWaterTime,
                        xmax = netOnDeckTime,
                        ymin = 0,
                        ymax = 45), fill = NA,
                    colour = 'gray50', linetype = "dashed", alpha = 0.5) 
      }
      
      if (exists("plot.spread")) {
        plot.spread <- plot.spread +
          geom_rect(data = trawl.window,
                    aes(xmin = equilibriumTime,
                        xmax = haulBackTime,
                        ymin = 0,
                        ymax = ceiling(max(trawl.tv80$DOR_Spread))),
                    fill = 'gray70', alpha = 0.5) +
          geom_rect(data = trawl.window,
                    aes(xmin = netInWaterTime,
                        xmax = netOnDeckTime,
                        ymin = 0,
                        ymax = ceiling(max(trawl.tv80$DOR_Spread))), fill = NA,
                    colour = 'gray50', linetype = "dashed", alpha = 0.5) 
      }
    }
    
    # Save TDR plot
    ggsave(plot.tdr, 
           filename = here("Figs/TDR",
                           paste0(survey.name, "_TDR_", sprintf("%03d", k), ".png")),
           height = 5, width = 10)
    
    # Combine all performance metrics
    # Remove legend from TDR plot for alignment with others
    plot.metrics <- plot.tdr + 
      theme(legend.position = "none")
    
    if (exists("plot.height")) {
      # Add height plot to TDR data
      plot.metrics <- plot.metrics / plot.height
    }
    
    # Add height plot to TDR data
    if (exists("plot.spread")) {      
      plot.metrics <- plot.metrics / plot.spread 
    } 
    
    if (exists("plot.height") | exists("plot.spread")) {
      # If an additional plot exists
      # Set panel heights based on
      if (length(plot.metrics) == 2) {
        plot.metrics <- plot.metrics +
          plot_layout(heights = unit(c(5, 2), c('cm', 'cm')))
        
        # Set output image height
        composite.h <- 5
        
      } else {
        plot.metrics <- plot.metrics  +
          plot_layout(heights = unit(c(5, 2, 2), c('cm', 'cm','cm')))
        
        # Set output image height
        composite.h <- 7
      }
      
      # Save composite plot
      ggsave(plot.metrics, 
             filename = here("Figs/TDR",
                             paste0(survey.name, "_TDR_All_", sprintf("%03d", k), ".png")),
             height = composite.h, width = 10)
    }
  }
  
  # Print processed TDR hauls.
  cat(paste0("Processed TDR data from haul(s) ", 
             glue_collapse(unique(tbl.all.new$haul), sep = ",", last = " and "), "."))
  
} else {
  cat("No new TDR data have been processed.")
  
}
```

# Plots

Below are TDR data for the last three trawl hauls. **<span style="color: black;">Black</span>** lines are vessel speed over ground (SOG, knots), **<span style="color: purple;">purple</span>** is kite depth, and **<span style="color: blue;">blue</span>** is footrope depth. If present, the  **<span style="color: red;">red</span>** and **<span style="color: green;">green</span>** lines represent the starboard- and port-side trawl door depths, respectively. The dashed box indicates the time between net deployment (or net in water) and retrieval (or net on deck), and the shaded **<span style="color: gray50;">gray</span>** region indicates the time during which the net was fishing (from equilibrium through haul back).  

```{r list-plots}
tdr.figs <- tail(dir_ls(here("Figs/TDR"), regexp = "TDR_All"), 3)

# If no composite plots, plot TDR-only plots
if (length(tdr.figs) == 0) {
  tdr.figs <- tail(dir_ls(here("Figs/TDR"), 3))
}
```

## First plot

```{r plot-1}
# Plot the first TDR plot
if(length(tdr.figs) > 0) {
  include_graphics(tdr.figs[1])  
} else {
  print("No TDR plots available.")  
}
```

## Second plot

```{r plot-2}
# Plot the second TDR plot, if present
if(length(tdr.figs) > 1) {
  include_graphics(tdr.figs[2])  
} else {
  print("No more TDR plots available.")  
}
```

## Third plot

```{r plot-31}
# Plot the second TDR plot, if present
if(length(tdr.figs) > 2) {
  include_graphics(tdr.figs[3])  
} else {
  print("No more TDR plots available.")  
}
```
